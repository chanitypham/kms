{"DSA/***-DSA-map-(OOP-course)":{"title":"*** DSA map (OOP course)","links":["DSA/Kruskal's-Algorithm","DSA/Prim's-Algorithm"],"tags":[],"content":"\n\nKruskal‚Äôs Algorithm\nPrim‚Äôs Algorithm\n"},"DSA/Kruskal's-Algorithm":{"title":"Kruskal's Algorithm","links":["tags/computerScience/DSA/tree/MST","tags/fc","DSA/Prim's-Algorithm"],"tags":["computerScience/DSA/tree/MST","fc"],"content":"Context\n\nTime: 06 04 2024 - 21:51\nTags:MST\nChild:\nSource:\n\nDefinition of Kruskalfc\n\ndefinition\n\nconnected graph\nweighted edge\nresult in a MST\n\n\nalgo\n\npick the smallest edge\nrepeatedly look for the smallest edges that don‚Äôt create a cycle\nlink\nCE ‚Üí AB ‚Üí AD ‚Üí DF ‚Üí FG\nlink\nmerge sort: O(ElogE)\n\n\nalgo2:\n\nStarts to build the MST from the vertex carrying minimum weight in the graph.\nSorts all the edges in increasing order of their weight.\nPicks the smallest edge and checks if it forms a cycle with the spanning tree formed so far. If not, it includes this edge. Else, it discards it.\nRepeats the process until there are (V-1) edges in the spanning tree.\nCan generate forest (disconnected components) at any instant and can work on disconnected components.\nTraverses one node only once.\nTime complexity is O(E log V), where E is the number of edges and V is the number of vertices.\nRuns faster in sparse graphs.\n\n\n\n\nDifference with Prim‚Äôs Algo"},"DSA/Prim's-Algorithm":{"title":"Prim's Algorithm","links":["tags/computerScience/DSA/tree/MST","tags/fc","DSA/Kruskal's-Algorithm"],"tags":["computerScience/DSA/tree/MST","fc"],"content":"Context\n\nTime: 06 04 2024 - 21:55\nTags:MST\nChild:\nSource:\n\nDefinition of Prim‚Äôs Algorithmfc\n\nStarts to build the MST from any vertex in the graph.\nMaintains two sets of vertices. The first set contains the vertices already included in the MST, the other set contains the vertices not yet included.\nAt every step, it considers all the edges that connect the two sets and picks the minimum weight edge from these edges.\nAfter picking the edge, it moves the other endpoint of the edge to the set containing MST.\nGives connected component and works only on connected graph.\nTraverses one node more than one time to get the minimum distance.\nTime complexity is O(V^2), which can be improved up to O(E log V) using Fibonacci heaps.\nRuns faster in dense graphs\n\n\nDifference with Kruskal‚Äôs Algorithmfc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrim‚Äôs AlgorithmKruskal‚Äôs AlgorithmIt starts to build the Minimum Spanning Tree from any vertex in the graph.It starts to build the Minimum Spanning Tree from the vertex carrying minimum weight in the graph.It traverses one node more than one time to get the minimum distance.It traverses one node only once.Prim‚Äôs algorithm has a time complexity of O(V2), V being the number of vertices and can be improved up to O(E log V) using Fibonacci heaps.Kruskal‚Äôs algorithm‚Äôs time complexity is O(E log V), V being the number of vertices.Prim‚Äôs algorithm gives connected component as well as it works only on connected graph.Kruskal‚Äôs algorithm can generate forest(disconnected components) at any instant as well as it can work on disconnected componentsPrim‚Äôs algorithm runs faster in dense graphs.Kruskal‚Äôs algorithm runs faster in sparse graphs.It generates the minimum spanning tree starting from the root vertex.It generates the minimum spanning tree starting from the least weighted edge.Applications of prim‚Äôs algorithm are Travelling Salesman Problem, Network for roads and Rail tracks connecting all the cities etc.Applications of Kruskal algorithm are LAN connection, TV Network etc.Prim‚Äôs algorithm prefer list data structures.Kruskal‚Äôs algorithm prefer heap data structures.^1712415352340"},"algoDesign/***algoDesign-map":{"title":"***algoDesign map","links":["algoDesign/algorithm-design-process","algoDesign/stable-matching-problem","algoDesign/Gale-Shapley-Algorithm","algoDesign/algorithm-analysis--and--efficiency--and--worst-case-runtime","algoDesign/big-o-notation","algoDesign/big-omega-notation","algoDesign/big-theta-notation","algoDesign/huffman-coding","algoDesign/Depth-First-Search---DFS","algoDesign/Lab-2-algo-des","algoDesign/Lab-3-algo-des","algoDesign/Lab-4-algo-des","algoDesign/Lab-5-algo-des"],"tags":[],"content":"*** algoDesign map\nLec 01: intro to algos and stable matching problem\n\nalgorithm design process\nspecific algo learned during the course\n\ngreedy\ndivide and conquer\ndynamic programming\nnetwork flows\n\n\nstable matching problem\n\nGale Shapley Algorithm\n\n\n\nLecture 02: Basic of Algorithm Analysis\n\nalgorithm analysis &amp; efficiency &amp; worst case runtime\n\nbig-o notation\nbig-omega notation\nbig-theta notation\n\n\n\nGreedy Algo 1\n\ncoin changing\n\ncons of greedy: only care about present, not the future; lack of backtracking!!\n\n\ninterval scheduling\ninterval partitioning\nscheduling to minimal lateness\nhuffman coding\nDepth First Search - DFS\n\n\nLab\nLab 2 algo des\nLab 3 algo des\nLab 4 algo des\nLab 5 algo des"},"algoDesign/Depth-First-Search---DFS":{"title":"Depth First Search - DFS","links":[],"tags":[],"content":"implementation\ndef dfs(matrix, start):\n    visited = []\n    stack = [start]\n \n    while stack:\n        vertex = stack.pop()\n        if vertex not in visited:\n            visited.append(vertex)\n            for i in range(len(matrix)):\n                if matrix[vertex][i] and i not in visited:\n                    stack.append(i)\n \n    return visited\n \nn = int(input())\nmatrix = [list(map(int, input().split()))for _ in n]\nstart = int(input())\ndfs(matrix, start)"},"algoDesign/Gale-Shapley-Algorithm":{"title":"Gale Shapley Algorithm","links":[],"tags":[],"content":"Propose-and-Reject (Gale-Shapley) Algorithm\n\n\n\n\ntheoretical explanation\n\neverybody (all those from the 2 sides) submit their preference list, ranking the other side\n1st side choosing other people of the 2nd side. those of 2nd side with many selections will reject all but their top suitors. Those who match will form a tentative pair\neach 1st side people rejected then propose the their next rank choices (whether their choices are free or not). 1st side and 2nd side people, forming the previously tentative pair, can reconsider and make new pair\niterate step 1-3\n\n\nexample\n\n\n\n\n\nimplementation\n\nyoutu.be/o1olHmxDzTw\n\nalgorithm analysis\n\ntermination guaranteed? ‚Üí Yes, at most n2 proposals/rounds of the algorithm\n\nn men, in worst case, each man has to propose to n women in order to find a match ‚áí n2\n\n\neveryone gets a match guaranteed? ‚Üí Yes\n\n\n\n\nresult allocation guaranteed stable? ‚Üí Yes\n"},"algoDesign/Lab-2-algo-des":{"title":"Lab 2 algo des","links":[],"tags":[],"content":"Theory Practice\nQuestion 1\n\nSecond loop runs from 0 to i2‚àí1 ‚Üí when j%i, the third loop will run 1,i,2i,‚ãØ times\nTotal loop: 1+i+2i+‚ãØ+(i‚àí1)i=1+2i2(i‚àí1)‚Äã ‚áí Complexity is O(n3)\n‚áí Total complexity: O(n4) (count the first loop)\n\nQuestion 2\n\n\nTo prove that f1‚Äã+f2‚Äã=Œ∏(max{f1‚Äã(n),f2‚Äã(n)}), we need to show there exists positive constants k1‚Äã,l2‚Äã,n0‚Äã such that ‚àÄn‚â•n0‚Äã we have:\n\nk1‚Äã.max(f1‚Äã,f2‚Äã)‚â§f1‚Äã+f2‚Äã‚â§k2‚Äã.max(f1‚Äã,f2‚Äã)\n\n\n\nWLOG, we assume f1‚Äã‚â§f2‚Äã so we have to prove\n\nk1‚Äã.f2‚Äã‚â§f1‚Äã+f2‚Äã‚â§k2‚Äã.f2‚Äã\n\n\n\nWith k2‚Äã=2, the right inequality always hold as f1‚Äã+f2‚Äã‚â§f2‚Äã+f2‚Äã=2‚ãÖf2‚Äã\n‚áí By choosing k1‚Äã=1,k2‚Äã=2, and any n0‚Äã\n\n\nFrom the definition, we have f(n)=Œ∏(g(n)) ‚áí f is asymptotically positive (f&gt;0).\n\n\nWith k1‚Äã=1, the left inequality always hold as f1‚Äã+f2‚Äã‚â•f2‚Äã(sincef‚â•0)\n‚áí Proving max(f1‚Äã,f2‚Äã)=Œ∏(f1‚Äã‚àíf2‚Äã)  is now finding k1‚Äã,k2‚Äã\nand n0‚Äã such that for all n‚â•n0‚Äã we have:\nk1‚Äã‚ãÖ(f1‚Äã‚àíf2‚Äã)‚â§max(f1‚Äã,f2‚Äã)‚â§k2‚Äã‚ãÖ(f1‚Äã‚àíf2‚Äã). With f1‚Äã=x,f2‚Äã=x‚àí1 ‚áí k1‚Äã‚ãÖ1‚â§x‚â§k2‚Äã‚ãÖ1\nAs x varies, it is impossible to find such constants k1,k2 ‚áí The statement is then disproved\n\n\nQuestion 3:\n\nWe can use Hash Set, in which we will gradually append an element into the Hash Set. We then will not append an element that already appears in the Set\nThe operation of adding an element to the Set and checking whether there already has that element has the complexity of O(n)\nthe suggested code\n\ndef removeDuplication(arr):\n\thash_Set = set()\n\tfor i in arr:\n\t\tif i not in hash_Set:\n\t\t\thash_Set.add(i)\n\tprint(hash_Set)\n \nremoveDuplication([1,2,4,4,6,2,4,7,6])\n\nthis will output:\n\n{1, 2, 4, 6, 7} # a set of integers with no duplications\nQuestion 4:\n\nThe worst case running time of this algorithm:\n\nfor subproblems with size ‚â§k, the algorithm uses insertion sort, with worst case time complexity is O(k2)\nThe complexity of using Merge sort with problem size k in this case is O(log(n/k)). As each layer requires O(n) for merging, the complexity for this process if O(nlogkn‚Äã)\nThe complexity of using Insertion sort with the problem size k in this case is O(k2.kn‚Äã)=O(nk)\nTotal complexity would be: O(nk+nlogkn‚Äã)\n\n\n\nQuestion 5:\nWe have: ‚àëi=2‚àû‚Äãi1‚Äã‚â§‚à´1n‚Äãx1‚Äã‚ü∫H(n)‚â§‚à´1n‚Äãx1‚Äã+1‚àíln(n)+1\nWe also have: ‚àëi=1‚àû‚Äã21‚Äã‚â•‚à´1n‚Äãx1‚Äã‚ü∫H(n)‚â•ln(n)\n‚áí ln(n)‚â§H(n)‚â§ln(n)+1"},"algoDesign/Lab-3-algo-des":{"title":"Lab 3 algo des","links":[],"tags":[],"content":"Theory\nQuestion 1:\n\nThe proposed solution of iteratively choosing the position to build new stations, maximizing the number of new towns covered, is not necessarily optimal.\nExample:\n\nConsider a scenario where the towns along the railroad path are arranged in a zigzag pattern\nThe algorithm starts by selecting the first town and building a train station at that position\nAs it iterates through the towns, it will continue to build train stations at every other town, alternating between the upper and lower positions\n‚áí This approach may result in a higher number of train stations being built compared to an optimal solution\n\n\n\n\nAn optimal solution would identify that building train stations only at the upper or lower positions, rather than both, can cover all the towns within the required distance D\nBy selecting the upper or lower positions strategically, the optimal solution can achieve the same coverage with fewer train stations\n\nQuestion 2:\n\nThe workers have 2 actions: load package on current truck or let current truck go and load on new truck\nCurrent procedure: load each truck to full capacity before moving to next truck\n\n\nCase 1: Package is too big for current truck - no difference between company‚Äôs solution and optimal solution\nCase 2: Package can fit in current truck - company‚Äôs solution always loads on current truck, optimal solution may load on next truck\nIf both solutions have same actions up to a point, optimal solution will use one more truck than company‚Äôs solution. So if number of packages loaded is the same, but optimal solution uses one more truck ‚áí not actually optimal\n‚áí Company solution is optimal\n\nQuestion 3:\n\nWhat makes Prim‚Äôs algorithm ‚Äúgreedy‚Äù?\n\nThe algorithm makes the optimal choice at each iteration by selecting the shortest edge that connects a vertex outside the tree to a vertex in the tree.\n\n\nTime and space complexity for Prim‚Äôs algorithm:\n\nTime complexity:\n\nO((n + m) log n), where n is the number of vertices and m is the number of edges in the graph\nReason: The algorithm iterates through all vertices and their neighbors, and the priority queue operations take O(log n) time.\n\n\nSpace complexity:\n\nO(n), where n is the number of vertices\nReason: The algorithm need to store all the edges of the graph (O(m)) and all vertices of the graph (O(n))\n\n\n\n\nDoes Prim‚Äôs algorithm always return the optimal solution:?\n\nYes, Prim‚Äôs algorithm always returns the optimal solution, which is the minimum spanning tree. This can be proven by showing that at each iteration, the algorithm selects the shortest edge that connects a vertex outside the tree to a vertex in the tree. By always choosing the shortest edge, the algorithm ensures that the total weight of the edges in the tree is minimized.\n\n\n\nQuestion 4\n\nThe robot‚Äôs algorithm finds a peak in a 2-D mountain range near its starting point\nHowever, it may get stuck in a local maximum and miss potentially taller global maximums\nIn a 3D case, the algorithm needs to consider multiple angles with varying granularity, in which a smaller angle granularity leads to higher computational costs\nTo improve the algorithm‚Äôs performance, steps can be introduced where the robot moves towards the point determined by gradient descent\nThe distance of each move determines the next step to consider\nFor example, if going higher by gradient descent brings a 5-meter increase, the next steps will scan a larger distance around it (e.g., 1/5 meter further)\nThis way, the robot considers a greater distance as it gets closer to its local maximum. And this approach may help the algorithm find the global maximum more efficiently.\n"},"algoDesign/Lab-4-algo-des":{"title":"Lab 4 algo des","links":[],"tags":[],"content":"Question 1:\nWe can use the Prim‚Äôs algorithm to find the Minimum Spanning Tree\n\nPick the edge with minimum weight from the edges set; for example, we pick edge (0,1) with weight 2\nRepeatedly picking edges with weight 2, we will result in [(0,1),(1,2),‚ãØ,(n‚àí1,n)] with nodes [0,1,2,‚ãØ]\nOur minimum spanning tree then will have the weight of ‚àëi=1n‚Äã2‚à£i‚àí(i‚àí1)‚à£=2n\n\nQuestion 2:\n\nApproach:\n\nFinding maximum vehicle height using modified Prim‚Äôs algorithm.\n\n\nAlgorithm Steps:\n\nSort edges by weight (descending).\nRepeat until all nodes are explored:\na. Select edge with maximum weight d\nb. Determine maximum allowable height at the intersection d\nc. Mark other end of road (nodes) as explored\n\n\nAlgorithm Characteristics:\n\nTime complexity: O(Blog V)\nSpace complexity: O(B + V)\n\n\n\nQuestion 3:\n\nGreedy: At each step, the algorithm chooses the two symbols with the lowest frequencies, without considering their future impact on the encoding of other symbols.\nOptimal substructure: Huffman coding constructs an optimal prefix code by recursively merging the two least frequent characters into a single node. This process repeats until a single root node remains. The efficiency of this method is due to Huffman coding‚Äôs optimal substructure property.\n\nQuestion 4:\n\n\n\n\n\n\naaaaaaaabbbbccccddee‚Üí 00000000100100100100101101101101110110111111\n"},"algoDesign/Lab-5-algo-des":{"title":"Lab 5 algo des","links":[],"tags":[],"content":"Algorithm Design - Spring 2024\nPham Quynh Trang\nV202200890\nQuestion 1:\n\nAlgorithm\n\nIterate through nodes in sorted order\nRemove each outgoing arc temporarily &amp; check if resulting graph is a valid topological ordering (using the Topological Sort function)\nIf yes, arc can be removed; otherwise, restore it\n\n\n\nQuestion 2:\na) Maximizing Minimum Weight of Edge:\n\nObservations:\n\nDetermining the existence of a perfect matching in a graph is straightforward, regardless of edge weights.\nConstruct a graph G(h) from Kn,n using only edges with weights at least h.\nThe perfect matching, M, in Kn,n maximizing the minimum edge weight contains exactly n edges.\nIf there‚Äôs a perfect matching in G(h), M in Kn,n must have a minimum edge weight ‚â•h\n\n\nApproach:\n\nFind the largest possible h such that a perfect matching exists in G(h), employing binary search\nThe perfect matching in G(h) becomes the desired solution in Kn,n, maximizing the minimum edge weight\n\n\n\nb) Maximizing Product of Chosen Edges‚Äô Weights\n\nAlgorithm Choice: One option is to use Max-flow Algorithm\nKey Observation:\n\nUtilize the property log(a‚àób)=log(a)+log(b).\nConvert the problem into finding a max-flow that maximizes the log-weight.\n\n\nSolution Approach: Apply the minimum-cost maximum-flow algorithm to discover the perfect matching maximizing the product of chosen edges‚Äô weights\n\nThe minimum-cost maximum-flow algorithm is a graph algorithm used to find the maximum flow in a network with minimum cost. It involves finding the optimal flow from a source to a sink while minimizing the total cost associated with sending the flow through the network.\nMethods:\n\nRepresent the graph with edge weights as costs.\nApply the minimum-cost maximum-flow algorithm to find the maximum flow that minimizes the total cost, which in this case corresponds to maximizing the sum of logarithmic weights.\nThe resulting flow corresponds to the desired perfect matching, achieving the objective of maximizing the product of chosen edges‚Äô weights.\n\n\n\n\n\nQuestion 3:\n\n\na.  List of edges must be in the MST regardless of the missing cost values\n\nApplying Kruskal algorithm, we will sort the edges in ascending order. ‚áí We have:\n\nGH = 2 &lt; BD = 3 &lt; BC = 9 &lt; AC = 10 &lt; DC = 15 &lt; AB = 20\nIf there are &gt;4 edges with cost &lt;=2, GH might not be chosen in the MST ‚áí GH is not a must choose edge\nBD will then be chosen next or chosen after some edges have cost &lt;=3. It will not be the last edge chosen, as it need at least 6 edges to connect vertices A, C, E, F, G, H and form MST. If we do not use BD, either AB or BC must be used to connect all vertices and form MST, in which each of these edges all cost more than BD ‚áí BD is a must choose edge\nBC is not a must choose edge (as proven above)\nSuppose that C has not been connected, it will either be connected by AC or BC as among all those known edge weights, AC &lt; BC &lt; DC. But BC is not an optimal selection ‚áí we choose AC ‚áí AC is a must choose edge to make sure it will go through all the nodes in optimal paths\nb. Edges cannot be added in the MST are AB and CD. As the Kruskal algorithm will always choose BD, BC, or AC before AB and CD.\n\n\n\n\n\nQuestion 4:\n\nGoal: Determine existence of a simple cycle through edge (s,t) with cost ‚â§ Œ≥.\n\nFind a simple path from t to s with minimum cost.\nUse edge (s,t) to form the cycle with minimum cost, including (s,t).\n\n\nDistances:\n\nDefine dist(t,s) as the minimum cost of the simple path from t to s.\nCheck if dist(t,s)+cs,t‚â§Œ≥\n\n\nProcedure:\n\nFind the minimum cost simple path from t to s.\nAdd the cost of edge (s,t) to determine if the cycle satisfies the condition.\n\n\n\nQuestion 5:\n\nInitialization: Initialize a variable ‚Äòres‚Äô to a vertex, starting at 0. Eventually, ‚Äòres‚Äô might become the universal sink.\n\n‚Äòres‚Äô is set to a vertex, initially 0.\n\n\nComparison:\n\nCompare ‚Äòres‚Äô with each subsequent vertex to determine its potential as a universal sink.\nIf there‚Äôs an edge from ‚Äòres‚Äô to the current vertex, update ‚Äòres‚Äô to the current vertex.\nOtherwise, keep ‚Äòres‚Äô unchanged.\n\n\nVerification:\n\nAfter the process, if only one vertex remains in ‚Äòres‚Äô, it could be a universal sink.\nCheck if any other vertices have edges pointing towards this vertex.\n\nIf no such vertices exist, it‚Äôs a universal sink.\nOtherwise, it‚Äôs not.\n\n\n\n\n"},"algoDesign/algorithm-analysis--and--efficiency--and--worst-case-runtime":{"title":"algorithm analysis & efficiency & worst case runtime","links":["algoDesign/algorithm-analysis--and--efficiency--and--worst-case-runtime"],"tags":[],"content":"what is algorithm analysis\n\nstudy to estimate the resources an algorithm used to solve a specific problem, i.e. calculating efficiency\ndoes not give exact values (eg. time, space, v.v), but help to study the behavior and estimate efficiency of the algo\n\nwhat is efficiency in algorithm\n\nrelated to the input length - time complexity, or volume of memory - space complexity\nwhy care about efficiency: there are many approaches to solve problem. Algo analysis is then to figure out what is the most optimal solution\n\neg. airbag in cars are programmed to open within 2s (for eg), if it takes longer ‚Üí cant protect the driver\n\n\n\nwhat is time complexity\n\na computational way to show how runtime of an algo changes as the input size changes\n\nwhy measure using worst case analysis - WCA\n\npurpose of worst case running time: what if an algo performs well on most cases except for some very slow running case?\nWCA is considered most efficient in analyzing algo\n\nas for eg average-case analysis, where we study the performance of an algorithm over random instances ‚Üí what is random? How to choose unbiased random\nreal input is not also a random distribution ‚Üí average case analysis tells more about mean performance of an algorithm rather than the comprehensive performance of the algorithm.\n\n\n\nbenchmark of WCA to determine algo efficiency\n\ncompare with brute force search (checking all possible cases)\nalgo is efficient if achieves better worst case performance than brute force search\nbrute force is not good as\n\ntoo slow to be useful\nintellectual cop-out, provide nothing into the structure of the problem we are studying\n\n\nalgo improving brute force search nearly always contain a valuable heuristic idea (shortest straight path to the goal) + computational tractability (ability to calculate)\nalgo is efficient if it has polynomial running time\n\npolynomial types:\n\nConstant (degree 0)\nLinear (degree 1)\nQuadratic (degree 2)\nCubic (degree 3)\nand so on\n\n\n\n\n\n\nasymptotic analysis\n\nmethod of defining mathematical boundaries of an algo‚Äôs run-time performance ‚Üí estimate time complexity function for arbitrarily large input\ncan estimate the average case, best case, and worst case scenario of an algorithm\n\ncommon asymptotic notations\n\nconstant time: O(1)\nlinear: O(n)\nlogarithmic: O(log n)\nquadratic: O(n^2)\ncubic: On(n^3)\nand so on\norder: (1&lt;log(n)&lt;sqr(n)&lt;n&lt;n√ólog(n)&lt;n2&lt;n3&lt;....&lt;nn)\nnote: remove all constants. eg. O(n/2) ‚Üí O(n)\n"},"algoDesign/algorithm-design-process":{"title":"algorithm design process","links":[],"tags":[],"content":"algorithm design process\n\ngiven a computing problem, how to approach solution\n\nformulate mathematically clean problem definition\npropose an algo\nprove that it correctly solves the problem\nanalyze its running time\n‚Üí iterative process\n\n\n"},"algoDesign/big-o-notation":{"title":"big-o notation","links":[],"tags":[],"content":"what is big-o notation\n\nmathematical way to express (the closest) upper bound (worst case) of an algorithm running time\nmathematical example: pic, pic 2\nformula: f(n)=O(g(n)) IFF f(n)&lt;=c.g(n), where n‚â•n0‚Äã,c&gt;0,n0‚Äã‚â•1\n\nc: constant\nn: natural number denoting size of the algo\n\n\npic\n"},"algoDesign/big-omega-notation":{"title":"big-omega notation","links":[],"tags":[],"content":"what is big-omega notation\n\nmathematical way to express (the closest) lower bound (best case) of an algorithm running time - fastest time an algorithm can run\nformula: f(n)=Œ©(g(n)) IFF f(n)&gt;=c.g(n), where n‚â•n0‚Äã,c&gt;0,n0‚Äã‚â•1\n\nc: constant\nn: natural number denoting size of the algo\n\n\nexample: pic\n"},"algoDesign/big-theta-notation":{"title":"big-theta notation","links":[],"tags":[],"content":"what is big-theta notation\n\nmathematical way to express average case of an algorithm running time - most realistic time complexity\nnormally used when best case O = worst case Œ©\nformula: f(n)=Œ∏(g(n)) IFF c1‚Äã.g(n)‚â§f(n)‚â§c2‚Äã.g(n), where n‚â•n0‚Äã;c1‚Äã,c2‚Äã&gt;0;n0‚Äã‚â•1\n\nc: constant\nn: natural number denoting size of the algo\n\n\nexample: pic\n"},"algoDesign/huffman-coding":{"title":"huffman coding","links":[],"tags":[],"content":"how to do huffman encoding\n\nsource: link\ngiven a string ‚ÄúAABCBAD‚Äù ‚Üí 7 characters\n\n7 * 8 bits (UTF-8) = 56 bits\n\nUnicode transformation format = UTF\n\n\n\n\nwrite table of the # of repetition for each character\n\n\n\n\nmake huffman tree by joining the 2 least repeated elements. continue until an entire tree is made with every element\n\n\n\n\n\n\nleft path is 0\nright path is 1\n\n\n\n\nencode each character\n\n\n\n\nfinal result\n\n\n\n\n"},"algoDesign/stable-matching-problem":{"title":"stable matching problem","links":["algoDesign/Gale-Shapley-Algorithm"],"tags":[],"content":"problem\n\n\nproblem in written description:\n\n\n\n\n‚ÄúSTABLE‚Äù\n\neveryone gets matched\nno pair of individuals both prefer each other to their current partners (if it is just 1 individual preferring the other, it‚Äôs fine)\n\n\n\nsolution\n\nGale Shapley Algorithm\n"},"algoDesign/time-complexity--and--space-complexity":{"title":"time complexity & space complexity","links":[],"tags":[],"content":"time complexity\n\ntime required to solve given prob\n\nhow to estimate\n\n\n\nspace complexity\n\nmemory required to solve given prob\n"},"artificialIntelligence/***AI-map":{"title":"***AI map","links":["artificialIntelligence/the-importance-of-AI","artificialIntelligence/what-is-AI","artificialIntelligence/the-different-approached-to-AI","artificialIntelligence/definition-of-an-agent","artificialIntelligence/the-structure-of-agents","artificialIntelligence/learning-agents","artificialIntelligence/options-to-design-an-AI-agent","artificialIntelligence/designing-rational-agents","artificialIntelligence/reflex-agent","artificialIntelligence/planning-agent","artificialIntelligence/search-problems","artificialIntelligence/state-space","artificialIntelligence/state-space-graph-vs-search-tree","artificialIntelligence/state-space-graph","artificialIntelligence/search-tree","artificialIntelligence/search-algorithm","artificialIntelligence/tree-search-algorithm","artificialIntelligence/depth-first-search---dfs","artificialIntelligence/breadth-first-search---bfs","artificialIntelligence/iterative-deepening","artificialIntelligence/cost-sensitive-search","artificialIntelligence/uniform-cost-search---ucs","artificialIntelligence/pancake-problem","artificialIntelligence/fringe-strategy---the-one-queue","artificialIntelligence/search-heuristics","artificialIntelligence/greedy-search","artificialIntelligence/a*-search","artificialIntelligence/admissible-heuristics","artificialIntelligence/manhattan's-distance","artificialIntelligence/8-Puzzle","artificialIntelligence/semi-lattice-of-heuristics","artificialIntelligence/graph-search","artificialIntelligence/consistent-heuristics","artificialIntelligence/constraint-satisfaction-problems","artificialIntelligence/examples-of-constraint-satisfaction-problems","artificialIntelligence/constraint-graphs","artificialIntelligence/The-Waltz-Algorithm","artificialIntelligence/Standard-Search-Formulation-of-CSPs","artificialIntelligence/search-methods-for-CSPs","artificialIntelligence/backtracking-search","artificialIntelligence/filtering-in-CSPs---forward-checking,-arc-consistency","artificialIntelligence/k-consistency","artificialIntelligence/ordering-in-CSPs---minimum-remaining-values,-least-constraining-value","artificialIntelligence/deterministic-games","artificialIntelligence/zero-sum-games","artificialIntelligence/Expectimax-Search","artificialIntelligence/probabilities,-for-search-in-AI","artificialIntelligence/the-dangers-of-optimism-and-pessimism-in-model-assumptions","artificialIntelligence/Expectiminimax","artificialIntelligence/multi-agent-utilities","artificialIntelligence/monte-carlo-tree-search","probStatAdvanced/Markov-chain","artificialIntelligence/Markov-Decision-Processes---MDP","artificialIntelligence/utility-of-sequences-in-MDP","artificialIntelligence/The-Bellman-Equation","artificialIntelligence/quiz-2-AI","artificialIntelligence/COMP2050-Homework-1","artificialIntelligence/COMP2050-Homework-2"],"tags":[],"content":"Lectures\nChapter 1: Introduction\n\nthe importance of AI\nwhat is AI\nthe different approached to AI\n\nChapter 2: Intelligent Agents\n\ndefinition of an agent\nthe structure of agents\nlearning agents\n\n\nLecture 2: Agents and Search\n\noptions to design an AI agent\ndesigning rational agents\n\nreflex agent\nplanning agent\n\n\nsearch problems\nstate space\nstate space graph vs search tree\n\nstate space graph\nsearch tree\n\n\nsearch algorithm\n\ntree search algorithm\ndepth-first search - dfs\nbreadth-first search - bfs\niterative deepening\ncost-sensitive search\nuniform cost search - ucs\n\n\n\nLecture 3: Informed Search\n\nsearch so far\n\nsearch problems\nsearch tree\nsearch algorithm\n\n\npancake problem\nfringe strategy - the one queue\nuniform cost search - ucs\nsearch heuristics\ngreedy search\na* search\nadmissible heuristics\n\nmanhattan‚Äôs distance\n8 Puzzle\nsemi-lattice of heuristics\n\n\ngraph search\nconsistent heuristics\n\nLecture 4 + 5: CSPs\n\nTo solve search problems, we have assumptions about the world of the problem:\n\na single agent\ndeterministic actions\nfully observed states\ndiscrete state space\n\n\nsearch so far is for planning problem, concerning sequences of actions\n\npath to goal is important\npaths have various costs, depths\nheuristics give problem-specific guidance\n\n\nanother search problem is identification problem: assignments to variables\n\ngoal is important, not the path\nall paths have same depth (for some formulations)\nCPS - specialized class of identification problems ‚Üí have more\n\n\nconstraint satisfaction problems\n\nexamples of constraint satisfaction problems\n\n\nconstraint graphs\n\nThe Waltz Algorithm\nStandard Search Formulation of CSPs\n\n\nsearch methods for CSPs\n\nbacktracking search\n\nfiltering in CSPs - forward checking, arc consistency\nk-consistency\nordering in CSPs - minimum remaining values, least constraining value\n\n\n\n\n\nLecture 6: Search with Other Agents I\n\ntypes of games: many\n\naxes\n\nDeterministic or stochastic?\nOne, two, or more players?\nZero sum?\nPerfect information (can you see the state)?\n\n\nwant algo to calculate strategy (policy) recommending a move from each state\ndeterministic games\nzero sum games\nvalue of a state: V(s) = maximum value of the child nodes s‚Äô of s\n\n\n\nLecture 7: Search with Other Agents II - Uncertainty &amp; Utility\n\nworst-case vs average case: Uncertain outcomes controlled by chance, not an adversary!\n\nup triangle: maximizer\ndown triangle: minimizer\ncircle: chance node\n\n\nExpectimax Search\nprobabilities, for search in AI\nthe dangers of optimism and pessimism in model assumptions\nmixed layer game types\n\nExpectiminimax\nmulti-agent utilities\n\n\nmonte carlo tree search\nsummary\n\nÔªøÔªøGames require decisions when optimality is impossible\n\nÔªøÔªøBounded-depth search and approximate evaluation functions\n\n\nÔªøÔªøGames force efficient use of computation\n\nÔªøÔªøAlpha-beta pruning, MCTS\n\n\nÔªøÔªøGame playing has produced important research ideas\n\nÔªøÔªøReinforcement learning (checkers)\nÔªøÔªøIterative deepening (chess)|\nÔªøÔªøRational metareasoning (Othello)|\nÔªøÔªøMonte Carlo tree search (chess, Go)\nÔªøÔªøSolution methods for partial-information games in economics (poker)\n\n\n\n\n\nLecture 8: Markov Decision Processes MDP\n\nwhat‚Äôs next beyond search\n\nsearch: calculate what to do in current situation\n\n\nMDP is looking at learning habits/reflexes\n\npre-calculate what to do for any situation\nMarkov chain\n\n\nMarkov Decision Processes - MDP\n\nutility of sequences in MDP\nThe Bellman Equation\n\n\n\nQuiz\nQuiz 2\n\nquiz 2 AI\n\nHomework\nHomework 1\n\nCOMP2050 Homework 1\nCOMP2050 Homework 2\n\n\nLec"},"artificialIntelligence/8-Puzzle":{"title":"8 Puzzle","links":[],"tags":[],"content":"8 puzzle\n\npic\n\n8 puzzle 1\n\npic\nheuristic: # of tiles misplaced\nadmissible? Yes, as every misplaced tiles has to undergo an action ‚áí minimum # of action = # titles misplaced. ‚áí This is an underestimation of the actual cost, as every misplaced titles has to undergo a series of actions, not just 1 action\nh(start): 8 = # of tiles misplaced at the start state\n‚áí this is relaxed problem heuristic\n\n8 puzzle 2\n\npic\nheuristic: sum of the manhattan‚Äôs distance\nrelaxed problem? yes, as you can slide the tiles just like when there are no other tiles.\nadmissible? yes, as each tile has to go through &gt; than the heuristic cost when there are other tiles around\nh(start) = sum of total manhattan‚Äôs distance of each tile from the start state to the goal state (when there are no other tiles)\n\nwith 1: dist = 3\nwith 2: dist = 1\nwith 3: dist = 2\nwith 4: dist = 2\nwith 5: dist = 2\nwith 6: dist = 3\nwith 7: dist = 3\nwith 8: dist = 2\n‚áí h(start) = 3+1+2+2+2+3+3+2 = 18\n\n\n\n8 puzzle 3\n\nusing actual cost as heuristic\nadmissible? Yes, h(x)=h‚àó(x) ‚Üí still satisfy\nsave on nodes expanded? Yes\nwhat‚Äôs wrong ‚Üí we dont know the actual cost :D\n"},"artificialIntelligence/COMP2050-Homework-1":{"title":"COMP2050 Homework 1","links":[],"tags":[],"content":"COMP2050 Homework 1\nProblem 1:\n\nAs in graph with negative weights, using UCS may not be optimal even though the algorithm will still be terminated. Therefore, Professor Khoa cannot find the optimal solution using UCS with negative energy.\nIn the modified graph, where all edges are non-negative (assuming Œ±=‚àí1), the optimal route can be found and the algorithm can terminate. However, the optimal path in the original graph, which may contain negative edges, could differ\nNo, it will be the same.\n\nProblem 2:\nProblem:¬†You are trapped in a large, complex maze garden and need to find the exit. The garden is represented as a 2D grid where open paths are denoted by ‚Äò0‚Äô and walls are denoted by ‚Äò1‚Äô. The starting position is at the top-left corner (0,0) and the exit is at the bottom-right corner (n-1, m-1). There is also a branching factor, interpreted as the constraint on maximum number of directions you can traverse (i.e. left, right, up, down)\nIn this case, Depth-First Search (DFS) can be more efficient than Breadth-First Search (BFS) as:\n\nPath Length &amp; Branching Factor¬†DFS is a better choice if the solution is expected to be far from the root. In this problem problem, if the exit is known to be far from the entrance, DFS could reach the solution faster because it explores a complete path to the end before backtracking.\nSpace Complexity:¬†DFS uses less memory than BFS. In the worst-case scenario, BFS needs to store all nodes in memory, while DFS only needs to store some paths from the root to a leaf node, along with siblings of each node on the path\n\nIn general, DFS is usually better than BFS in problems where:\n\nThe tree/graph is known to have a large breadth (i.e., each node has many children)\nThe solution is expected to be deep in the tree/graph and not located in the higher levels\nSpace is a matter of concern, as DFS has lower memory requirements than BFS\n\nProblem 3:\n\nState: A tuple (a,b,c)\n\na represents the water in the 5L jar\nb represents the water in the 8L jar\nc represents the water in the 12L jar\n\n\nSuccessor Function:\n\nFill: Fill a jar from the source, changing the state to (5,b,c), (a,8,c), or (a,b,12). The cost is the effort to fill\nEmpty: Empty a jar, changing the state to (0,b,c), (a,0,c), or (a,b,0). The cost is minimal\nPour: Pour water between jars. The outcome depends on the current state.\n\n\nExample case: Pouring from the 5L to the 8L jar:\n\nif b+a‚â§8, results in (0,b+a,c)\nif b+a&gt;8, results in (a‚àí(8‚àíb),8,c)\n\n\nThe cost is the transferred water amount\n\n\nInitial State: (0,0,0)\nGoal State: (9,b,c);(a,9,c);(a,b,9)\n"},"artificialIntelligence/COMP2050-Homework-2":{"title":"COMP2050 Homework 2","links":[],"tags":[],"content":"Problem 1:\n\nVariable: V={X1‚Äã,X2‚Äã,X3‚Äã}\n\nX1‚Äã: first student hired\nX2‚Äã: second student hired\nX3‚Äã: third student hired\n\n\nDomains: D={Chinh,Duy,Quang,Jason,Hoang,Hieu,Phuc}\nConstraints:\n\nX1‚ÄãÓÄ†=X2‚ÄãÓÄ†=X3‚Äã\n2 AI expertises:\n\nProf Khoa has AI expertise, so at least 1 other must have AI expertise as well.\nXi‚Äã with i‚àà{1,2,3} should have AI expertise\nPossible selections of AI: Chinh, Jason, Hieu\n\n\n2 Front end:\n\nCount of FE engineers among X1‚Äã,X2‚Äã,X3‚Äã should be 2\nPossible selections of FE: Chinh, Duy, Quang, Hoang, Phuc\n\n\n1 Photoshop:\n\nCount of Photoshop among X1‚Äã,X2‚Äã,X3‚Äã should be 1\nPossible selections of Photoshop: Duy, Hoang, Phuc\n\n\n1 Back end:\n\nCount of BE engineers among X1‚Äã,X2‚Äã,X3‚Äã should be 1\nPossible selections of BE: Jason\n\n\n1 System:\n\nCount of System engineers among X1‚Äã,X2‚Äã,X3‚Äã should be 1\nPossible selections of System: Quang, Hieu\n\n\n\n\n\nProblem 2\n\nanother choice can be\n\nVariable:\n\nR1‚Äã: Room where Duy is located\nR2‚Äã: Room where Chinh is located\nR3‚Äã: Room where Quang is located\nW1‚Äã: weapon in room adjacent to Duy‚Äôs room\nW2‚Äã: weapon in room adjacent to Chinh‚Äôs room\nW3‚Äã: weapon in room adjacent to Quang‚Äôs room\n\n\nDomain:\n\nEach variable Ri‚Äã,i‚àà{1,2,3} and Wj‚Äã,j‚àà{1,2,3} , can take values from set of 3 rooms and 3 weapons, which is {1,2,3} respectively\n\n\n\n\nUsing the variables and domains already provided in part a, we have the constraint:\n\n\n\nCÓÄ†=DÓÄ†=Q\n\n\nkÓÄ†=gÓÄ†=w\n\n\nDÓÄ†=w\n\n\n‚à£C‚àíg‚à£=1\n\n\n‚à£Q‚àík‚à£=1\n\n\nDÓÄ†=1,gÓÄ†=1\n\n\nBacktracking steps Table\n\n\n\nProblem 3\n\n\nMinimax:\n\n\n\nAlpha beta prunning\n\n\n"},"artificialIntelligence/Evaluation-by-rollouts---monte-carlo-tree-search":{"title":"Evaluation by rollouts - monte carlo tree search","links":[],"tags":[],"content":"what is rollout\n\n‚ÄùMove 37‚Äù in Go as example\nRepeat until terminal:\n\nPlay a move according to a fixed, fast rollout policy\n\n\nRecord the result\n‚áí Fraction of wins correlates with the true value of the position\nhaving a ‚Äúbetter - quick, better than random‚Äù roll out policy helps\n"},"artificialIntelligence/Expectimax-Search":{"title":"Expectimax Search","links":["artificialIntelligence/Markov-Decision-Processes---MDP"],"tags":["computerScience/AI-ML/optimization","computerScience/searchProblems","computerScience/gameTheory"],"content":"expectimax search\n\nWhy wouldn‚Äôt we know what the result of an action will be?\n\nExplicit randomness: rolling dice, tossing a coin\nUnpredictable opponents: the ghosts respond randomly  (teleport, etc)\nActions can fail: when moving a robot, wheels might slip\n\n\nValues should now reflect average-case (expectimax) outcomes, not worst-case (minimax) outcomes\nExpectimax search: compute the average score under optimal play (maximize what we get on average when playing many times)\n\nMax nodes as in minimax search\nChance nodes are like min nodes but the outcome is uncertain\nCalculate their expected utilities\nI.e. take weighted average (expectation) of children\noptimality? 50/50 chance ‚Üí not completely sure\nassumptions on the selection can be mismatched with the world\n\n\nformalize the underlying uncertain result problems as Markov Decision Processes - MDP\n\nexpectimax pseudocode\n\nexpectimax pseudocode\n\nexpectimax pruning\n\ncant do the same pruning, as there can be hugely large values dominating the others, affecting the expectation ‚Üí if prun ‚Üí misleading result\n\ndepth-limited expectimax\n\nas cant get to the bottom in the time we have ‚Üí stop at some move, use est of the value (approx evaluation function)\ndont need to go deep in the tree ‚Üí in a reasonable amount of time ‚Üí find approx answer to the top\n\nquiz - should we use expectimax\n\nquiz - what tree search to use\n\nproblems w expectimax\n\ninfinite horizons ‚Üí expectimax needs finite\nself-loop\nlarge search tree ‚Üí lots of computation\n"},"artificialIntelligence/Expectiminimax":{"title":"Expectiminimax","links":[],"tags":[],"content":"\n\nEnvironment is an extra ‚Äúrandom agent‚Äù player that moves after each min/max agent\nEach node computes the appropriate combination of its children\neg. backgammon\n"},"artificialIntelligence/Markov-Decision-Processes---MDP":{"title":"Markov Decision Processes - MDP","links":["artificialIntelligence/Expectimax-Search","artificialIntelligence/The-Bellman-Equation"],"tags":["Math/probability/markovChain","computerScience/AI-ML/RL"],"content":"Markov Decision Processes - MDP\nAn MDP is defined by:\n\n\nA set of states s ‚àà S\n\n\nA set of actions a ‚àà A\n\n\nA transition function T(s, a, s‚Äô)\n\nProbability that a from s leads to s‚Äô, i.e., P(s‚Äô| s, a)\nAlso called the model or the dynamics\n\n\n\nA reward function R(s, a, s‚Äô)\n\nSometimes just R(s) or R(s‚Äô)\n\n\n\nA start state\n\n\nMaybe a terminal state\n\n\nUsually denoted as tuple „ÄàS, A, T, R, ùõÑ„Äâ\n\n\nMarkov in MDP means action outcomes depend only on the current state (just like successor function of search)\n\n\nutilities of sequences\n\nmore reward, now ‚Üí values of rewards decay exponentially U‚ü∂P0‚Äã¬†+¬†Œ≥P1‚Äã¬†¬†+¬†Œ≥2P2‚Äã+‚ãØ\n\n\n\npolicies in MDP\n\nin deterministic single-agent search problems: want optimal plan / sequence of actions from start to goal\nin MDP: want optimal policy œÄ‚àó:S‚ÜíA\n\na policy p gives an action for each state\noptimal policy: maximize expected utility if followed (can have many optimal policies, but will receive same amt of rewards in the long run)\nexplicit policy defines a reflex agent\n\n\nexpectimax didnt compute entire policies\n\nonly the action for a single state\n\n\n\nexample\nConsider a simple MDP where an agent is navigating a gridworld. The states (S) are the cells of the grid, the actions (A) are the directions the agent can move (up, down, left, right), and the rewards are +1 for reaching the goal cell, -1 for hitting a trap, and -0.01 for each step to encourage the agent to reach the goal quickly.\nA policy in this case might be a simple rule like ‚Äúalways move towards the goal if possible, otherwise move randomly‚Äù. This policy gives an action for each state (each cell of the grid).\nAn optimal policy (ùõë*) would be the one that maximizes the expected utility. This might involve taking a longer path to avoid traps, for example.\nThe Expectimax algorithm could be used to decide the best action for a single state. For example, if the agent is in a particular cell, Expectimax could be used to decide whether it‚Äôs better to move up, down, left, or right, based on the expected utility of each action. However, Expectimax wouldn‚Äôt provide a policy for the other cells of the grid.\nMDP Search Tree\n\n link\nMDP search tree\n\nEach MDP state projects an expectimax-like search tree\n\n\nProblems\n\nRepeated states\nTree goes on forever\n‚áí The Bellman Equation\n\n\n"},"artificialIntelligence/Standard-Search-Formulation-of-CSPs":{"title":"Standard Search Formulation of CSPs","links":[],"tags":[],"content":"states defined by the values assigned so far (partial assignments)\n\ninitial state: empty assignment, {}\nsuccessor function: assign value to an unassigned variable\ngoal test: current assignment is complete and satisfies all constraints\n"},"artificialIntelligence/The-Bellman-Equation":{"title":"The Bellman Equation","links":[],"tags":["computerScience/AI-ML/RL"],"content":"Optimal Quantities\n\nThe value (utility) of a state s:\n\nV‚àó(s)=¬†maxa‚ÄãQ‚àó(s,a)=maxa‚Äã‚àës‚Ä≤‚ÄãT(s,a,s‚Ä≤)[R(s,a,s‚Ä≤)+Œ≥V‚àó(s‚Ä≤)]\nexpected utility starting in s and acting optimally\n\n\nThe value (utility) of a q-state (s,a)\n\nQ‚àó(s,a)=‚àës‚Ä≤‚ÄãT(s,a,s‚Ä≤)[R(s,a,s‚Ä≤)+Œ≥V‚àó(s‚Ä≤)]\nexpected utility starting out having taken action a from state s and (thereafter) acting optimally\n\n\nThe optimal policy:\n\nùùø*(s) = optimal action from state s\n\n\n\n\nTime limited values\n\ndefine Vk‚Äã(S) to be the optimal value of s if the game ends in k more time steps = what a depth-k expectimax give from s\n"},"artificialIntelligence/The-Waltz-Algorithm":{"title":"The Waltz Algorithm","links":[],"tags":[],"content":"what is The Waltz Algorithm\n\nearly computer vision algo - not how they do it now anymore\ninterpreting line drawing of solid polyhedra (ƒëa di·ªán) as 3D objects\nPose as CSP: each intersection is a variable, domain = {outtie, innie}. constraint if 2 things are connected, cannot have one convex, the other concave\n"},"artificialIntelligence/a*-search":{"title":"a* search","links":["artificialIntelligence/admissible-heuristics","artificialIntelligence/consistent-heuristics"],"tags":["computerScience/DSA/a-starSearch"],"content":"what is A* search\n\nUniform-cost orders by path cost, or backward cost g(n)\nGreedy orders by goal proximity, or forward cost h(n)\ncombination of UCS and greedy ‚Üí Orders by the sum of backward cost ( g(n) ) and forward cost ( h(n) ): (f(n)=g(n)+h(n)) ‚Üí A*\n\nA* search optimality\n\nTree search:\n\nA* is optimal if we have admissible heuristics, inadmissible (pessimistic) heuristic ‚Üí not optimal\nUCS is a special case (h=0)\n\n\nGraph search\n\nA* is optimal if we have consistent heuristics\nUCS optimal (h = 0 is consistent)\n\n\nconsistency implies admissibility\nmost natural admissible tend to be consistent, esp. in relaxed problems\n\nshould stop when enqueue a goal?\n\nNo, as it may not be the most optimal solution ‚Üí only stop when dequeue a goal\n\nA* vs other searches\n\na* vs ucs pic\nUCS: search widely just like BFS; in contours map: expand equally in all directions\nA*: zone in to search for optimal path (with good heuristic); in contours map: expand mainly toward the goal to ensure optimality\na* vs greedy vs ucs pic\n\nA* application\n\nVideo games\nPathing / routing problems\nResource planning problems\nRobot motion planning\nLanguage analysis\nMachine translation\nSpeech recognition\nGraph Matching\n"},"artificialIntelligence/admissible-heuristics":{"title":"admissible heuristics","links":["artificialIntelligence/manhattan's-distance"],"tags":["computerScience/DSA/a-starSearch","computerScience/AI-ML/optimization/a-starSearch"],"content":"what is heuristic\n\na heuristic (function) to speed up the process of finding optimal solution\neg. number of pancake out of order (pancake problem), number of titles misplaced (8 puzzle problem)\nan underestimation of the actual cost we will incur\n\nwhat is admissibility\n\nestimate how much cost from current state ‚Üí goal state\n\npessimistic &amp; optimistic heuristic\n\npessimistic / inadmissible heuristics break optimality by trapping good paths on the fringe, example\noptimistic / admissible heuristics slow down bad plans, but never outweigh true costs ‚Üí ensure A* optimality\n\nadmissible heuristics\n\na heuristic h is admissible (optimistic) if: 0‚â§h(n)‚â§h‚àó(n)\n\nh(n): heuristic function\nh‚àó(n) : actual cost to nearest goal\n\n\nexample: manhattan‚Äôs distance, pancake flipping (# of the largest pancake still out of place)\nmost of what involved in A* is brainstorming admissible heuristics\n\nwhy a-star tree search is optimal with admissible heuristic\nto prove optimality\n\nassume A is optimal goal node, B is suboptimal goal node, h is admissible\nProve: A will exit the fringe before B  = we will explore optimal node before suboptimal ones\n\nproof:\n\nimagine B on the fringe; ancestor n of A (or A itself) on the fringe\nclaim: n will be expanded before B\n\nf(n)‚â§f(A)\n\nthings to remember: n: a node on the path to A; A: goal node\nanalysis: As A is goal node, h(A)=0 ‚áî g(n)+h(n)‚â§g(A), or the total cost through n to the goal node is smaller or equal to the estimated cost through A to the goal node.\n\nThis is because g(n)‚â§g(A) (equal when n = A)\nh(n)‚â§h‚àó(n): or the heuristic through n to the goal node has to be smaller or equal to the actual cost through n to the goal node\n\n\n‚áîf(n)‚â§g(A)\n‚áîg(A)=f(A) as h(A)=0\n‚áîf(n)‚â§f(A)\n\n\nf(A)&lt;f(B)\n\ng(A)&lt;g(B): as A is optimal goal node, B is suboptimal goal node\nf(A)&lt;f(B):h=0 at both goal states\n\n\nn expands before B: as of 1 and 2 ‚áí f(n)‚â§f(A)&lt;f(B) ‚áí f(n)&lt;f(B)\n\n\nTherefore, all ancestors of A expand before B\nA expands before B\nA search with admissible heuristic* is optimal\n\ncreating admissible heuristics\n\ninadmissible heuristics are often useful (find fast solution)\nWay to ensure admissibility in heuristics: introduce new actions\n\ntake original problem ‚Üí add new actions ‚Üí in this hypothetical problem space, we find the optimal solution\nas this is hypothetical, there are more actions available ‚Üí optimal solution in this hypo space will be cheaper or same as in the real world\n‚áí often, admissible heuristics are solutions to relaxed problems, where new actions are available\n‚áí optimal solution in relaxed problem = admissible heuristic for real problem\n\n\nnote: A with heuristic is the trade-off between quality of estimate and work per node*\n\nas heuristic get closer to the true cost, you will expand fewer node (quality of estimate is better), yet we will have to do more work per node to compute the heuristic\n\n\n"},"artificialIntelligence/backtracking-search":{"title":"backtracking search","links":["artificialIntelligence/filtering-in-CSPs---forward-checking,-arc-consistency"],"tags":[],"content":"what is backtracking search\n\na type of DFS\nbasic uninformed algorithm for solving CSPs (dont have additional information about the state beyond its definition; doesnt know whether close to solution or not until finds one, or exhaust all possibilities)\n\n\nOne variable at a time\n\nÔªøÔªøVariable assignments are commutative (giao ho√°n) ‚Üí fix ordering\nÔªøÔªøI.e., [WA = red then NT = green] same as [NT = green then WA = red]\nÔªøÔªøOnly need to consider assignments to a single variable at each step\n\n\nCheck constraints as you go\n\nÔªøÔªøI.e. consider only values which do not conflict with previous assignments\nÔªøÔªøMight do some computation to check constraints\nÔªøÔªø‚ÄúIncremental goal test‚Äù\n\n\n\n\nÔªøÔªøCan solve n-queens for n = 25\npic - algorithm implementing backtracking\nBacktracking = DFS + variable-ordering + fail-on-violation\n\nimproving backtracking\n\ngeneral purpose idea (not like heuristics in A* - custom the the search problem) but give huge gains in speed\nOrdering\n\nvariable should be assigned next?\nvalues tried in what order?\n\n\nÔªøÔªøFiltering: Can we detect inevitable failure early? ‚Üí filtering in CSPs - forward checking, arc consistency\nÔªøÔªøStructure: Can we exploit the problem structure?\n"},"artificialIntelligence/breadth-first-search---bfs":{"title":"breadth-first search - bfs","links":[],"tags":[],"content":"note\n\nStrategy: expand a shallowest node first\nImplementation: fringe is a FIFO queue\nProperties:\n\nTime complexity: O(bs)\n\ns tiers ‚Üí there will be s nodes of b in the worst case time\n\n\nSpace complexity: O(bs)\nComplete: yes\nOptimal: only if costs are all 1\n\n\n\n\nBFS in CSPs\n\nchoose a node as root, then explore level by level\neg. level 0, tree node is WA, child node is WA = R, WA = G, WA = B\n\nlevel 1, child node is WA = R and SA = G, WA = G and NT = R, ‚Ä¶\n\n\nit falls into the worst case: explore the deepest level to find the solution\n"},"artificialIntelligence/consistent-heuristics":{"title":"consistent heuristics","links":[],"tags":[],"content":"consistent heuristics vs admissible heuristics\n\nnote: C is goal, A is node\nadmissibility: h(A)‚â§h‚àó(A)\nconsistency: heuristic arc cost ‚â§ actual cost for each arc: h(A)‚àíh(C)‚â§cost(AtoC)\npic of inconsistency\n\nas  h=1 at C ‚áí it should be h=2 at A\n\n\n\npurpose of consistency\n\nf-value along a path never decreases\n\nh(A)‚â§cost(AtoC)+h(C): from the definition of consistency\nf(A)=g(A)+h(A)‚â§g(A)+cost(AtoC)+h(C)=f(C): add backward cost\n\n\n"},"artificialIntelligence/constraint-graphs":{"title":"constraint graphs","links":[],"tags":[],"content":"what is CG\n\nbinary CSP: each constraints related (at most) 2 vars\nbinary CG: nodes are variables, arcs show constraints\ngeneral-purpose CSP algos use graph structure to speed up search\n\neg. Tasmania is independent subproblem\n\n\nCG only show there are constraints, dont tell what the constraints are\naustralia map constraint graph\n5x5 nqueens constraint graph\n\nconstraint Queen 1 btw A and B means that 1,1 not oke, 1,2 not oke, 1,3 oke and so on\n\n\n"},"artificialIntelligence/constraint-satisfaction-problems":{"title":"constraint satisfaction problems","links":[],"tags":[],"content":"standard search problems\n\nstate is a ‚Äúblack box‚Äù: arbitrary data structure\ngoal test: any function over states\nsuccessor function can be anything\n\nconstraint satisfaction problems\n\nspecial subset of search problems\nstate defined by variables Xi‚Äã, values from domain D (D sometimes depends on i)\nGoal test: set of constraints specifying allowable combination of values for subsets of variables\nsimple example of a formal representation language\nallows more power and useful general-purpose algorithms than standard search algos\n\nVarieties of CSP\n\nDiscrete Variables\n\nfinite domains:\n\nsize d means O(dn) complete assignments ‚Üí still bad\neg. boolean CSPs (including Boolean satisfiability - NP complete)\n\n\nInfinite domains (integers, strings, etc)\n\njob scheduling, variables are start/end times\nlinear constraints solvable, nonlinear undecidable\n\n\n\n\nContinuous variables\n\neg. start/end times for hubble telescope observations\nlinear constraints solvable in polynomial time by LP methods\n\n\n\nVarieties of Constraints\n\nÔªøÔªøUnary constraints involve a single variable (equivalent to reducing domains), e.g.:  SAÓÄ†=green\nÔªøÔªøBinary constraints involve pairs of variables, e.g: SAÓÄ†=WA\nÔªøÔªøHigher order constraints involve 3 or more variables: e.g., cryptarithmetic column constraints\nÔªøÔªøPreferences (soft constraints):\n\nÔªøÔªøE.g., red is better than green\nÔªøÔªøOften representable by a cost for each variable assignment\nÔªøÔªøGives constrained optimization problems\nÔªøÔªø(We‚Äôll ignore these until we get to Bayes‚Äô nets)\n\n\n\nreal world CSPs\n\nÔªøÔªøScheduling problems: e.g., when can we all meet?\nÔªøÔªøTimetabling problems: e.g., which class is offered when and where?\nÔªøÔªøAssignment problems: e.g., who teaches what class\nÔªøÔªøHardware configuration\nÔªøÔªøTransportation scheduling\nÔªøÔªøFactory scheduling\nÔªøÔªøCircuit layout\nÔªøÔªøFault diagnosis\nÔªøÔªø‚Ä¶ lots more!\n"},"artificialIntelligence/cost-sensitive-search":{"title":"cost-sensitive search","links":[],"tags":["computerScience/searchProblems"],"content":"note\n\npic\nBFS finds the shortest path in terms of number of actions\nDoes not find the least-cost path\nNeed to consider the cost of each action\n"},"artificialIntelligence/definition-of-an-agent":{"title":"definition of an agent","links":[],"tags":[],"content":"title\nnote\n\nAn agent is something that perceives its environment through sensors and acts upon that environment through actuators based on its agent function.\n"},"artificialIntelligence/depth-first-search---dfs":{"title":"depth-first search - dfs","links":[],"tags":["computerScience/searchProblems/dfs"],"content":"note\n\nStrategy: expand a deepest node first\nImplementation: fringe is a LIFO stack\nProperties:\n\nNodes DFS expand?\n\nSome left prefix of the tree\nCould process the whole tree\nIf m is finite, takes time (O(bm))\n\n\nTime complexity: (O(bm))\n\nb: branching factor (the average number of successors per state)\nm: maximum depth\nsearch has to explore the entire tree before finding a solution or concluding that none exists.\n\n\nSpace complexity: (O(bm))\n\nsearch stores nodes &amp; their siblings along path from root ‚Üí current node, with at most length is m\nat most number of siblings each level is b\n\n\nComplete: finite only if we prevent cycles\nOptimal: no. find the leftmost solution regardless of depth or cost\n\n\n\n\nwhen to use\n\ndetect cycles in a tree\n\nimplementation\n// Java program to print DFS traversal\n// from a given graph\nimport java.io.*;\nimport java.util.*;\n \n// This class represents a\n// directed graph using adjacency\n// list representation\nclass Graph {\n\tprivate int V;\n \n\t// Array of lists for\n\t// Adjacency List Representation\n\tprivate LinkedList&lt;Integer&gt; adj[];\n \n\t// Constructor\n\t@SuppressWarnings(&quot;unchecked&quot;) Graph(int v)\n\t{\n\t\tV = v;\n\t\tadj = new LinkedList[v];\n\t\tfor (int i = 0; i &lt; v; ++i)\n\t\t\tadj[i] = new LinkedList();\n\t}\n \n\t// Function to add an edge into the graph\n\tvoid addEdge(int v, int w)\n\t{\n\t\t// Add w to v&#039;s list.\n\t\tadj[v].add(w);\n\t}\n \n\t// A function used by DFS\n\tvoid DFSUtil(int v, boolean visited[])\n\t{\n\t\t// Mark the current node as visited and print it\n\t\tvisited[v] = true;\n\t\tSystem.out.print(v + &quot; &quot;);\n \n\t\t// Recur for all the vertices adjacent to this\n\t\t// vertex\n\t\tIterator&lt;Integer&gt; i = adj[v].listIterator();\n\t\twhile (i.hasNext()) {\n\t\t\tint n = i.next();\n\t\t\tif (!visited[n])\n\t\t\t\tDFSUtil(n, visited);\n\t\t}\n\t}\n \n\t// The function to do DFS traversal.\n\t// It uses recursive DFSUtil()\n\tvoid DFS(int v)\n\t{\n\t\t// Mark all the vertices as\n\t\t// not visited(set as\n\t\t// false by default in java)\n\t\tboolean visited[] = new boolean[V];\n \n\t\t// Call the recursive helper\n\t\t// function to print DFS\n\t\t// traversal\n\t\tDFSUtil(v, visited);\n\t}\n \n\t// Driver Code\n\tpublic static void main(String args[])\n\t{\n\t\tGraph g = new Graph(4);\n \n\t\tg.addEdge(0, 1);\n\t\tg.addEdge(0, 2);\n\t\tg.addEdge(1, 2);\n\t\tg.addEdge(2, 0);\n\t\tg.addEdge(2, 3);\n\t\tg.addEdge(3, 3);\n \n\t\tSystem.out.println(\n\t\t\t&quot;Following is Depth First Traversal &quot;\n\t\t\t+ &quot;(starting from vertex 2)&quot;);\n \n\t\t// Function call\n\t\tg.DFS(2);\n\t}\n}\n// This code is contributed by Aakash Hasija\n \nDFS in CSPs\n\nif the worst case is we have to find sth at the deepest level, DFS at least in some first attempts can reach the solution\n"},"artificialIntelligence/designing-rational-agents":{"title":"designing rational agents","links":["artificialIntelligence/definition-of-an-agent"],"tags":[],"content":"note\n\nan agent is an entity that perceives and acts\na rational agent: select actions maximizing its expected utility\nCharacteristics of the percepts, environment, and action space dictate techniques for selecting rational actions\n\n\n\n\n"},"artificialIntelligence/deterministic-games":{"title":"deterministic games","links":[],"tags":[],"content":"Many possible formalizations, one is:\n\nStates: S (start at s0)\nPlayers: P={1‚Ä¶N} (usually take turns)\nActions: A (may depend on player / state)\nTransition Function: S x A ‚Üí S\nTerminal Test: S ‚Üí {t,f}\nTerminal Utilities: S x P ‚Üí R\n\nSolution for a player is a policy: S ‚Üí A"},"artificialIntelligence/examples-of-constraint-satisfaction-problems":{"title":"examples of constraint satisfaction problems","links":[],"tags":[],"content":"eg of CSP: map coloring\n\npic of map in australia\nVariables: different states (WA, NT, Q, NSW, V, SA, T)\nDomains: values to assign, D = {red, green, blue}\nConstraints: adjacent regions must have different colors\n\nimplicit: WAÓÄ†=NT\nexplicit: (WA,NT)‚àà(red,green),(red,blue)...\n\n\nSolutions: assignments satisfying constraints\n\neg of CSP: n-queens\n\nintro: have chessboard of square size, must place queens on the board so that nobody is threatening others\nformulation 1 - nqueens\n\nvariables: Xij‚Äã the squares = 4 x 4 = 36\ndomains: {0, 1}, for not queen and queen\nconstraint: ‚Ä¶\n\n\nformulation 2 - nqueens\n\neg of CSP. cryptarithmetic\n\ncryptarithmetic vars, domains, constraints, and CG\nX1‚Äã,X2‚Äã,X3‚Äã: carry bit\nalldiff(): all have to be different\n\neg of CSP. sudoku\n\nsudoku vars, domains, constraints\n\nanother constraints: fill the missing number adhering to the prefilled numbers\n\n\n"},"artificialIntelligence/filtering-in-CSPs---forward-checking,-arc-consistency":{"title":"filtering in CSPs - forward checking, arc consistency","links":[],"tags":[],"content":"filtering:\n\nkeep track of domains for unassigned variables, cross off bad options\n\nforward checking\n\na way of filtering\ncross off values violating constraint when added to existing assignment\nprocess of forward checking aus map\nprevent the generation of paths leading to a dead-end in the search tree ‚Üí more efficient than simple backtracking\n\nconstraint propagation\n\npropagates info from assigned to unassigned vars\ndoesnt provide early detection for all failures (checking btw unassigned and unassigned vars)\nreason from constraint to constraint\n\narc consistency\n\nan arc is just an edge with direction ‚áí an edge means 2 arcs to check ‚áí we can check satisfaction in 2 different directions\narc consistency = all arcs are consistence\nconceptually, can check an arc between 2 things not connected by a constraint\narc is consistent = no constraint violation along the arc ‚áí for 1 thing in the tail, there is at least one OK option in the head\nif violating ‚áí delete from the TAIL\nevery time deleting from a domain, arcs declared consistent pointing into it, is now questionable again\n‚áí dont have to backtrack as much as forward checking, as it detects failure earlier\ndisadvantage:\n\nbad runtime\nconvergence\n\n\ntrade off between making the core search run faster &amp; doing more filtering\nAC3: algo to enforce arc consistency in a CSP\n\nlimitation after enforcing arc consistency:\n\ncan have 1 solution/multiple solutions/no solution left\narc consistency runs inside a backtracking search\n\ndifference btw arc consistency and forward checking\n\nforward checking check constraints between current and future variables; arc consistency checks constraints between unassigned variables\nFC is faster to perform than AC\n\nK-consistency\n\n\n"},"artificialIntelligence/fringe-strategy---the-one-queue":{"title":"fringe strategy - the one queue","links":[],"tags":[],"content":"what is fringe strategies\n\nall search algorithm are the same, except for fringe strategies\n\nFringe Strategies: Each search algorithm systematically builds a search tree and chooses an ordering for the fringe. The difference lies in how they prioritize or order these unexplored nodes\nimplemented with priority queues\nPractically, for DFS and BFS, you can avoid the log(n) overhead from an actual priority queue, by using stacks and queues\nCan even code one implementation that takes a variable queuing object\n\n\n"},"artificialIntelligence/graph-search":{"title":"graph search","links":["artificialIntelligence/consistent-heuristics"],"tags":[],"content":"problem with search tree\n\nit is prone to expand repetitive nodes, pic\ngraph search ‚Üí keep track of list of expanded nodes, not expand them again\n\ngraph search\n\nIdea: never expand a state twice\nImplementation:\n\nTree search + set of expanded states (‚Äúclosed set‚Äù)\nloop through every node in the tree\n\nif its state was expanded before ‚Üí skip it\nif new ‚Üí add to the ‚Äúclosed set‚Äù\n\n\n\n\nImportant: store the closed set as a set, not a list (sets, in many languages like python, are implemented as hash tables ‚Üí faster look up time than list)\nCompleteness? Yes, as we just remove the repetition in the search tree, so basically nodes all are searched, but not repeated\nOptimal? Maybe not\n\nonly optimal if we already searched the optimal states, then when searching others, we remove the stated searched. else, we may never optimally searched\nexample of a* graph search gone wrong\nunderlying issue? poor choice of heuristic ‚Üí misled us to the suboptimal path ‚Üí we need more than admissible heuristic ‚áí consistent heuristics\n\n\n"},"artificialIntelligence/greedy-search":{"title":"greedy search","links":[],"tags":[],"content":"what is greedy search\n\nStrategy: expand a node that you think is closest to a goal state, dont care about the cost\n\nHeuristic: estimate of distance to nearest goal for each state\n\n\nA common case:\n\nBest-first takes you straight to the (wrong) goal\n\n\nWorst-case: like a badly-guided DFS\n\n"},"artificialIntelligence/iterative-deepening":{"title":"iterative deepening","links":[],"tags":[],"content":"what is iterative deepening\n\nIdea: get DFS‚Äôs space advantage with BFS‚Äôs time / shallow-solution advantages\nRun a DFS with increasing depth limit\nNot wastefully redundant, most work in lowest level\nProperties:\n\nTime complexity: (O(bs))\nSpace complexity:  (O(bs))\nComplete: yes\nOptimal: only if costs are all 1\n\n\nvisualization\n"},"artificialIntelligence/k-consistency":{"title":"k-consistency","links":[],"tags":[],"content":"1-consistency - node consistency\n\nIncreasing degrees of consistency\n\n1-Consistency (Node Consistency): Each single node‚Äôs domain has a value which meets that node‚Äôs unary constraints (constraint on 1 variable\n\neg. node A,B,C can take a value in {1,2,3,4,5}, and A&gt;1 ‚áí A‚àà{2,3,4,5} will make A consistent\n\n\n2-Consistency (Arc Consistency): For each pair of nodes, any consistent assignment to one can be extended to the other\n\neg. given constraint AÓÄ†=B. if we assign the value 1 to A (A=1), we can find a value for B (B=2 or 3 or 4 or 5) that satisfies the constraint AÓÄ†=B, and vice versa, there is a value in A‚Äôs domain that satisfies the constraint AÓÄ†=B\n‚áí arc from A to B is consistent. same for B to C and C to A\n\n\nK-Consistency: For each k nodes, any consistent assignment to k-1 can be extended to the k-th node.\n\nif we assign the values 1 and 2 to A and B respectively (A=1, B=2), we can find a value for C (C=3) that satisfies the constraints A ‚â† C and B ‚â† C. Therefore, the set of nodes {A, B, C} is 3-consistent.\n\n\n\n\nHigher k more expensive to compute\n\nmust check more combinations of assignments\nis easier to find a solution (they eliminate inconsistency)\n\n\n(You need to know the k=2 case: arc consistency)\n"},"artificialIntelligence/learning-agents":{"title":"learning agents","links":[],"tags":[],"content":"title\nnote\n\nLearning agents are capable of learning from their experiences, which allows them to improve their performance and adapt to changing environments.\nA learning agent can be divided into four conceptual components: a learning element, a performance element, a problem generator, and a critic.\n"},"artificialIntelligence/manhattan's-distance":{"title":"manhattan's distance","links":[],"tags":[],"content":"what is manhattan‚Äôs distance\n\nthe shortest distance between 2 points, following the grid lines\nalso called sum of absolute distance\n‚à£x1‚Äã‚àíx2‚Äã‚à£+‚à£y1‚Äã‚àíy2‚Äã‚à£: the absolute differences in the x-coordinates and the y-coordinates of the two points\neg. as a taxi driver, The Manhattan distance is the shortest distance you can drive from one point to another, following the streets\n"},"artificialIntelligence/models":{"title":"models","links":[],"tags":["computerScience/AI-ML/machineLearning","computerScience/AI-ML/AI/model"],"content":"note\n\nalmost always wrong but some are useful\n"},"artificialIntelligence/monte-carlo-tree-search":{"title":"monte carlo tree search","links":["artificialIntelligence/Evaluation-by-rollouts---monte-carlo-tree-search"],"tags":[],"content":"MCTS\n\ndeveloped for the purpose of playing Go, with large branching factor b &gt; 300\nalpha beta search assume a fixed horizon can reach ~ b &gt; 4\ncombine 2 important ideas:\n\nEvaluation by rollouts - monte carlo tree search ‚Äì play multiple games to termination from a state s (using a simple, fast or random policy) and count wins and losses\n\nwin a lot: state s is good, else, is bad\n\n\nSelective search ‚Äì explore parts of the tree that will help improve the decision at the root, regardless of depth\n\nabandon the idea of fixed horizon\n\n\n\n\n\nMCTS version 0\n\nDo N rollouts from each child of the root, record fraction of wins\nPick the move that gives the best outcome by this metric\nmcts v0\nproblem with mcts v0\n\nkeep searching even though we know that‚Äôs a bad move ‚Üí 0/10\n\n\n\nMCTS version 0.9\n\nallocate rollouts to more promising &amp; uncertain nodes\n\na tradeoff btw promising and uncertain\n\n\nMCTS version 0.9\n\nUpper Confidence Bounds - UCB heuristics\n\nUCB1 formula combines ‚Äúpromising‚Äù and ‚Äúuncertain‚Äù\n\nUCB1(n)=N(n)U(n)‚Äã+C√óN(n)logN(PARENT(n))‚Äã‚Äã\n\n\nN(n) = number of rollouts from node n\nU(n) = total utility of rollouts (e.g., # wins) for Player(Parent(n))\n\nKeep track of both for each node N(n)\n\n\nC: constant, depending on the stage of the game\n\nMCTS version 2.0: Upper Confidence of Trees - UCT\n\nRepeat until out of time:\n\nSelection: recursively apply UCB to choose a path down to a leaf node n  (i.e. from parent ‚Üí choose child ‚Üí grandchild ‚Üí ‚Ä¶ ‚Üí leaf node)\nExpansion: add a new child c to n\nSimulation: run a rollout from c\nBackpropagation: update U and N counts from c back up to the root\n\n\nChoose the action leading to the child with highest N\npic - UCT example\n\nwhy no min max\n\n‚ÄúValue‚Äù of a node, U(n)/N(n), is a weighted sum of child values!\nIdea: as N ‚Üí ‚àû, the vast majority of rollouts are concentrated in the best child(ren), so weighted average ‚Üí max/min\nTheorem: as N ‚Üí ‚àû selects the minimax move\n\n(but N never approaches infinity!)\n\n\n"},"artificialIntelligence/multi-agent-utilities":{"title":"multi-agent utilities","links":[],"tags":[],"content":"\n\nWhat if the game is not zero-sum, or has multiple players?\nGeneralization of minimax:\n\nTerminals have utility tuples\nNode values are also utility tuples\nEach player maximizes its own component\nCan give rise to cooperation and competition dynamically‚Ä¶\n\n\n\n"},"artificialIntelligence/options-to-design-an-AI-agent":{"title":"options to design an AI agent","links":[],"tags":[],"content":"note\n\nThink/act as human\n\nHuman cognition and behavior\nLimitations and irrationality\n\n\nThink/act rationally\n\nGoal-oriented and utility-maximizing\nDecision-making process and outcomes\n\n\n"},"artificialIntelligence/ordering-in-CSPs---minimum-remaining-values,-least-constraining-value":{"title":"ordering in CSPs - minimum remaining values, least constraining value","links":["tags/computerScience/AI-ML/CSPs","tags/fc"],"tags":["computerScience/AI-ML/CSPs","fc"],"content":"Context\n\nTime: 06 04 2024 - 22:32\nTags:CSPs\nChild:\nSource:\n\nMinimum Remaining Valuesfc\n\nproblem in improving backtracking: which variable should be assigned next? ‚Üí MRV\ndefinition: choose variable with minimum legal values left in its domain\n\nalso called ‚Äúmost constrained variable‚Äù or ‚Äúfail-fast‚Äù ordering\n\n\n\nLeast constraining valuefc\n\nproblem in improving backtracking: in what order should the variable‚Äôs values be tried? ‚Üí LCV\ndefinition: choose the least constraining value (the one that rule out fewest values in the remaining variables)\n\nmight take computation: eg. rerunning filtering\n\n\n"},"artificialIntelligence/pancake-problem":{"title":"pancake problem","links":[],"tags":[],"content":"note\n\npic\npic - tree search to get solution to pancake problem\n\ninitialize the search tree, initial state in the fringe\nloop to explore nodes in the fringe\n\nif the initial state is not the goal state\n\nif there are no candidates can be added to the fringe ‚Üí return failure\nelse: choose a leaf node, expand on strategy\nif node contains a goal state ‚Üí return solution\n\n\n\n\n\n\ntotal space graph is 4! = 4 (ways to choose the bottom layer) * 3 (ways to choose 3rd layer) * 2 (ways to choose 2nd layer) * 1 (way to choose the top layer) = 24\nAction and Cost: Flipping pancakes with a cost associated with the number of pancakes flipped.\nPath to Goal: Sequence of flips leading to the goal with a total cost.\n\nheuristic: # of largest pancake still out of place\n\n"},"artificialIntelligence/planning-agent":{"title":"planning agent","links":[],"tags":[],"content":"note\n\n\ndecide based on evaluating consequences of actions\n\n\nMust have a model of how the world evolves in response to actions\n\n\nMust formulate a goal (test)\n\n\nConsider how the world WOULD BE\n\n\nTypes:\n\nOptimal vs Complete planning\nPlanning vs Replanning\n\n\n"},"artificialIntelligence/probabilities,-for-search-in-AI":{"title":"probabilities, for search in AI","links":[],"tags":[],"content":"prob\n\nA random variable represents an event whose outcome is unknown\nA probability distribution is an assignment of weights to outcomes\nExample: Traffic on freeway\n\nRandom variable: T = whether there‚Äôs traffic\nOutcomes: T in {none, light, heavy}\nDistribution: P(T=none) = 0.25, P(T=light) = 0.50, P(T=heavy) = 0.25\n\n\nSome laws of probability (more later):\n\nProbabilities are always non-negative\nProbabilities over all possible outcomes sum to one\n\n\nAs we get more evidence, probabilities may change:\n\nP(T=heavy) = 0.25, P(T=heavy | Hour=8am) = 0.60\nWe‚Äôll talk about methods for reasoning and updating probabilities later\n\n\n\nexpectation\n\nprobability * outcome\nThe expected value of a function of a random variable is the average, weighted by the probability distribution over outcomes\n\nwhat probability to use\n\nIn expectimax search, we have a probabilistic model of how the opponent (or environment) will behave in any state\n\nModel could be a simple uniform distribution (roll a die)\nModel could be sophisticated and require a great deal of computation\nWe have a chance node for any outcome out of our control: opponent or environment\nThe model might say that adversarial actions are likely!\n\n\nFor now, assume each chance node magically comes along with probabilities that specify the distribution over its outcomes\n"},"artificialIntelligence/quiz-2-AI":{"title":"quiz 2 AI","links":[],"tags":[],"content":"problem 2:\n\nfalse\n\nif all cost is not negative\n\n\nfalse\ntrue\ntrue\nfalse\ntrue\n\nucs is a star w heuristic 0\n\n\n\nproblem 3:\n\nA\nA\nC\nproblem 4:\nA\nA\nC\n"},"artificialIntelligence/reflex-agent":{"title":"reflex agent","links":[],"tags":[],"content":"note\n\nChoose action based on current percept (and maybe memory)\nMay have memory or a model of the world‚Äôs current state\nNo consideration of future consequences\nConsider how the world IS\nSimple and fast, but limited and suboptimal\n"},"artificialIntelligence/search-algorithm":{"title":"search algorithm","links":[],"tags":["computerScience/searchProblems"],"content":"Properties of search algorithm\n\ncomplete: guaranteed to find a solution if one exists?\noptimal: guaranteed to find least cost path?\ntime complexity?\nspace complexity?\npic\nSystematically builds a search tree\nChooses an ordering of the fringe (unexplored nodes)\nOptimal: finds least-cost plans\n\nCartoon of search tree:\n\nb: branching factor\nm: maximum depth\ns: depth of shallowest solution\nC*: cost of cheapest solution\nùú∫: minimum arc cost\nNumber of nodes in entire tree: 1+b+b2+‚ãØ+bm=O(bm)\n"},"artificialIntelligence/search-heuristics":{"title":"search heuristics","links":[],"tags":[],"content":"what is a heuristic\n\nHeuristic Function: Estimates how close a state is to a goal, designed for specific search problems; a direction among multiple directions presented, to give a sense of the shortest path to the goal\nExamples: Manhattan distance (Manhattan(x1,y1,x2,y2)=‚à£x1‚àíx2‚à£+‚à£y1‚àíy2‚à£), Euclidean distance for pathing\npic - wo heuristic\npic - w heuristic: heuristic: the number of the largest pancake that is still out of place\nP(v) = dist(v) + h(v)\n\npriority for PQ = dist + heuristic ‚Üí total path length ‚Üí have to minimize this\n\n\n\n\nstart node: 90\n\n\n"},"artificialIntelligence/search-methods-for-CSPs":{"title":"search methods for CSPs","links":["artificialIntelligence/breadth-first-search---bfs","artificialIntelligence/depth-first-search---dfs","artificialIntelligence/backtracking-search"],"tags":[],"content":"BFS\n\nBFS in CSPs\n\nDFS\n\nDFS in CSPs\n\nNaive search\n\ndo all the assignments, then at the end discover it does not work ‚Üí backtrack\n\nBacktracking search\n\nbacktracking search\n"},"artificialIntelligence/search-problems":{"title":"search problems","links":["artificialIntelligence/state-space","artificialIntelligence/models"],"tags":["computerScience/searchProblems"],"content":"note\n\nA search problem consists of:\n\nstate space: set of possible configurations\nSuccessor function: transitions between states (with actions, costs)\nStart state and goal test\n\n\nSolution: sequence of actions (plan) transforms start state ‚Üí goal state\nSearch: find a solution if it exists\nSearch problem:\n\nmodels that abstract away the details of the environment\ncan have different state space sizes depending on the level of abstraction\nalmost always wrong but some are useful\n\n\n\n"},"artificialIntelligence/search-tree":{"title":"search tree","links":[],"tags":["computerScience/searchProblems/searchTree","computerScience/DSA/tree"],"content":"note\n\nA ‚ÄúWhat if‚Äù tree of plans (paths) in the state space graph\nStart state is the root node\nChildren correspond to successors\nNodes show states, but correspond to plans\nProblems:\n\nFor most problems, can never build the whole tree\nConstruct the tree on demand\n\n\n\n"},"artificialIntelligence/semi-lattice-of-heuristics":{"title":"semi-lattice of heuristics","links":["artificialIntelligence/semi-lattice-structure"],"tags":[],"content":"what is semi-lattice structure, comparison with tree\n\nsemi-lattice structure\n\npurpose of semi-lattice of heuristic\n\nunderstand relationships between different heuristics\nguide the selection of the most appropriate heuristics\npic of semi-lattice of heuristic\n\ncomparing dominance\n\nto see if 1 heuristic is dominant than the other\nDominance: ha‚Äã‚â•hc‚Äã if:\n\n‚àÄn:ha‚Äã(n)‚â•hc‚Äã(n)\nthis can tell us if both h(a) and h(c) is admissible (never overestimate the true cost), h(a) is better as it is closer to the actual cost ‚áí more efficient search\nnot all heuristic can be compared this way, sometimes they have lower and higher node, and can be in the same ranking\n\n\n\nbetter heuristics formed from 2 heuristics\n\nif have 2 heuristics, compare dominate btw them, and take the max ‚áí the max will be admissible and informative than either of these 2\nh(n)=max(ha‚Äã(n),hb‚Äã(n))\n"},"artificialIntelligence/semi-lattice-structure":{"title":"semi-lattice structure","links":[],"tags":[],"content":"what is semi-lattice structure, comparison with tree\n\npic of semi-lattice structure vs tree\n\n\nParent Nodes: In a tree, each node (except the root) has exactly one parent. This means there‚Äôs a single path from the root to any node.¬†In a semi-lattice, a node can have more than one parent, allowing for multiple paths from the root to a node\n\n\n\n\nStructure: A tree has a hierarchical structure, with each level representing a ‚Äúgeneration‚Äù of nodes. A semi-lattice doesn‚Äôt have this strict hierarchy and allows for more complex relationships between nodes\n\n\n\n\nReal-world analogy: A tree is like a family tree where each person has exactly one biological mother and one biological father. A semi-lattice is more like a network of roads in a city, where there are many different routes from one location to another\n\n\nMathematical Definition: A semi-lattice is a mathematical structure where any two elements have a greatest lower bound. This is not necessarily the case in a tree.\n"},"artificialIntelligence/state-space-graph-vs-search-tree":{"title":"state space graph vs search tree","links":[],"tags":["computerScience/searchProblems/searchTree","computerScience/searchProblems/stateSpace"],"content":"SSG vs ST\n\n\nNode in ST = entire path in SSG\n\n\na graph without a cycle = a tree\na graph with a cycle = an infinite tree\n\n\n"},"artificialIntelligence/state-space-graph":{"title":"state space graph","links":[],"tags":["computerScience/searchProblems/stateSpace"],"content":"State space graph\n\nMathematical representation of a search problem\n\nNodes: abstracted world configurations\nArcs: successors (action results)\n\n\nGoal test: set of goal node(s)\nIn a state space graph, each state occurs only once\nProblem: Too big to build in memory, but useful\n\n\n"},"artificialIntelligence/state-space":{"title":"state space","links":[],"tags":["computerScience/searchProblems/stateSpace"],"content":"definition\n\n\nWorld state: every detail of the environment\n\n\nSearch state: only relevant details for planning (abstraction)\n\n\nTrade-off between expressiveness and tractability\n\n\nexample:\n\n\n\n\n\nstate space size\n\nState space size: number of possible search states\nexample\n\n\n\n\n\n"},"artificialIntelligence/the-dangers-of-optimism-and-pessimism-in-model-assumptions":{"title":"the dangers of optimism and pessimism in model assumptions","links":[],"tags":[],"content":"\n\ndangerous optimism: assuming chance when the world is adversarial\ndangerous pessimism: assuming worst case when its not likely\n\nassumptions vs reality\n\nadversarial ghost &amp; minimax pacman = perfect combination\npic - adversarial ghost vs random ghost &amp; minimax pacman vs expectimax pacman\n\n"},"artificialIntelligence/the-different-approached-to-AI":{"title":"the different approached to AI","links":[],"tags":[],"content":"title\nnote\n\nThere are four main approaches to AI: acting humanly, thinking humanly, thinking rationally, and acting rationally.\nThe rational agent approach has been the most common as it involves creating agents that act so as to achieve the best outcome or the best expected outcome.\n"},"artificialIntelligence/the-importance-of-AI":{"title":"the importance of AI","links":[],"tags":[],"content":"title\nnote\n\nArtificial Intelligence (AI) is a significant field because it enables machines to mimic human intelligence.\nAI is a broad field that includes various subfields such as\n\nlearning,\nreasoning,\nperception,\nnatural language processing,\nand more.\n\n\n"},"artificialIntelligence/the-structure-of-agents":{"title":"the structure of agents","links":[],"tags":[],"content":"title\nnote\n\nAgents can be grouped into five classes based on the nature of their environment and how they operate: simple reflex agents, model-based reflex agents, goal-based agents, utility-based agents, and learning agents.\n"},"artificialIntelligence/tree-search-algorithm":{"title":"tree search algorithm","links":[],"tags":["computerScience/DSA/tree","computerScience/searchProblems/searchTree"],"content":"Search algorithm\n\nExpand out potential plans (tree nodes)\nMaintain a fringe (storage) of partial plans under consideration\nExploration strategy: Try to expand as few tree nodes as possible\n\nGeneral Tree Search\n\n\nMain questions:\n\nWhich leaf node to expand next\nWhether to check for repeated states\nData structures for frontier, expanded nodes\n\n\n"},"artificialIntelligence/uniform-cost-search---ucs":{"title":"uniform cost search - ucs","links":[],"tags":[],"content":"what is uniform cost search\n\nStrategy: expand a cheapest node first\nImplementation: fringe is a priority queue (priority: cumulative cost)\nProperties: (if the solution cost C* and arc costs at least ùú∫ ‚Üí effective depth is roughly C*/ùú∫\n\nTime complexity: \\\\(O(b^{C*/ùú∫})\\\\)\nSpace complexity: \\\\(O(b^{C*/ùú∫})\\\\)\nComplete: yes (if C* and ùú∫ are finite and positive)\nOptimal: yes\n\n\nvisualization\npic\nGood?\n\ncomplete &amp; optimal\n\n\nBad?\n\nexplore options in every direction\nno info about goal location\n\n\n"},"artificialIntelligence/utility-of-sequences-in-MDP":{"title":"utility of sequences in MDP","links":[],"tags":[],"content":"discounting of rewards\n\n\nmaximize rewards now ‚áí values of rewards decay exponentially\n\n\n\n\n\nU=R0‚Äã+Œ≥R1‚Äã+Œ≥2R2‚Äã+‚ãØ\n\n\nHow to discount?\n\nEach time we descend a level, we multiply in the discount once\n\n\n\nWhy discount?\n\nHelps our algorithms converge\nUncertainty about the future may not be fully represented\nIf the reward is financial, immediate rewards may earn more interest than delayed rewards\nAnimal/human behaviour shows preference for immediate reward\n\n\n\nInfinite Utilities: solution to game lasting forever, resulting in infinite rewards (esp when rewards are positive):\n\nfinite horizon (similar to depth-limited search)\n\nTerminate episodes after a fixed T steps (e.g. life)\n\nFor example, if we‚Äôre modeling a robot‚Äôs actions in a warehouse, we might decide to only look 100 steps into the future\nThe utility of a state is then the sum of the rewards for the next 100 steps.\n\n\nGives non-stationary policies (ùùø depends on time left)\n\nwhen using finite horizon ‚Üí policies become non-stationary (can change over time)\neg. when using finite horizon of 100 steps\n\nEarly in the horizon, it prioritizes actions that lead to long-term rewards (e.g., reaching distant packages).\nAs the horizon approaches, it becomes more focused on immediate rewards (e.g., delivering nearby packages).\n\n\n\n\n\n\nDiscounting:\n\nuse 0&lt;Œ≥&lt;1\nU([r0‚Äã,‚ãÖ‚ãÖr‚àû‚Äã])=‚àët=0‚àû‚ÄãŒ≥trt‚Äã‚â§Rmax/(1‚àíŒ≥)\n\n\nAbsorbing state:\n\nguarantee that for every policy, a terminal state will eventually be reached (like ‚Äúoverheated‚Äù for racing)\n\n\n\n\n"},"artificialIntelligence/what-is-AI":{"title":"what is AI","links":["The-Turing-Test"],"tags":[],"content":"title\nnote\n\nAI has been defined in various ways, including thinking like a human, acting like a human, thinking rationally, and acting rationally.\nThe Turing Test, proposed by Alan Turing, is a method of measuring a machine‚Äôs ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human.\n"},"artificialIntelligence/zero-sum-games":{"title":"zero sum games","links":[],"tags":[],"content":"Zero-Sum Games\n\nAgents have opposite utilities (values on outcomes)\nLets us think of a single value that one maximizes and the other minimizes\nAdversarial, pure competition\nthe total sum is always 0 (the lose of someone is the gains of the others)\n\nGeneral Games\n¬ß Agents have independent utilities (values on outcomes) ¬ß Cooperation, indifference, competition, and more are all possible ¬ß More later on non-zero-sum games"},"comOrg/***comOrg-map":{"title":"***comOrg map","links":["comOrg/translators---assembler-+-compiler-+-interpreter","comOrg/instruction-set-architecture-(ISA)","comOrg/moore's-law","comOrg/base10---decimal,-base2---binary,-base16---hexadecimal","comOrg/negative-numbers-_-sign-magnitude-+-twos-complement-+-sign-extension--and--truncation","comOrg/transistors-_-n-type-and-p-type","comOrg/cmos-notation","comOrg/logic-gates","comOrg/universal-gates-_-nand-+-nor","comOrg/hide-complexity-in-logic-gates-through-abstraction","comOrg/multiplexer---MUX","comOrg/logic-symbols--and--notation","comOrg/logic-implementation-_-from-truth-tables-to-logic-circuits","comOrg/Combinational-circuits","comOrg/equality-comparators-using-XOR","comOrg/2-to-1-MUX","comOrg/4-to-1-MUX","comOrg/decoder","comOrg/encoder","comOrg/1-bit--and--4-bit-full-adder","comOrg/overflow","comOrg/binary-subtraction","comOrg/4-bit-adder-OR-subtractor","tags/toProceed","comOrg/shifters","comOrg/Arithmetic-Logic-Unit---ALU","comOrg/numbers-with-fractions-in-computer","comOrg/Sequential-circuits","comOrg/clock-in-sequential-circuit","Finite-State-Machine","comOrg/Moore-machine","comOrg/Mealy-machine","comOrg/State-diagram","comOrg/level-of-languages-in-computer","comOrg/instruction-processing","comOrg/RISC-V","comOrg/User-level-ISA","comOrg/RISC-V-registers","comOrg/Instruction-Types--and--RISC-V-Instruction-Types","R-Type-1:-arithmetic-and-logic","R-Type-2:-shift-instructions"],"tags":["computerArchitecture","toProceed"],"content":"comOrg map\nLecture 1\n\ntranslators - assembler + compiler + interpreter\ninstruction set architecture (ISA)\nmoore‚Äôs law\nbase10 - decimal, base2 - binary, base16 - hexadecimal\nnegative numbers _ sign-magnitude + twos-complement + sign extension &amp; truncation\n\nLecture 2\n\ntransistors _ n-type and p-type\ncmos notation\nlogic gates\nuniversal gates _ nand + nor\nhide complexity in logic gates through abstraction\nmultiplexer - MUX\nlogic symbols &amp; notation\nlogic implementation _ from truth tables to logic circuits\n\nLecture 3\n\nCombinational circuits\nequality comparators using XOR\nmultiplexer - MUX\n\n2-to-1 MUX\n4-to-1 MUX\n\n\ndecoder\nencoder\n\nLecture 4: Binary Arithmetic\n\n1 bit &amp; 4 bit full adder\noverflow\nbinary subtraction\n4 bit adder OR subtractortoProceed\nshifterstoProceed\nArithmetic Logic Unit - ALU\nnumbers with fractions in computer\n\nLecture 5: Sequential Logic\n\nSequential circuits\n\nclock in sequential circuit\n\n\n\nLecture 6: Finite State Machines\n\nFinite State Machine\n\nMoore machine\nMealy machine\n\n\nState diagram\nstate encoding:\n\nBinary encoding:\n\nN states need log2‚ÄãN FFs\nEg: S0 = 00, S1 = 01, S2 = 10, S3 = 11\ntables\n\nstate transition\n\n\n\n\nbinary encoding\n\n\n\n\nmin term table ‚áí minterms ‚áí shorten, if possible\n\n\n\n\ncircuit\n\n\n\n\nOne-hot encoding\n\nEach state has 1 flip flop, Q of 1 FF = 1, Q of others = 0\nEg:             Q3 Q2 Q1 Q0\n\nS0 =   0    0    0    1\nS1 =    0    0    1    0\nS2 =    0    1    0    0\nS3 =    1    0    0    0\n\n\n\ncircuit\n\n\n\n\n\nLecture 8+9: RISC-V ISA\n\nlevel of languages in computer\nnumber of assembly languages: many, each processor need 1\nsimilar to number of C (?)\nRV32I - calc integers\nRV64F - calc float\ninstruction processing\nRISC-V\nUser level ISA\nRISC-V registers\nInstruction Types &amp; RISC-V Instruction Types\n\nR-Type 1: arithmetic and logic\nR-Type 2: shift instructions\n\n\n"},"comOrg/1-bit--and--4-bit-full-adder":{"title":"1 bit & 4 bit full adder","links":[],"tags":[],"content":"what is 1 bit full adder\n\n\n\nwhat is 4 bit full adder\n\n\n"},"comOrg/2-to-1-MUX":{"title":"2-to-1 MUX","links":[],"tags":[],"content":"note\n\n1 S: select input\n(Y=S‚Ä≤‚àóI0+S‚àóI1)\nwhen S = 0 ‚Üí Y = I0\nwhen S = 1 ‚Üí Y = I1\n\n"},"comOrg/4-bit-adder-OR-subtractor":{"title":"4 bit adder OR subtractor","links":[],"tags":[],"content":"what is 4 bit adder / subtractor\n\n\n\n"},"comOrg/4-to-1-MUX":{"title":"4-to-1 MUX","links":[],"tags":[],"content":"note\n\n2 S (select inputs)\n\neg. 8to1 MUX ‚Üí 3S, 16to1 MUX ‚Üí 4S\n\n\nY=S1‚Ä≤.S0‚Ä≤.I0+S1‚Ä≤.S0.I1+S1.S0‚Ä≤.I2+S1.S0.I3\n\n"},"comOrg/Arithmetic-Logic-Unit---ALU":{"title":"Arithmetic Logic Unit - ALU","links":[],"tags":[],"content":"what is ALU\n\nCombinational logic circuit that combines a variety of operations into a single unit\n\ncommon operations may include\n\nAddition and subtraction\nLogical (OR, AND)\nShift\nComparisons\n\n8 bit ALU\n\n\n\n\n\nALU operations, inputs &amp; outputs:\n\n\n\n\n\nALU block diagram\n\n\neg. ALU operation encodings\n\n\n\n\n"},"comOrg/Combinational-circuits":{"title":"Combinational circuits","links":["comOrg/equality-comparators-using-XOR","comOrg/multiplexer---MUX","comOrg/decoder","comOrg/encoder"],"tags":[],"content":"note\n\n\ncomplex functions built from basic gates\n\ncomparators\nMultiplexers\nDecoders\nEncoders\n\n\n\ncombinational: output depends only on current inputs\n\n\n\n\n"},"comOrg/D-Flip-Flop---DFF":{"title":"D Flip Flop - DFF","links":[],"tags":["comArc/sequentialCircuit"],"content":"positive edge-triggered DFF\n\ndata captured when clock low (0)\noutput changes only on rising edge\nQ = D\npic - positive edge-triggered DFF\n"},"comOrg/Instruction-Types--and--RISC-V-Instruction-Types":{"title":"Instruction Types & RISC-V Instruction Types","links":[],"tags":[],"content":"Instruction Types\nArithmetic\n‚Ä¢ add, subtract, shift left, shift right, multiply, divide\nMemory\n‚Ä¢ load value from memory to a register\n‚Ä¢ store value to memory from a register\nControl flow\n‚Ä¢ conditional jumps (branches)\n‚Ä¢ jump and link (subroutine call)\nMany other instructions are possible\n‚Ä¢ vector add/sub/mul/div, string operations\n‚Ä¢ manipulate coprocessor\n‚Ä¢ I/O\nRISC-V Instruction Types\n\nArithmetic/Logical\n\nR-type: result and two source registers, shift amount\nI-type: result and source register, shift amount in 16-bit immediate with sign/zero extension\nU-type: result register, 16-bit immediate with sign/zero extension\n\n\nMemory Access\n\nI-type for loads and S-type for stores\nload/store between registers and memory\nword, half-word and byte operations\n\n\nControl flow\n\nS-type: conditional branches: pc-relative addresses\nU-type: jump-and-link\nI-type: jump-and-link register\n\n\n\n"},"comOrg/Mealy-machine":{"title":"Mealy machine","links":[],"tags":["Math/discrete/Automata","comArc/sequentialCircuit/FSM"],"content":"Mealy state diagram\n\n1 input, 1 output, 2 states\nBubble for each state\nState transitions (arcs) for each input value\nInput values on the arcs (first number)\nOutput values on the arcs (second number)\nStarts at S0 when Reset asserted\n\nMealy machine structure diagram\n\npic\noutput depends on inputs and current state values\n"},"comOrg/Moore-machine":{"title":"Moore machine","links":[],"tags":["Math/discrete/Automata","comArc/sequentialCircuit/FSM"],"content":"Moore state diagram\n\n1 input, 1 output, 3 states\nBubble for each state\nState transitions (arcs) for each input value\nInput values on the arcs\nOutput values within the bubbles\nStarts at S0 when Reset asserted\npic\n\nMoore machine structure diagram\n\npic\noutput depend on current state value\n"},"comOrg/RISC-V-registers":{"title":"RISC-V registers","links":[],"tags":[],"content":"\nProgram counter (pc)\n32x32-bit integer registers (x0-x31)\n\nx0 always contains a 0\nx1 to hold the return address on a call.\n\n\n32 floating-point (FP) registers (f0- f31)\n\nEach can contain a single- or double precision FP value (32-bit or 64-bit IEEE FP)\nIs an extension\n\n\n"},"comOrg/RISC-V":{"title":"RISC-V","links":[],"tags":[],"content":"what is RISC-V (reduced instruction set computer)\nRISC-V, pronounced ‚Äúrisk five‚Äù, is an ISA standard (a document)\n\nopen-source implementation of a reduced-instruction-set-computer-based instruction set architecture\nprevious version before: RISC-I, II, III, IV\n\nmost ISA: X86, ARM, Power, MIPS, SPARC\n\ncommercially protected by patents\nprevent practical efforts to reproduce computer systems (so as to effectively sell patents :D)\n\nRISC-V is open source\n\npermit any person / group to construct compatible computers\nuse associated software\n\noriginated from UC Berkeley\n\nin 2010, by CS researchers at UCB\nnow has large number of contributors\n\nRISC-V ISA principles\n\nkept simple &amp; extendable\nseparated into multiple specifications\n\nUser-Level (unprivileged) ISA spec\nCompressed ISA spec (16-bit instructions)\nPrivileged ISA spec (supervisor-mode instructions)\n\n\nISA support is given by RV + word‚àíwidth + extensionssupported\n\nE.g. RV32I means 32bitRISC‚àíV with supportfortheIinstructionset\nE.g. RV64F means 64-bit RISC-V with support for the Single precision Floating-point instruction set\n\n\n"},"comOrg/Sequential-circuits":{"title":"Sequential circuits","links":["comOrg/clock-in-sequential-circuit"],"tags":["computerArchitecture/sequentialCircuit"],"content":"sequential circuit vs combinational circuit\n\nCombinational: Output depends only on current input\nSequential:\n\nOutput depends on current inputs + state variables (past history of the circuit, hold by the storage elements)\na clock periodically advances the circuit\n\n\npic sequential circuit vs combinational circuit\n\ntypes of sequential circuits:\n\nasynchronous sequential circuits: outputs &amp; state change AS input change\nsynchronous sequential circuits: output &amp; state change ONLY WHEN a special input, the clock, gets a certain value\n"},"comOrg/State-diagram":{"title":"State diagram","links":[],"tags":[],"content":"what is state diagram\n\nvisual specification of FSM\n\nBubble: state\nArcs: state transitions\nInput values shown on the arcs\nOutput values shown within the bubbles (Moore) or on the arcs (Mealy)\nClock input implicit (always present, triggering state transitions)\n\n\npic of Moore and Mealy FSM\n"},"comOrg/User-level-ISA":{"title":"User level ISA","links":[],"tags":[],"content":"define normal instructions needed for computation\n\nA mandatory Base integer ISA\n\nI: Integer instructions: ALU, branches/jumps, and loads/stores\n\n\nStandard Extensions\n\nM: Integer Multiplication and Division\nA: Atomic Instructions\nF: Single-Precision Floating-Point\nD: Double-Precision Floating-Point\nC: Compressed Instructions (16 bit)\nand more\n\n\n"},"comOrg/base10---decimal,-base2---binary,-base16---hexadecimal":{"title":"base10 - decimal, base2 - binary, base16 - hexadecimal","links":[],"tags":["computerScience/numerals"],"content":"general\n\n\n\nconvert to base 10\n\n\n\nconvert from base 10\n\nuse the remainder method\nrepeatedly divide by the number of base you are converting to\nplacing the remainder in backward order\n\n\nconversion summary\n\n\n"},"comOrg/binary-subtraction":{"title":"binary subtraction","links":[],"tags":[],"content":"what is two‚Äôs complement subtraction\n\n\n"},"comOrg/clock-in-sequential-circuit":{"title":"clock in sequential circuit","links":["comOrg/D-Flip-Flop---DFF"],"tags":["comArc/sequentialCircuit"],"content":"what is clock in sequential circult\n\nan input to a sequential circuit that changes output and state values at a predetermined rate\n\ntriggering edge\n\ntransition of the clock, capturing the input data\ninclude:\n\nPositive (rising) edge: 0 ‚Üí1\nNegative (falling) edge: 1 ‚Üí 0\n\n\nclock tick = occurrence of a triggering edge\n\nclock period and frequency\n\nclock period (cycle time): time between successive transitions in the same direction = tper‚Äã\nclock frequency: 1/tper‚Äã\npic - clock period and frequency\n\nedge-triggered storage\n\nD Flip Flop - DFF\n"},"comOrg/cmos-notation":{"title":"cmos notation","links":[],"tags":[],"content":"note\n\n\np-type\n\n0 to turn on/close = conducting current\n1 to turn off/open = not conducting current\n\n\nn-type\n\n1 to turn on/close = conducting current\n0 to turn off/open = not conducting current\n\n\n\nCMOS inverter\n\n\n"},"comOrg/decoder":{"title":"decoder","links":[],"tags":[],"content":"binary decoders\n\nn inputs, (2n) outputs\nEach output corresponds to a unique input value\nAt most one output asserted at a time (all is outputted at the same time &gt;&lt; only 1 is active)\n\n\n2-to-4 decoder\n\n\nexample: remember n inputs, (2n) outputs\n\nA1A0 is 00 ‚Üí 1 in Y0\nA1A0 is 01 ‚Üí we have 0 input ‚Üí output is 2^0 = 1  ‚Üí Y1 = 1\nA1A0 is 11 ‚Üí 2^1 + 2^0 = 3 ‚Üí Y3 = 1\n\n\n\n3-to-8 decoder\n\n\nA2A1A0 is 110 ‚Üí 2^2+2^1 = 6 ‚Üí Y6 = 1\n\ndecoder with enable\n\npic1\n\nillustration:\n\n1st row 0XX = when the enable is turned off, whatever input, there wont be any output\nfrom row 2 onward, enable is 1, it works just like normal decoder, taking into account the output solely not the enable anymore\n\n\n\n\npic2: enable is drawn just like an extra input\n"},"comOrg/encoder":{"title":"encoder","links":["comOrg/decoder"],"tags":["computerArchitecture/encoder"],"content":"note\n\nbinary encoders: 2n inputs ‚Üí n outputs (encoder is opposite of decoder)\n\nquick remember: (2N) looks just like ENcoders\n\n\neg. keyboard\nexactly one input is asserted at any given time\n\n4-to-2 encoder\n\n\nanalyze:\n\nI3 = 1 ‚Üí 2^n = 3 ‚Üí\n\n\n"},"comOrg/equality-comparators-using-XOR":{"title":"equality comparators using XOR","links":[],"tags":[],"content":"note\n\n\n"},"comOrg/hide-complexity-in-logic-gates-through-abstraction":{"title":"hide complexity in logic gates through abstraction","links":[],"tags":[],"content":"note\n\n\n"},"comOrg/instruction-processing":{"title":"instruction processing","links":[],"tags":[],"content":"instruction processing\n\na basic processor\n\nfetches\ndecodes\nexecutes\none instruction at a time\n\n\n\n"},"comOrg/instruction-set-architecture-(ISA)":{"title":"instruction set architecture (ISA)","links":[],"tags":["computerArchitecture/ISA"],"content":"definition\n\nabstract interface between hardware and the lowest level software\n\n\ngroup of commands that processor can perform, to execute the program instructions\nevery processor designed is based on 1 specific ISA, which defines the operational capacity of processor in terms of set of commands, that the processor can decode and execute\nIntel 8085 ISA, has 246 operation codes, 74 instructions\n\nhow ISA is implemented\n\n\nmicroarchitecture\n\nprocessor architecture at the hardware level\nactual hardware implementation of the ISA\nhardware circuitry of the processor chip that implements 1 particular ISA\n\n\n"},"comOrg/level-of-languages-in-computer":{"title":"level of languages in computer","links":[],"tags":[],"content":"high level language\n\nC, Java, Python\nLoops, control flow, variables\n\nAssembly language\n\nno symbols (except labels)\n1 operation per statement\n‚Äùhuman readable machine language‚Äù\n\nMachine language\n\nbinary-encoded assembly\nlabels become addresses\nthe language of the CPU\n\nillustration\n or link"},"comOrg/logic-gates":{"title":"logic gates","links":[],"tags":[],"content":"definition\n\n\n\nlogic gates: names + symbols + truth tables\n\n\n\nlogic functions\n\n\n"},"comOrg/logic-implementation-_-from-truth-tables-to-logic-circuits":{"title":"logic implementation _ from truth tables to logic circuits","links":[],"tags":[],"content":"note\n\ncombination circuit\n\n\n\n\n"},"comOrg/logic-symbols--and--notation":{"title":"logic symbols & notation","links":[],"tags":[],"content":"\n\n"},"comOrg/moore's-law":{"title":"moore's law","links":[],"tags":[],"content":"note\n\n‚Äù# of transistors integrated on a die doubles every 18-24 months (i.e., grows exponentially with time)‚Äù - 1965 (Gordon Moore, founder Intel Corp.)\n"},"comOrg/multiplexer---MUX":{"title":"multiplexer - MUX","links":[],"tags":[],"content":"note\n\n\n\nDescription:\n\nIf selection is 0 choose the first input, otherwise choose the second input\nCombinational circuit that has multiple data inputs and one output, along with additional control or select inputs. The control inputs determine which of the data inputs is connected to the output.\n\n\nhow it works\n\nconnects one of n inputs to the output\n\nselect control signals pick one of the n sources (log2n select bits)\n\n\nuseful when multiple data sources need to be routed to a single destination\n\nOften arises from resource sharing\nExample: select 1-of-n data inputs to an adder\n\n\nunderstand how it output\n\nThe selection lines essentially form a 2-bit binary number that determined which input is selected to appear at the output\n\neg. 4-to-1 MUX\n\nIf¬†S1S0¬†is¬†00, then¬†I0¬†is selected.\nIf¬†S1S0¬†is¬†01, then¬†I1¬†is selected.\nIf¬†S1S0¬†is¬†10, then¬†I2¬†is selected.\nIf¬†S1S0¬†is¬†11, then¬†I3¬†is selected.\n\n\n\n\n\n\n\ncascading multiplexers\n\nLarge multiplexers can be implemented by cascading smaller ones\npic\n"},"comOrg/negative-numbers-_-sign-magnitude-+-twos-complement-+-sign-extension--and--truncation":{"title":"negative numbers _ sign-magnitude + twos-complement + sign extension & truncation","links":[],"tags":[],"content":"sign-magnitude representation\n\nconsists of 2 parts: sign and magnitude\ndecimal example: +12310‚Äã and ‚àí12310‚Äã\nbinary example: 011002‚Äã=+1210‚Äã,111002‚Äã=‚àí1210‚Äã\n\nsign represented by MSB (most significant bit = leftmost digit): 1 = negative, 0 = positive\n\n\n\ntwo‚Äôs complement representation\n\nrepresent negative number\npositive numbers represented as usual\nleading 1‚Äôs for negative numbers\nto negate any number\n\nWAY 1\n\nflip all the bits\nadd 1 to the least significant bit (LSB = rightmost digit)\n\n\nWAY 2\n\ntranslate normally like base 10 ‚Üí\n\n\n\n\n"},"comOrg/numbers-with-fractions-in-computer":{"title":"numbers with fractions in computer","links":[],"tags":[],"content":"two common notations for numbers with fractions\n\nFixed-point: binary point fixed\nFloating-point: binary point floats to the right of the most significant 1\n"},"comOrg/overflow":{"title":"overflow","links":[],"tags":[],"content":"when can overflow occur\n\n\n\n"},"comOrg/shifters":{"title":"shifters","links":["tags/toProceed"],"tags":["toProceed"],"content":"logical shifters (&gt;&gt; or &lt;&lt;)\n\nshift value to left or right, fill empty spaces with 0‚Äôs\n\nEx: 11001 &gt;&gt; 2 = 00110\nEx: 11001 &lt;&lt; 2 = 00100\n\n\n\nArithmetic shifter (&gt;&gt;&gt; or &lt;&lt;&lt;)\n\nsame as logical shifter, but on right shift, fills empty spaces with the old most significant bit (msb).\n\nEx: 11001 &gt;&gt;&gt; 2 = 11110\nEx: 11001 &lt;&lt;&lt; 2 = 00100\n\n\n\nRotator\n\nrotates bits in a circle, such that bits shifted off one end are shifted into the other end\n\nEx: 11001 ROR 2 = 01110 (put skipped to be the beginning, rotate right)\nEx: 11001 ROL 2 =  00111(put skipped to the end, rotate left)\n\n\n\nshifter designtoProceed\n\n\n\neg. shift 2 times the input Y3 Y2 Y1 Y0 ‚áí they are all at 10 ‚áí 0 0 A3 A2\n\n\n\nshifters as multipliers, dividers\n\n\njust like in base 10, now is for base 2\n\n\nA&lt;&lt;N=A√ó2N\n\nExample: 00001 &lt;&lt; 2  = 00100  (1 √ó 22 = 4)\nExample: 11101 &lt;&lt; 2  = 10100  (-3 √ó 22 = -12)\n\n\n\nA&gt;&gt;&gt;N=A√∑2N\n\nExample: 01000 &gt;&gt;&gt; 2 = 00010  (8 √∑ 22 = 2)\nExample: 10000 &gt;&gt;&gt; 2 = 11100  (-16 √∑ 22 = -4)\n\n\n"},"comOrg/transistors-_-n-type-and-p-type":{"title":"transistors _ n-type and p-type","links":[],"tags":[],"content":"info about transistors\n\n\n2 types of silicon\n\np-type silicon: positive free-carriers (holes)\nn-type silicon: negative free-carriers (electrons)\n\n\n2 types of transistors\n\np-transistor: Gate (- charged), generates electric field that creates a (+ charged) p-type channel connecting sources &amp; drain\nn-transistor: Gate (+ charged), generates electric field that creates a (- charged) n-type channel connecting sources &amp; drain\n\n\n\nCMOS\n\nComplementary Metal-Oxide Semiconductor (CMOS)\nuse both p- &amp; n-type transistors\n"},"comOrg/translators---assembler-+-compiler-+-interpreter":{"title":"translators - assembler + compiler + interpreter","links":[],"tags":["computerArchitecture/translator"],"content":"what is translator in computer\n\ndefinition\n\na translator or a programming language processor that converts a computer program from a language to another\nit takes a program written in source code and converts into machine code\nit discover and identifies errors during translation\n\n\ntypes of translators\n\nassembler: assembly (src code) ‚Üí assembler (translator) ‚Üí machine level language (object code)\ncompiler:\n\nread the complete src program in high level language ‚Üí if error free, convert into machine level language\nspecifies errors in the src code at the end of compilation, if any\n\n\ninterpreter\n\nconvert high-level language to machine level language\nit converts line by line, then report errors with executable lines‚Äô results ‚Üí faster than compiler\n\n\n\n\n"},"comOrg/universal-gates-_-nand-+-nor":{"title":"universal gates _ nand + nor","links":[],"tags":[],"content":"note\n\ncan implement any functions with just NAND or NOR gates\nuseful for manufacturing\npic\n"},"history2/***history-2-map":{"title":"***history 2 map","links":["history2/C√≥-c·∫ßn-ph·∫£i-c·∫£i-ti·∫øn-ch·ªØ-qu·ªëc-ng·ªØ","history2/his2lec2-questions","history2/Nh·∫≠t-B·∫£n","history2/ƒë∆∞·ªùng-s·∫Øt-b·∫Øc-nam","history2/NAQ-v·ªÅ-Qu·∫£ng-Ch√¢u","history2/reflection-lecture-3-his2","history2/Everything-about-V√µ-Nguy√™n-Gi√°p","history2/make-in-vi·ªát-nam-his2","history2/li·ªáu-c√≥-th·ªÉ-tr√°nh-ƒë∆∞·ª£c-cu·ªôc-chi·∫øn-tranh-ƒë√¥ng-d∆∞∆°ng-l·∫ßn-1-hay-kh√¥ng","history2/draft---ph√°p-r∆°i-v√†o-th·∫ø-ph·∫£i-chi·∫øn","history2/Lƒê1---Ph√°p-r∆°i-v√†o-th·∫ø-ph·∫£i-chi·∫øn"],"tags":[],"content":"Lecture 1\nC√≥ c·∫ßn ph·∫£i c·∫£i ti·∫øn ch·ªØ qu·ªëc ng·ªØ?\nLecture 2\n\nhis2lec2 questions\nNh·∫≠t B·∫£n\n\nC√¢u 3: T·∫°i sao Ph√°p x√¢y d·ª±ng ƒë∆∞·ªùng s·∫Øt B·∫Øc Nam? B√¢y gi·ªù c√≥ c·∫ßn x√¢y d·ª±ng ƒë∆∞·ªùng s·∫Øt B·∫Øc Nam kh√¥ng? ƒë∆∞·ªùng s·∫Øt b·∫Øc nam\n\nLecture 3\n\nNAQ v·ªÅ Qu·∫£ng Ch√¢u\nl√†m 1 vi·ªác k c√≥ thi√™n th·ªùi ƒë·ªãa l·ª£i nh√¢n ho√†, th√¨ c√≥ ph·∫£i ƒëg c√πng k m√† l√†m. cta s·∫Ω justify h√†nh ƒë·ªông c·ªßa mk, cho r·∫±ng ƒë∆∞·ªùng c√πng. Nh∆∞ng th·ª±c ra lu√¥n lu√¥n c√≥ ƒë∆∞·ªùng kh√°c\nt∆∞·ªõng gi·ªèi l√† t∆∞·ªüng c√≤n s·ªëng v√† √≠t thi·ªát h·∫°i nh·∫•t (ƒë·∫ßu ti√™n l√† cho t∆∞·ªõng)\nb√°c mu·ªën khuy·∫øn kh√≠ch mng vi·∫øt b√°o ‚Üí l√£nh ƒë·∫°o ph·∫£i bi·∫øt vi·∫øt\n\n\n\nh·ªèi c√¢u simple\nreflection lecture 3 his2\ncompare (t√°c ƒë·ªông √≠t nh√≥m ng h∆°n, sustainable h∆°n)\n\nLecture 5:\n\nEverything about V√µ Nguy√™n Gi√°p\n‚ÄùL·ªùi k√™u g·ªçi to√†n qu·ªëc kh√°ng chi·∫øn‚Äù c·ªßa HCM ng√†y 19/12/1946 ƒë√£ ph√°t ƒë·ªông m·ªôt cu·ªôc chi·∫øn tranh to√†n d√¢n ch·ªëng Ph√°p. T∆∞ t∆∞·ªüng n√†o c√≥ th·ªÉ d√πng ƒë·ªÉ ph√°t ƒë·ªông m·ªôt cu·ªôc chi·∫øn v·ªÅ c√¥ng ngh·ªá trong chi·∫øn d·ªãch ‚ÄúMake in Vi·ªát Nam‚Äù - make in vi·ªát nam his2\n\nLecture 6:\n\nli·ªáu c√≥ th·ªÉ tr√°nh ƒë∆∞·ª£c cu·ªôc chi·∫øn tranh ƒë√¥ng d∆∞∆°ng l·∫ßn 1 hay kh√¥ng\n\ndraft - ph√°p r∆°i v√†o th·∫ø ph·∫£i chi·∫øn\nLƒê1 - Ph√°p r∆°i v√†o th·∫ø ph·∫£i chi·∫øn\n\n\n"},"history2/Chi·∫øn-tranh-Th·∫ø-gi·ªõi-2":{"title":"Chi·∫øn tranh Th·∫ø gi·ªõi 2","links":[],"tags":[],"content":"\nk·∫øt th√∫c CTTG1 v√†o 1918\n\nth·∫Øng tr·∫≠n: Anh, Ph√°p, Italia, M·ªπ, Nh·∫≠t\nb·∫°i tr·∫≠n: ƒê·ª©c, √Åo - Hung\n\n\n1929, ƒë·∫°i kh·ªßng ho·∫£ng kinh t·∫ø ‚Üí t·ª´ s·ª•p ƒë·ªï th·ªã tr∆∞·ªùng ch·ª©ng kho√°n hoa k√¨, lan r·ªông to√†n TG ‚áí 2 c√°ch kh√¥i ph·ª•c kinh t·∫ø ch√≠nh\n\nti·∫øn h√†nh c·∫£i c√°ch kinh t·∫ø x√£ h·ªôi: Anh, Ph√°p, M·ªπ\nb√†nh tr∆∞·ªõng l√£nh th·ªï, x√¢m chi·∫øm thu·ªôc ƒë·ªãa, v∆° v√©t t√†i nguy√™n: ƒê·ª©c, √ù, Nh·∫≠t\n\n\n10 May ‚Äì 25 June 1940, ƒë·ª©c th·∫Øng ph√°p (The Battle of France), xo√° s·∫°ch ƒë·ªôi qu√¢n tinh nhu·ªá nh·∫•t n∆∞·ªõc Ph√°p ‚Üí cu·ªôc di t·∫£n Dunkirk (ƒë·ªôi qu√¢n cu·ªëi c√πng c·ªßa A tho√°t ƒëc) ‚Üí ƒê·ª©c chi·∫øm lu√¥n Paris, th√¥n t√≠nh Ph√°p, ki·ªÉm so√°t c√°c thu·ªôc ƒë·ªãa b√π nh√¨n c·ªßa ph√°p (g·ªìm VN) (b·∫±ng c√°ch l·∫≠p ch√≠nh ph·ªß b√π nh√¨n ·ªü P)\nc·ªßng c·ªë kh·ªëi li√™n minh ph√°t x√≠t - √Ω, ƒë·ª©c, nh·∫≠t k√Ω hi·ªáp ∆∞·ªõc tam c∆∞·ªùng\n22/6/1941, xo√° b·ªè hi·ªáp ∆∞·ªõc x√¥ ƒë·ª©c (kh√¥ng x√¢m l∆∞·ª£c l·∫´n nhau) ‚Üí x√¢m l∆∞·ª£c li√™n x√¥\n1940s, ·ªü ch√¢u √°, nh·∫≠t nhanh ch√≥ng chi·∫øm h·∫ßu h·∫øt mi·ªÅn ƒë√¥ng trung qu·ªëc\n1944, m·ªπ anh, qu√¢n ƒë·ªìng minh, ƒë√°nh ƒë·ª©c, ph√°p ƒëc gi·∫£i ph√≥ng\n‚áí ph√°p\n\n\n\nƒë·ªông l·ª±c\n\nmong mu·ªën: l√≤ng tham mu·ªën chi·∫øm ƒë·∫•t, b√≥c l·ªôt lao ƒë·ªông, t√†i nguy√™n\n\nThe French colonization and occupation of Vietnam were a result of secular¬†imperialism, driven by economic interests and strategic considerations. In addition to exploiting Vietnam‚Äôs resources, the French saw the region as a strategic buffer to facilitate access to resources in China. France, however, used the pretext of protecting Christians, who were persecuted by the Nguyen, as a justification for their invasion of Vietnam. (link)\n\n\ns·ª£ h√£i: kh√¥ng duy tr√¨ ƒë∆∞·ª£c v·ªã th·∫ø c∆∞·ªùng qu·ªëc c·ªßa m√¨nh, sau khi li√™n t·ª•c b·ªã m·∫•t n∆∞·ªõc ‚Üí Ph√°p c·∫ßn l·∫•y l·∫°i v·ªã th·∫ø, danh d·ª±, ƒë∆∞·ªùng ƒë∆∞·ªùng l√† c∆∞·ªùng qu·ªëc l·ªõn t·ª´ng th·∫Øng CTTG1, gi·ªù l·∫°i b·∫°i tr·∫≠n\n\nsau CTTG1, th·∫ø gi·ªõi tr·∫£i qua\n\n\n\n\n"},"history2/C√≥-c·∫ßn-ph·∫£i-c·∫£i-ti·∫øn-ch·ªØ-qu·ªëc-ng·ªØ":{"title":"C√≥ c·∫ßn ph·∫£i c·∫£i ti·∫øn ch·ªØ qu·ªëc ng·ªØ?","links":[],"tags":[],"content":"note\n\n∆Øu ƒëi·ªÉm c·ªßa ch·ªØ qu·ªëc ng·ªØ.\ns·ª≠ d·ª•ng r·∫•t √≠t k√≠ hi·ªáu nh∆∞ng kh·∫£ nƒÉng bi·ªÉu ƒë·∫°t cao\nV√¨ theo m·∫´u t·ª± La Tinh ‚áí d·ªÖ h·ªçc d·ªÖ vi·∫øt, t·∫°o ƒëi·ªÅu ki·ªán ƒë·ªÉ ng∆∞·ªùi vi·ªát d·ªÖ h·ªçc c√°c ng√¥n ng·ªØ kh√°c (anh, ph√°p,..)\nA. D·ªÖ h·ªçc v√† s·ª≠ d·ª•ng B. H·ªó tr·ª£ giao ti·∫øp v√† ti·∫øp c·∫≠n th√¥ng tin C. Kh·∫£ nƒÉng t∆∞∆°ng th√≠ch v·ªõi c√¥ng ngh·ªá v√† ph∆∞∆°ng ti·ªán truy·ªÅn th√¥ng hi·ªán ƒë·∫°i\nNh∆∞·ª£c ƒëi·ªÉm c·ªßa ch·ªØ qu·ªëc ng·ªØ.\nDo ng∆∞·ªùi ph∆∞∆°ng t√¢y so·∫°n ‚áí k√Ω t·ª± hay c·ª•m k√Ω t·ª± ghi c√πng m·ªôt √¢m ti·∫øt (c v√† k, g v√† gh, ng v√† ngh)\nRa ƒë·ªùi khi c∆° s·ªü nghi√™n c·ª©u ph√¢n t√≠ch h·ªá th·ªëng ng·ªØ √¢m c·ªßa ti·∫øng Vi·ªát ch∆∞a ƒë·∫ßy ƒë·ªß, ch∆∞a c√≥ nh·ªØng kh√°i ni·ªám ng√¥n ng·ªØ h·ªçc hi·ªán ƒë·∫°i nh∆∞ √¢m v·ªã n√™n c√≥ ch·ªó b·∫•t h·ª£p l√Ω\nNg√¥n ng·ªØ k√®m nhi·ªÅu d·∫•u ph·ª• nh·∫•t tr√™n th·∫ø gi·ªõi\nA. S·ª± phong ph√∫ v√† ph·ª©c t·∫°p c·ªßa ng√¥n ng·ªØ Vi·ªát Nam B. Thi·∫øu kh·∫£ nƒÉng ph·∫£n √°nh ƒë·∫ßy ƒë·ªß c√°c √¢m ƒëi·ªáu v√† ng·ªØ ƒëi·ªáu C. Kh√≥ khƒÉn trong vi·ªác b·∫£o t·ªìn v√† ph√°t tri·ªÉn vƒÉn h√≥a d√¢n t·ªôc th√¥ng qua ch·ªØ qu·ªëc ng·ªØ\nNh·ªØng ƒë·ªÅ xu·∫•t c·∫£i ti·∫øn ch·ªØ qu·ªëc ng·ªØ g·∫ßn ƒë√¢y.\nA. C·∫ßn c√¢n nh·∫Øc gi·ªØa vi·ªác c·∫£i ti·∫øn v√† b·∫£o t·ªìn ch·ªØ qu·ªëc ng·ªØ B. Khuy·∫øn kh√≠ch nghi√™n c·ª©u v√† ƒë·∫ßu t∆∞ v√†o c√°c ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y v√† s·ª≠ d·ª•ng ch·ªØ qu·ªëc ng·ªØ hi·ªáu qu·∫£ h∆°n C. T√¥n tr·ªçng v√† b·∫£o t·ªìn nh·ªØng gi√° tr·ªã vƒÉn h√≥a c·ªßa ng√¥n ng·ªØ Vi·ªát Nam th√¥ng qua vi·ªác ph√°t tri·ªÉn ch·ªØ qu·ªëc ng·ªØ.\n\n‚áí Possible Qs:"},"history2/Everything-about-V√µ-Nguy√™n-Gi√°p":{"title":"Everything about V√µ Nguy√™n Gi√°p","links":[],"tags":[],"content":"\n\n‚ÄúD√¢n kh√¥ng th·ªù sai ai bao gi·ªù‚Äù - D∆∞∆°ng Trung Qu·ªëc. l√≤ng d√¢n s·∫Ω quy·∫øt ƒë·ªãnh c√°c b·∫≠c ti·ªÅn nh√¢n c√≤n s·ªëng m√£i trong l·ªãch s·ª≠ d√¢n t·ªôc hay kh√¥ng‚Äù\n\nFun insight\n\n\nL√™ ƒê·ª©c Th·ªç kh√¥ng th√≠ch V√µ Nguy√™n Gi√°p ‚Üí mqh gi·ªØa t∆∞·ªõng Gi√°p v√† LƒêT\n\nchi·∫øn d·ªãch m·∫≠u th√¢n 1968: [link](5 V·ªä T∆Ø·ªöNG T√ÄI BA NH·∫§T L·ªäCH S·ª¨ VI·ªÜT NAM (P1) (spiderum.com))\n30 ng th√¢n c·∫≠n v·ªõi t∆∞·ªõng ph√°p b·ªã b·∫Øt gi·ªØ\nT∆∞·ªõng Gi√°p ƒë∆∞a ch∆∞√£ b·ªánh Hungary\nHCM ngh·ªâ ng∆°i ·ªü B·∫Øc Kinh\nd√π thua trong chi·∫øn tr∆∞·ªùng, nh∆∞ng b·ª©c ·∫£nh ƒë√£ ƒë∆∞a chi·∫øn th·∫Øng tr√™n truy·ªÅn th√¥ng tr·∫£ v·ªÅ cho VNDCCH.\n\n\n\nL√™ Tr·ªçng T·∫•n - v·ªã t∆∞·ªõng ƒë√°nh tr·∫≠n gi·ªèi nh·∫•t l·ªãch s·ª≠ hi·ªán ƒë·∫°i Vi·ªát Nam: link\n\nph∆∞∆°ng ch√¢m ‚Äúth·∫Øng kh√¥ng tranh c√¥ng, thua kh√¥ng ƒë·ªï l·ªói‚Äù\n\n\n\nm·ªôt s·ªë c√¢u h·ªèi t√≤ m√≤\n\n\nB√†i h·ªçc\n\nB√†i h·ªçc cu·ªôc s·ªëng t·ª´ quy·∫øt ƒë·ªãnh c·ªßa t∆∞·ªõng Gi√°p t·∫°i ƒêi·ªán Bi√™n Ph·ªß 1954 (spiderum.com)\n\n\n\nv√¨ sao t·ª´ nh√† gi√°o tr·ªü th√†nh v·ªã t∆∞·ªõng\n\ncon ng∆∞·ªùi ∆∞a chu·ªông ho√† b√¨nh, √¥ng n√≥i n·∫øu kh√¥ng l√†m t∆∞·ªõng c≈©ng s·∫Ω l√†m gi√°o vi√™n d·∫°y tri·∫øt ho·∫∑c l·ªãch s·ª≠\n\n\nb√°c gi√°p h·ªçc qu√¢n s·ª± ·ªü ƒë√¢u\n\nch∆∞a t·ª´ng tr·∫£i qua b·∫•t k√¨ tr∆∞·ªùng l·ªõp n√†o\nnh√† l√Ω lu·∫≠n chi·∫øn tranh clausewitz ƒë√£ t·ª´ng n√≥i, n·∫øu mu·ªën t·ª± h·ªçc v·ªÅ qu√¢n s·ª± ch·ªâ c√≥ 2 con ƒë∆∞·ªùng: kinh nghi·ªám b·∫£n th√¢n v√† l·ªãch s·ª≠ chi·∫øn tranh\nchi·∫øn tranh du k√≠ch\n\n\n\n\n\nli·ªáu c√≥ th·ªÉ tr√°nh ƒë∆∞·ª£c cu·ªôc chi·∫øn tranh ƒë√¥ng d∆∞∆°ng l·∫ßn 1 hay kh√¥ng\n"},"history2/Lƒê1---Ph√°p-r∆°i-v√†o-th·∫ø-ph·∫£i-chi·∫øn":{"title":"Lƒê1 - Ph√°p r∆°i v√†o th·∫ø ph·∫£i chi·∫øn","links":["history2/Chi·∫øn-tranh-Th·∫ø-gi·ªõi-2"],"tags":[],"content":"C·∫ßn v∆° v√©t thu·ªôc ƒë·ªãa ƒë·ªÉ kh·∫Øc ph·ª•c t·ªïn th·∫•t\n\nSau CTTG 2,\n"},"history2/NAQ-v·ªÅ-Qu·∫£ng-Ch√¢u":{"title":"NAQ v·ªÅ Qu·∫£ng Ch√¢u","links":[],"tags":[],"content":"Topic 4: T·∫°i sao NAQ quay v·ªÅ Qu·∫£ng Ch√¢u m√† kh√¥ng ·ªü l·∫°i ch√¢u √Çu l√†m vi·ªác cho QTCS. √îng ƒë√£ l√†m ƒë∆∞·ª£c g√¨ quan tr·ªçng nh·∫•t ·ªü Qu·∫£ng Ch√¢u?\n\n\n"},"history2/Nh·∫≠t-B·∫£n":{"title":"Nh·∫≠t B·∫£n","links":[],"tags":[],"content":"note\n\nfukuzawa\n\n12 nƒÉm chu·∫©n b·ªã\nc·∫£i c√°ch nh·∫≠t th√†nh c√¥ng?\n\nph√°t h√†nh s√°ch ra c√¥ng ch√∫ng, 5tr b·∫£n (30tr d√¢n) ‚Üí tr√¨nh ƒë·ªô d√¢n tr√≠ cao\nph√°i ƒëo√†n 128 ng ƒëi t·∫•t c·∫£ th√†nh ph·ªë l·ªõn, h·ªçc t·ª´ c√°c n∆∞·ªõc l·ªõn (hi·∫øn ph√°p ƒë·ª©c, t√†u thu·ª∑ h√† lan, l√°i xe anh) ‚Üí shortcut c·∫Øt tgian, learn from the best + apply lu√¥n\n\n\n\n\nnguy·ªÖn tr∆∞·ªùng t·ªô - c·∫£i c√°ch n·ªôp cho vua, c·∫≠n th·∫ßn &gt;&lt; c·∫£i c√°ch to√†n di·ªán\n\n\n\nnghi√™n c·ª©u l·ªãch s·ª≠ hay kinh doanh, v.v ‚Üí lu√¥n ph·∫£i ƒë·ªÉ √Ω b·ªëi c·∫£nh xung quanh, c√°c n∆∞·ªõc kh√°c, lsu vhoa ctri, trong b·ªëi c·∫£nh chung c·ªßa c·∫£ TG\n\n"},"history2/Untitled":{"title":"Untitled","links":[],"tags":[],"content":""},"history2/draft---ph√°p-r∆°i-v√†o-th·∫ø-ph·∫£i-chi·∫øn":{"title":"draft - ph√°p r∆°i v√†o th·∫ø ph·∫£i chi·∫øn","links":[],"tags":[],"content":"\nƒë·ªëi v·ªõi ph√°p, cu·ªôc chi·∫øn mang t√≠nh ch√≠nh tr·ªã v√† t√¢m l√Ω h∆°n kinh t·∫ø~~\n\nn·∫øu ph√°p ƒë·ªÉ ƒë√¥ng d∆∞∆°ng d√†nh ƒë·ªôc l·∫≠p, c√°c quy·ªÅn v√† t√†i s·∫£n c·ªßa Ph√°p t·∫°i nhi·ªÅu thu·ªôc ƒë·ªãa h·∫£i ngo·∫°i s·∫Ω nhanh ch√≥ng b·ªã m·∫•t theo\nxung ƒë·ªôt gi·ªØa l·ª£i √≠ch ƒë·∫ø qu·ªëc v√† phong tr√†o ƒë·ªôc l·∫≠p c·ªßa ƒê√¥ng D∆∞∆°ng\nxung ƒë·ªôt gi·ªØa c√°c c∆∞·ªùng qu·ªëc ch√¢u √¢u - ai chi·∫øm ƒë∆∞·ª£c nhi·ªÅu thu·ªôc ƒë·ªãa, t√†i nguy√™n h∆°n\n\nD·∫´n ch·ª©ng: Vi·ªác c·∫°nh tranh gi·ªØa c√°c qu·ªëc gia ch√¢u √Çu (nh∆∞ Ph√°p, Anh) ƒë·ªÉ chi·∫øm ƒë√≥ng c√°c v√πng ƒë·∫•t v√† t√†i nguy√™n ·ªü ƒê√¥ng D∆∞∆°ng ƒë√£ l√†m tƒÉng s·ª± cƒÉng th·∫≥ng v√† xung ƒë·ªôt (V√≠ d·ª•: Tr·∫≠n M·∫°c C·ª≠u nƒÉm 1940 gi·ªØa Ph√°p v√† Nh·∫≠t B·∫£n).\n\n\n\n\nph√°p li√™n ti·∫øp b·∫°i tr·∫≠n k·ªÉ t·ª´ CTTG T2 n·ªï ra ‚Üí kh·∫Øc ph·ª•c t·ªïn th·∫•t b·∫±ng c√°ch v∆° v√©t thu·ªôc ƒë·ªãa (Trong ƒë√≥ c√≥ VN)\n\nT6/1940, Ph√°p b·ªã ƒë·ª©c qu·ªëc x√£ chi·∫øm ƒë√≥ng trong CTTG2 ‚Üí c∆° h·ªôi Nh·∫≠t B·∫£n chi·∫øm b√°n ƒë·∫£o ƒê√¥ng D∆∞∆°ng t·ª´ P\nT9/1940, Nh·∫≠t t·∫•n c√¥ng VN, P ch·∫°y v·ªÅ Th√°i Nguy√™n ‚Üí th·ªùi c∆° cho kh·ªüi nghƒ©a ƒë√£ ƒë·∫øn\n\n27/9/1940, chi b·ªô ƒêCS ƒêD ph√°t ƒë·ªông kh·ªüi nghƒ©a, d√†nh 1 s·ªë ƒë·ªãa b√†n\nP b·∫°i tr·∫≠n ·ªü CTTG2, b·ªã Nh·∫≠t c∆∞·ªõp quy·ªÅn ·ªü ƒê√¥ng D∆∞∆°ng\n09/03/1945, Nh·∫≠t ƒë·∫£o ch√≠nh Ph√°p tr√™n to√†n b√°n ƒë·∫£o ƒë√¥ng d∆∞∆°ng, P theo ƒë√≥ ph·∫£i r·ªùi VN\n\nnh·∫≠t b·∫£n tuy√™n b·ªë trao tr·∫£ ƒë·ªôc l·∫≠p cho vi·ªát nam, th√†nh l·∫≠p v√† b·∫£o h·ªô ƒë·∫ø qu·ªëc VN, gi·ªØ nguy√™n b·ªô m√°y cai tr·ªã, thay ng nh·∫≠t v√†o v·ªã tr√≠ ng ph√°p\nN v∆° v√©t t∆∞ li·ªáu s·∫£n xu·∫•t h√†ng ho√° l∆∞∆°ng th·ª±c, c∆∞·ªõp t√†i s·∫£n c·ªßa d√¢n VN, chi·∫øm kho th√≥c ‚Üí n·∫°n ƒë√≥i 1945\n\n\n‚áí ƒë·∫•u tranh v≈© trang gi·ªØa c√°c d√¢n t·ªôc, ƒëi·ªÉn h√¨nh l√† VN, P, N\n\n\nNh·∫≠t thua VN\n\nnh·∫≠t s·ª£ ptrao c·ªông s·∫£n lan r·ªông, ƒë√£ m·ªü c√†n qu√©t b√¨nh ƒë·ªãnh, t·∫•n c√¥ng v√†o c√°c v√πng ch·ªët hi·ªÉm c·ªßa vi·ªát minh &gt;&lt; t∆∞ t∆∞·ªüng c√¥ng s·∫£n c·ªßa VN lan truy·ªÅn m·∫°nh m·∫Ω, ng d√¢n th·∫•y l·ªëi ƒëi m·ªõi tho√°t kh·ªèi xi·ªÅng x√≠ch phong ki·∫øn c≈© ‚Üí kh√¥ng ch·∫•p nh·∫≠n b√≥c l·ªôt h√† kh·∫Øc c·ªßa N.\ngi·ªØa 1945, cu·ªôc chi·∫øn ch∆∞a ƒëi xa, ƒêQ Nh·∫≠t ƒë·∫ßu h√†ng phe ƒë·ªìng minh ‚Üí t·∫°i sao\n\nVN c√≥ c∆° h·ªôi l·ªõn d√†nh l·∫°i ƒë·ªôc l·∫≠p ‚Üí 19/8/1945, VM t·ªï ch·ª©c CMT8 t·ª´ t·ªïng kh·ªüi nghƒ©a HN lan r·ªông ra kh·∫Øp B·∫Øc Trung Nam ‚Üí ƒêQ Nh·∫≠t, ch√≠nh ph·ªß ƒêQ VN do N th√†nh l·∫≠p s·ª•p ƒë·ªï. 2/9 ‚Üí khai sinh VNDCCH sau g·∫ßn 100 nƒÉm Ph√°p thu·ªôc\n\n\n\n\n‚áí s·ª± kh·∫≥ng ƒë·ªãnh l√† m√¨nh m·∫°nh h∆°n Nh·∫≠t, l·∫•y l·∫°i danh d·ª±\n\n\n\n\nCheck your Supabase project‚Äôs API settings to find these values\nsupabase.com/dashboard/project/_/settings/api\nat RootLayout (./app/[locale]/layout.tsx:75:87)\nat stringify ()\n‚®Ø Error: Your project‚Äôs URL and Key are required to create a Supabase client!"},"history2/his2lec2-questions":{"title":"his2lec2 questions","links":[],"tags":[],"content":"\nnƒÉng\n"},"history2/li·ªáu-c√≥-th·ªÉ-tr√°nh-ƒë∆∞·ª£c-cu·ªôc-chi·∫øn-tranh-ƒë√¥ng-d∆∞∆°ng-l·∫ßn-1-hay-kh√¥ng":{"title":"li·ªáu c√≥ th·ªÉ tr√°nh ƒë∆∞·ª£c cu·ªôc chi·∫øn tranh ƒë√¥ng d∆∞∆°ng l·∫ßn 1 hay kh√¥ng","links":[],"tags":[],"content":"Ch·ª©ng minh kh√¥ng th·ªÉ tr√°nh ƒë∆∞·ª£c cu·ªôc chi·∫øn tranh ƒë√¥ng d∆∞∆°ng l·∫ßn 1 qua 3 lu·∫≠n ƒëi·ªÉm, g·ªìm\n\nlu·∫≠n ƒëi·ªÉm ch√≠nh (1 c√¢u ng·∫Øn g·ªçn)\nSupporting ideas\nD·∫´n ch·ª©ng, data\nDL: T·ªëi T7 tr∆∞·ªõc l√∫c h·ªçp\n\n\n\nframing\n\nnguy√™n nh√¢n v√† b·ªëi c·∫£nh c·ªßa CTDD\n\n([wiki](Chi·∫øn tranh ƒê√¥ng D∆∞∆°ng ‚Äì Wikipedia ti·∫øng Vi·ªát)) xung ƒë·ªôt th·∫≠t s·ª± ƒë√£ n·ªï ra t·ª´ ng√†y¬†23 th√°ng 9¬†nƒÉm¬†1945¬†khi qu√¢n Ph√°p theo ch√¢n qu√¢n Anh ti·∫øn v√†o¬†mi·ªÅn Nam Vi·ªát Nam¬†ƒë·ªÉ gi·∫£i gi√°p qu√¢n Nh·∫≠t.\n\n\n\n\n\n\n\n\n\nm·ªôt cu·ªôc chi·∫øn ƒë√£ ƒë∆∞·ª£c l∆∞·ªùng tr∆∞·ªõc b·ªüi c√°c b√™n\n\nƒë·ªëi v·ªõi VN, ƒë√¢y l√† giai ƒëo·∫°n ƒë·∫ßu ti√™n trong cu·ªôc kh√°ng chi·∫øn 30 nƒÉm c·ªßa h·ªç\ns·∫Ω l√† cu·ªôc chi·∫øn: Gi·ªØa h·ªï v√† voi. N·∫øu h·ªï ƒë·ª©ng y√™n, ch·∫Øc ch·∫Øn voi s·∫Ω d·∫´m b·∫πp. Nh∆∞ng h·ªï n·∫•p trong r·ª´ng v√† s·∫Ω xu·∫•t hi·ªán ban ƒë√™m, c·∫Øn m·ªôt mi·∫øng r·ªìi l·∫°i bi·∫øn m·∫•t v√†o r·ª´ng s√¢u. D·∫ßn d·∫ßn voi s·∫Ω ch·∫£y h·∫øt m√°u m√† ch·∫øt. ƒê√≥ s·∫Ω l√† cu·ªôc chi·∫øn tranh ƒê√¥ng D∆∞∆°ng.\nt·∫°m ∆∞·ªõc 14/09 b·ªã ph√° b·ªè, H·ªôi ngh·ªã Fontainebleau ƒë√£ th·∫•t b·∫°i do Ph√°p v·∫´n gi·ªØ l·∫≠p tr∆∞·ªùng th·ª±c d√¢n v√† √¢m m∆∞u t√°i chi·∫øm Vi·ªát Nam\n\n\n\nƒë·ªëi v·ªõi ph√°p, cu·ªôc chi·∫øn mang t√≠nh ch√≠nh tr·ªã v√† t√¢m l√Ω h∆°n kinh t·∫ø\n\nn·∫øu ph√°p ƒë·ªÉ ƒë√¥ng d∆∞∆°ng d√†nh ƒë·ªôc l·∫≠p, c√°c quy·ªÅn v√† t√†i s·∫£n c·ªßa Ph√°p t·∫°i nhi·ªÅu thu·ªôc ƒë·ªãa h·∫£i ngo·∫°i s·∫Ω nhanh ch√≥ng b·ªã m·∫•t theo\nl√£nh ƒë·∫°o ph√°p: cu·ªôc chi·∫øn n√†y c√≥ quy m√¥ l·ªõn h∆°n ch√∫t so v·ªõi m·ªôt cu·ªôc t√°i chi·∫øm thu·ªôc ƒë·ªãa c·ªï ƒëi·ªÉn\n\n\n\nPh√°p ƒë·ª©ng v√†o th·∫ø ti·∫øn tho√°i l∆∞·ª°ng nan v·ªÅ ch√≠nh tr·ªã:\n\ndebate c√¢u 4 week 6 - Google Docs\n\n\n\nxung ƒë·ªôt gi·ªØa l·ª£i √≠ch ƒë·∫ø qu·ªëc v√† phong tr√†o ƒë·ªôc l·∫≠p c·ªßa ƒê√¥ng D∆∞∆°ng\n\n\nƒê√≤n b·∫©y qu·ªëc t·∫ø v√† c·∫°nh tranh l·ª£i √≠ch:\n\nC√°c c∆∞·ªùng qu·ªëc ch√¢u √Çu ƒëang c·∫°nh tranh l·ª£i √≠ch trong khu v·ª±c ƒê√¥ng D∆∞∆°ng, t·∫°o ra √°p l·ª±c kh√¥ng th·ªÉ tr√°nh kh·ªèi cho c√°c qu·ªëc gia ƒë·ªãa ph∆∞∆°ng.\nS·ª± can thi·ªáp c·ªßa c√°c c∆∞·ªùng qu·ªëc ƒë√£ l√†m tƒÉng cƒÉng th·∫≥ng v√† nguy c∆° xung ƒë·ªôt.\nD·∫´n ch·ª©ng: Vi·ªác c·∫°nh tranh gi·ªØa c√°c qu·ªëc gia ch√¢u √Çu (nh∆∞ Ph√°p, Anh) ƒë·ªÉ chi·∫øm ƒë√≥ng c√°c v√πng ƒë·∫•t v√† t√†i nguy√™n ·ªü ƒê√¥ng D∆∞∆°ng ƒë√£ l√†m tƒÉng s·ª± cƒÉng th·∫≥ng v√† xung ƒë·ªôt (V√≠ d·ª•: Tr·∫≠n M·∫°c C·ª≠u nƒÉm 1940 gi·ªØa Ph√°p v√† Nh·∫≠t B·∫£n).\n\n\n\n\n\nB·∫£n tuy√™n ng√¥n nh√¢n quy·ªÅn v√† d√¢n quy·ªÅn c·ªßa c√°ch m·∫°ng ph√°p nƒÉm 1971: ng∆∞·ªùi ta sinh ra t·ª± do v√† b√¨nh ƒë·∫≥ng v·ªÅ quy·ªÅn l·ª£i v√† ph·∫£i lu√¥n lu√¥n ƒë∆∞·ª£c t·ª± do v√† b√¨nh ƒë·∫≥ng v·ªÅ quy·ªÅn l·ª£i\n\n\n\nph√°p li√™n ti·∫øp b·∫°i tr·∫≠n k·ªÉ t·ª´ CTTG T2 n·ªï ra ‚Üí kh·∫Øc ph·ª•c t·ªïn th·∫•t b·∫±ng c√°ch v∆° v√©t thu·ªôc ƒë·ªãa (Trong ƒë√≥ c√≥ VN)\nP ch∆∞a √Ω th·ª©c ƒëc ƒëe do·∫° phong tr√†o CSQT mang l·∫°i, ch·ªâ lo v∆° v√©t thu·ªôc ƒë·ªãa, tham chi·∫øn nhi·ªÅu n∆°i, d√†nh ƒë·∫•t v·ªõi c√°c ƒë·ªìng m√¨nh\n\nP v∆° v√©t VN, t·∫ßng l·ªõp n√¥ng d√¢n c√¥ng nh√¢n ng√†y c√†ng cƒÉm ph·∫´n, t∆∞ s·∫£n ƒë·ªãa ch·ªß tr√≠ th·ª©c ng·∫£ d·∫ßn v·ªÅ ph√≠a c√°ch m·∫°ng. c√°c t·∫ßng l·ªõp ƒë·ªÅu ch·ªù th·ªùi c∆° n·ªïi d·∫≠y ch·ªëng l·∫°i ch√≠nh ph·ªß P\n\n\nNh·∫≠t mu·ªën v·∫Ω l·∫°i b·∫£n ƒë·ªì TG - ƒëi·ªÉm y·∫øu l√† k c√≥ nhi·ªÅu t√†i nguy√™n kho√°ng s·∫£n (ph·∫£i nh·∫≠p kh·∫©u) ‚Üí mu·ªën s√°p nh·∫≠p TQ &amp; c√°c qu·ªëc gia l√¢n c·∫≠n v√†o th·ªãnh v∆∞·ª£ng chung ƒë·∫°i ƒë√¥ng √° ‚áí ctranh Trung Nh·∫≠t\nT6/1940, Ph√°p b·ªã ƒë·ª©c qu·ªëc x√£ chi·∫øm ƒë√≥ng trong CTTG2 ‚Üí c∆° h·ªôi Nh·∫≠t B·∫£n chi·∫øm b√°n ƒë·∫£o ƒê√¥ng D∆∞∆°ng t·ª´ P\nT9/1940, Nh·∫≠t t·∫•n c√¥ng VN, P ch·∫°y v·ªÅ Th√°i Nguy√™n ‚Üí th·ªùi c∆° cho kh·ªüi nghƒ©a ƒë√£ ƒë·∫øn\n\n27/9/1940, chi b·ªô ƒêCS ƒêD ph√°t ƒë·ªông kh·ªüi nghƒ©a, d√†nh 1 s·ªë ƒë·ªãa b√†n\nP b·∫°i tr·∫≠n ·ªü CTTG2, b·ªã Nh·∫≠t c∆∞·ªõp quy·ªÅn ·ªü ƒê√¥ng D∆∞∆°ng\n‚áí ƒë·∫•u tranh v≈© trang gi·ªØa c√°c d√¢n t·ªôc, ƒëi·ªÉn h√¨nh l√† VN, P, N\n\n\n1941, ptrao c·ªông s·∫£n ƒë√¥ng d∆∞∆°ng b√πng n·ªï, NAQ v·ªÅ VN, tr·ª±c ti·∫øp l√£nh ƒë·∫°o CM ch·ªëng P\n19/5/1941, Vi·ªát Minh th√†nh l·∫≠p, nvu gi·∫£i ph√≥ng d√¢n t·ªôc ch·ªëng ph√°p d√†nh ƒë·ªôc l·∫≠p\n09/03/1945, Nh·∫≠t ƒë·∫£o ch√≠nh Ph√°p tr√™n to√†n b√°n ƒë·∫£o ƒë√¥ng d∆∞∆°ng, P theo ƒë√≥ ph·∫£i r·ªùi VN\n\nnh·∫≠t b·∫£n tuy√™n b·ªë trao tr·∫£ ƒë·ªôc l·∫≠p cho vi·ªát nam, th√†nh l·∫≠p v√† b·∫£o h·ªô ƒë·∫ø qu·ªëc VN, gi·ªØ nguy√™n b·ªô m√°y cai tr·ªã, thay ng nh·∫≠t v√†o v·ªã tr√≠ ng ph√°p\nN v∆° v√©t t∆∞ li·ªáu s·∫£n xu·∫•t h√†ng ho√° l∆∞∆°ng th·ª±c, c∆∞·ªõp t√†i s·∫£n c·ªßa d√¢n VN, chi·∫øm kho th√≥c ‚Üí n·∫°n ƒë√≥i 1945\n\n\n9/3-12/3/1945, ƒêCS DD ra ch·ªâ th·ªã Nh·∫≠t Ph√°p b·∫Øn nhau v√† h√†nh ƒë·ªông c·ªßa ch√∫ng ta\n\nch·ªß tr∆∞∆°ng ph√°t ƒë·ªông cao tr√†o ƒë√°nh nh·∫≠t m·∫°nh m·∫Ω\n\n\nnh·∫≠t s·ª£ ptrao c·ªông s·∫£n lan r·ªông, ƒë√£ m·ªü c√†n qu√©t b√¨nh ƒë·ªãnh, t·∫•n c√¥ng v√†o c√°c v√πng ch·ªët hi·ªÉm c·ªßa vi·ªát minh &gt;&lt; t∆∞ t∆∞·ªüng c√¥ng s·∫£n c·ªßa VN lan truy·ªÅn m·∫°nh m·∫Ω, ng d√¢n th·∫•y l·ªëi ƒëi m·ªõi tho√°t kh·ªèi xi·ªÅng x√≠ch phong ki·∫øn c≈© ‚Üí kh√¥ng ch·∫•p nh·∫≠n b√≥c l·ªôt h√† kh·∫Øc c·ªßa N.\ngi·ªØa 1945, cu·ªôc chi·∫øn ch∆∞a ƒëi xa, ƒêQ Nh·∫≠t ƒë·∫ßu h√†ng phe ƒë·ªìng minh ‚Üí t·∫°i sao\n\nVN c√≥ c∆° h·ªôi l·ªõn d√†nh l·∫°i ƒë·ªôc l·∫≠p ‚Üí 19/8/1945, VM t·ªï ch·ª©c CMT8 t·ª´ t·ªïng kh·ªüi nghƒ©a HN lan r·ªông ra kh·∫Øp B·∫Øc Trung Nam ‚Üí ƒêQ Nh·∫≠t, ch√≠nh ph·ªß ƒêQ VN do N th√†nh l·∫≠p s·ª•p ƒë·ªï. 2/9 ‚Üí khai sinh VNDCCH sau g·∫ßn 100 nƒÉm Ph√°p thu·ªôc\n\n\ntuy nhi√™n t∆∞ t∆∞·ªüng th∆∞·ª£ng ƒë·∫≥ng, th√≥i quen ƒë√†n √°p d√¢n t·ªôc kh√°c c√≤n ƒë√≥ ‚Üí Nh·∫≠t b·∫°i tr·∫≠n, m·∫•t quy·ªÅn ki·ªÉm so√°t ƒêD\n\nhi·ªáp ƒë·ªãnh Postdam, qu√¢n ƒë·ªôi Anh, 23/9/1945, ƒë·∫°i di·ªán ƒë·ªìng minh ti·∫øn v√†o gi·∫£i gi√°p qu√¢n nh·∫≠t ·ªü nam vi·ªát nam.  Theo ch√¢n A, P ƒë∆∞a qu√¢n tr·ªü l·∫°i ƒê√¥ng D∆∞∆°ng ph·∫£i ti·∫øp t·ª•c n·∫±m trong Li√™n hi·ªáp Ph√°p, ng d√¢n P ·ªßng h·ªô cu·ªôc chi·∫øn, cho r·∫±ng n·∫øu Ph√°p ƒë·ªÉ ƒê√¥ng D∆∞∆°ng gi√†nh ƒë·ªôc l·∫≠p, c√°c quy·ªÅn l·ª£i v√† t√†i s·∫£n c·ªßa th·ª±c d√¢n Ph√°p t·∫°i c√°c thu·ªôc ƒë·ªãa h·∫£i ngo·∫°i s·∫Ω nhanh ch√≥ng b·ªã m·∫•t theo.\n23/9/1946, P n·ªï s√∫ng t·∫•n c√¥ng s√†i g√≤n, P cho bi·∫øt h·ªç mu·ªën l√£nh th·ªï ƒê√¥ng D∆∞∆°ng ph·∫£i ti·∫øp t·ª•c n·∫±m trong Li√™n hi·ªáp Ph√°p m·ªõi ƒë∆∞·ª£c th√†nh l·∫≠p\n\n\n\n\n\nƒë·ªï b·ªô c·∫£ng h·∫£i ph√≤ng 1946\nqu√¢n ƒë·ªìng minh g·ªìm Anh v√† trung hoa d√¢n qu·ªëc ti·∫øn v√†o VN r·∫£i r√°c qu√¢n nh·∫≠t ‚Üí t·∫°o ƒëi·ªÅu ki·ªán cho Ph√°p tr·ªü l·∫°i chi·∫øm s√†i g√≤n ‚Üí Ph√°p k ch·ªâ mu·ªën ki·ªÉm so√°t mNam VN, P mu·ªën thay th·ªÉ qu√¢n T∆∞·ªüng gi·∫£i gi√°p qu√¢n nh·∫≠t ƒë·ªÉ th√¢u t√≥m to√†n b·ªô mi·ªÅn b·∫Øc\n28/2/1946 - P ƒë∆∞a nhi·ªÅu l·ª£i √≠ch ƒë·ªÉ k√≠ v·ªõi Trung Hoa D√¢n Qu·ªëc Hƒê Tr√πng Kh√°nh\n\nP bi·∫øn HP (thu·ªôc ch·ªß quy·ªÅn VNDCCH) th√†nh c·∫£ng t·ª± do ƒëvs ng Hoa\nVN t·ª©c gi·∫≠n, k th·ª´a nh·∫≠n vƒÉn b·∫£n\n\n\nb·∫•t ch·∫•p VNDCCH ph·∫£n ƒë·ªëi, ƒë·∫ßu t3/1946, P di chuy·ªÉn ra HP th·ª±c hi·ªán hi·ªáp ƒë·ªãnh tr√πng kh√°nh\n\nTHDQ vi·ªán c·ªõ ch∆∞a nh·∫≠n ƒë∆∞·ª£c l·ªánh v·ªÅ th·ª±c hi·ªán hi·ªáp ∆∞·ªõc, k ch·∫•p nh·∫≠n cho P ti·∫øn v√†o, ƒëe do·∫° n·∫øu c·ªë t√¨nh ƒë·ªï b·ªô HP, qu√¢n T s·∫Ω n·ªï s√∫ng\nqu√¢n T th·ª±c ra mu·ªën k√©o d√†i tgian v∆° v√©t c·ªßa c√°i\nP v·∫´n ti·∫øn v√†o HP ‚Üí n·ªï s√∫ng xung ƒë·ªôt n·ªï ra\n\n\nsau xung ƒë·ªôt, P hy v·ªçng ƒë√†m ph√°n v·ªõi VN ƒë·ªÉ thay qu√¢n T∆∞·ªüng ·ªü mBac VN\n\nVNDCCH t·ª´ l√¢u ƒë√£ mu·ªën Tg r√∫t v·ªÅ nc ‚Üí tr√°nh r·∫Øc r·ªëi ‚Üí hi·ªáp ƒë·ªãnh s∆° b·ªô: ho√† ho√£n v·ªõi P\n\n\n18/3/1946: Tg r√∫t kh·ªèi mB, P cho qu√¢n ƒë√≥ng t·∫°i c·∫£ng HP v√† d·∫´n qu√¢n l√™n HN\n\nk l√¢u sau, P vi ph·∫°m Hƒê: cho qu√¢n chi·∫øm ƒë√≥ng c√°c v·ªã tr√≠ quan tr·ªçng ·ªü HP (s·ªü thu·∫ø quan, ng√¢n h√†ng, c·∫£ng HP g·∫ßn nh∆∞ b·ªã phong to·∫£ ) ‚Üí nhi·ªÅu bi·ªÉu t√¨nh, meeting ph·∫£n ƒë·ªëi P\nƒë·ªÉ c·ª©u v√£n cƒÉng th·∫£ng ‚Üí VNDCCH c·ª≠ ng ƒë·∫øn h·ªôi ngh·ªã fontainebleau ƒë√†m ph√°n\ntrong l√∫c ƒë√†m ph√°n di·ªÖn ra, P ti·∫øp t·ª•c can thi·ªáp thu·∫ø quan ·ªü HP, ng·∫ßm ·ªßng h·ªô ng bu√¥n b√°n n∆∞·ªõc ngo√†i tr·ªën thu·∫ø ·ªü VN\n\n\nT9/1946: t·∫°m ∆∞·ªõc vi·ªát ph√°p\n\nh√†nh ƒë·ªông g√¢y h·∫•n c·ªßa Ph√°p k d·ªãu ƒëi\nt·ªè thi·ªán ch√≠ c·ªßa ng V, HCM ƒë·ªÅ ngh·ªã t·ªï ch·ª©c b√≥ng ƒë√° giao h·ªØu gi·ªØa P v√† VN, ho√† 1-1, kkhi vui v·∫ª &gt;&lt; k ngƒÉn ƒëc tham v·ªçng c·ªßa P t·∫°i H·∫£i Ph√≤ng\nngay sau ƒë√≥, P ra m·ªánh l·ªánh (13706 r3s + 938pc) ch·ªâ huy l√™n k·∫ø ho·∫°ch chi·∫øm h·∫£i ph√≤ng\nVN nh·∫≠n ra kh√≥ k√©o d√†i ho√† ho√£n ‚Üí HCM chia th√†nh 12 chi·∫øn khu\n\n\nT11/1946\n\nP t·∫•n c√¥ng tr·ª• s·ªü h·∫£i quan t·∫°i HP &gt;&lt; VN ph·∫£n ƒë·ªëi, kdinh ch·ªß quy·ªÅn trong ki·ªÉm so√°t vde lquan xu·∫•t nh·∫≠p kh·∫©u &gt;&lt; P v·∫´n c√¥ng khai g√¢y chi·∫øn\n23/11/1946, HCM v·∫´n thi·ªán ch√≠ k√™u g·ªçi Pari ƒë√¨nh chi·∫øn tr√°nh ƒë·ªï m√°u (nh√¢n nh∆∞·ª£ng &gt;&lt; chu·∫©n b·ªã ti·ªÅm l·ª±c m·ªçi m·∫∑t)  &gt;&lt; P k d·ª´ng l·∫°i ‚Üí VN quy·∫øt d√†nh l·∫°i HP\nchi·∫øn khu tr∆∞·ªüng khu 3 (Ho√†ng Minh Th·∫£o, khu 3 g·ªìm h·∫£i ph√≤ng) trƒÉn tr·ªü ra l·ªánh cho d√¢n th∆∞·ªùng &amp; llvt r√∫t kh·ªèi HP, ƒë·ªÉ l·∫°i nh√≥m nh·ªè ph√° P &amp; x√¢y tuy·∫øn ph√≤ng th·ªß ngo·∫°i th√†nh th√†nh ph·ªë, ch·ªët gi·ªØ c√°c c·ª≠a ng√µ (ph√° s·∫≠p c·∫ßu, th√°o r·ª° ƒë∆∞·ªùng s·∫Øt HP H·∫£i DG, ƒë·ªï ƒë√° ngƒÉn s√¥ng)\n28/11/1946: VN r√∫t ho√†n to√†n ra kh·ªèi n·ªôi th√†nh HP\nsau tr·∫≠n cam l·ªô, chi·∫øn s·ª± gi·∫±ng co k√©o d√†i cho ƒë·∫øn ƒë·∫ßu th√°ng 12\n\n\nT12/1946:\n\nP ho√†n to√†n ki·ªÉm so√°t HP, chi·∫øm th√™m L·∫°ng S∆°n &amp; ƒêN\nk·∫øt th√∫c chi·∫øn d·ªãch HP 1946\n\nƒë·ªÉ ph√°t ƒë·ªông chi·∫øn tr√™n to√†n VN, P g·ª≠i √≠t nh·∫•t 3 t·ªëi h·∫≠u th∆∞, ycau ch√≠nh ph·ªß HCM gi·∫£i gi√°p qu√¢n s·ª± ƒë·ªÉ P n·∫Øm quy·ªÅn ki·ªÉm so√°t ‚áí HCM ra k√™u g·ªçi To√†n Qu·ªëc Kh√°ng Chi·∫øn\nBlum - th·ªß t∆∞·ªõng m·ªõi ·ªü P, b·∫•t ng·ªù k√™u g·ªçi gi·∫£i quy·∫øt xung ƒë·ªôt ·ªü ƒë√¥ng d∆∞∆°ng theo c√°ch trao l·∫°i ƒë·ªôc l·∫≠p cho VNDCCH ‚Üí th√¥ng ƒëi·ªáp t√≠ch c·ª±c nh·∫•t ‚Üí HCM g·ª≠i b·ª©c th√¥ng ƒëi·ªáp t·ªõi Blum, g·ª£i √Ω c·ª• th·ªÉ c√°ch gi·∫£i quy·∫øt xung ƒë·ªôt (Sainteny - ƒë·∫°i di·ªán P, g·ª≠i v√†o SG r·ªìi sang Pari)\n16/12: √¢m m∆∞u x√¢m chi·∫øm VN, t∆∞·ªõng Valluy ph·ªï bi·∫øn plan ƒë√°nh chi·∫øm h√† n·ªôi v√† c·∫£ ph√≠a b·∫Øc vƒ© tuy·∫øn 16 cho c√°c t∆∞·ªõng lƒ©nh P (nh·∫•n m·∫°nh ph√° ho·∫°i ch∆∞·ªõng ng·∫°i v·∫≠t Vi·ªát Minh d·ª±ng ‚Üí khi√™u kh√≠ch ng∆∞·ªùi vi·ªát t·∫°o ra xung ƒë·ªôt ‚Üí valluy m∆∞·ª£n c·ªõ xung ƒë·ªôt ·ªü HN, c·∫£nh b√°o th·ªß t∆∞·ªõng P th·∫≠n tr·ªçng v·ªõi th√¥ng ƒëi·ªáp HCM)\n18/12: P ƒë∆∞a ra 2 t·ªëi h·∫≠u th∆∞ y√™u c·∫ßu VNDCCH ch·∫•m d·ª©t d·ª±ng ch∆∞·ªõng ng·∫°i v·∫≠t, ƒëe do·∫° t·ª´ 20/12 qu√¢n ph√°p s·∫Ω t·ª± ƒë·∫£m nhi·ªám tr·ªã an HN\nt·ªëi 18/12: VM ph·ª•c k√≠ch t·ª´ ngo·∫°i √¥ ‚Üí TP, k√™u g·ªçi ng d√¢n n√¢ng c·∫£nh gi√°c tu√¢n th·ªß k·ª∑ lu·∫≠t ch·ªù l·ªánh m·ªõi ƒëc t·∫•n c√¥ng. trong n·ªôi th√†nh, ph·ªë x√° th∆∞a th·ªõt b√≥ng ng, nh√† c·ª≠a ƒë√≥ng k√≠n, nh∆∞ng th·ª±c ch·∫•t b√™n trong t·ª´ ban c√¥ng, c·ª≠a s·ªï ƒë·∫øn m√°i nh√† ƒë·ªÅu tr·ªü th√†nh v·ªã tr√≠ ph√≤ng ng·ª±. t∆∞·ªùng trong nh√†, ngo√†i s√¢n, tr√™n g√°c ƒë·ªÅu ƒë∆∞·ª£c ƒë·ª•c th√†nh l·ªó giao th√¥ng di chuy·ªÉn t·ª´ nh√† ƒë·∫øn nh√†, t·∫°o tr·∫≠n ƒë·ªãa chi·∫øn ƒë·∫•u li√™n ho√†n\ns√°ng 19/12: P ra t·ªëi h·∫≠u th∆∞ #3, ƒë√≤i ch√≠nh ph·ªß VN ƒë√¨nh ch·ªâ m·ªçi hƒë chu·∫©n b·ªã chi·∫øn tranh, cho qu√¢n ƒë·ªôi P duy tr√¨ an ninh trong tpho, do·∫° c∆∞·ªõp v≈© khi qu√¢n t·ª± v·ªá HN\nHCM tri·ªáu t·∫≠p h·ªôi ngh·ªã TW ƒë·∫£ng m·ªü r·ªông, ƒë√£ so·∫°n s·∫µn l·ªùi k√™u g·ªçi tqkc. V√µ Nguy√™n Gi√°p ra m·ªánh l·ªánh chi·∫øn ƒë·∫•u.\n\nc∆° quan ƒë·∫ßu n√£o r√∫t kh·ªèi n·ªôi th√†nh ƒë·ªÉ b·∫£o to√†n l·ª±c l∆∞·ª£ng\nC∆° quan m·∫≠t m√£ b·ªô t·ªïng tham m∆∞u truy·ªÅn ƒëi b·∫£n m·∫≠t l·ªánh\n\nt·ªïng tham m∆∞u quy ∆∞·ªõc khi ƒë√†i ti·∫øng n√≥i ph√°t c√¢u l√∫c ƒë√∫ng 20h 19/12/1946 ‚Äúƒë·ªìng b√†o ch√∫ √Ω‚Äù - t√≠n hi·ªáu t·ªïng giao chi·∫øn\nkho·∫£ng 20 gi·ªù ng√†y 19/12/1946, c√¥ng nh√¢n nh√† m√°y ƒëi·ªán Y√™n Ph·ª• ph√° m√°y, c·∫£ th√†nh ph·ªë t·∫Øt ƒëi·ªán + ƒë√†i ti·∫øng n√≥i ph√°t ‚Äúƒë·ªìng b√†o ch√∫ √Ω‚Äù ‚Üí hi·ªáu l·ªánh chi·∫øn ƒë·∫•u to√†n th√†nh, m·ªü ƒë·∫ßu kh√°ng chi·∫øn to√†n qu·ªëc.\n\n\n\n\n\n\n\nTinh th·∫ßn d√¢n t·ªôc\nB·ªëi c·∫£nh th·∫ø gi·ªõi ·∫£nh h∆∞·ªüng ƒë·∫øn Ph√°p - Ph√°p r∆°i v√†o th·∫ø ph·∫£i chi·∫øn\n\nNh·∫≠t chi·∫øm b√°n ƒë·∫£o ƒë√¥ng d∆∞∆°ng t·ª´ P (v√¨ c·∫ßn t√†i nguy√™n t·ª´ c√°c nc thu·ªôc ƒë·ªãa ƒë√¥ng d∆∞∆°ng, [link](TO√ÄN C·∫¢NH CHI·∫æN TRANH VI·ªÜT NAM - CHI·∫æN TRANH ƒê√îNG D∆Ø∆†NG - YouTube) 10:50)\nphong tr√†o QTCS ·∫£nh h∆∞·ªüng t·ªõi Ph√°p\n\n\nB·ªëi c·∫£nh ·∫£nh h∆∞·ªüng ƒë·∫øn Vi·ªát Nam - Vi·ªát Nam r∆°i v√†o th·∫ø kh√¥ng th·ªÉ nh√¢n nh∆∞·ª£ng\n\n\n\nreply: ch·ª©ng minh ngay c·∫£ khi ch√∫ng t√¥i ·ªü trong th·∫ø gi·ªõi c·ªßa c√°c b·∫°n, lu·∫≠n ƒëi·ªÉm c·ªßa ch√∫ng t√¥i v·∫´n ƒë√∫ng\n\nph√°p th·∫Øng k b·∫°i tr·∫≠n trong th√¨ l√≤ng tham v·∫´n v√¥ ƒë√°y\n\n\n\n\nm·∫´u thu·∫´n l·ªõn nh·∫•t v√¨ sao k th·ªÉ k x·∫£y ra ƒë√¥ng d∆∞∆°ng l·∫ßn 1 l√† g√¨"},"history2/make-in-vi·ªát-nam-his2":{"title":"make in vi·ªát nam his2","links":[],"tags":[],"content":"\n\n\nk·∫ø ho·∫°ch marshall P nh·∫≠n h·ªó tr·ª£ t·ª´ m·ªπ\n\n\nt·ªï ch·ª©c nhi·ªÅu c∆° h·ªôi ƒë∆∞·ª£c qu·ªëc t·∫ø c√¥ng nh·∫≠n\n\nh·ª£p t√°c v·ªõi c√°c b√™n c√≥ t√™n tu·ªïi\n\npay it forward, gi√∫p t√™n tu·ªïi h·ªç th√¢m nh·∫≠p th·ªã tr∆∞·ªùng vi·ªát nam\nƒë·ªëi t√°c l√†\n\n\n\n\n\nt·∫°o ra c√°c h·ªó tr·ª£ ƒëi n∆∞·ªõc ngo√†i h·ªçc t·∫≠p, ph√°t tri·ªÉn, v·ªÅ VN ph·ª•c v·ª•\n\nVingroup scholarship\n\n\n\nƒë·∫ßu t∆∞ v√†o gi√°o d·ª•c\n\n"},"history2/reflection-lecture-3-his2":{"title":"reflection lecture 3 his2","links":[],"tags":[],"content":"good\n\nresearch well about different topics\n1 bonus point for answer\n\nimprove\n\nfocus on getting the main idea of the topic ‚Üí get points by answering more than questioning\nfocus on self interpretation, think in multiple perspective\nask thought-provoking questions, start with why\nevery words you speak out has to be:\n\ndirect to the point in 1 sentences of max 8 words\nexplain later if asked\n\n\ntake note questions from others, esp good questions with 2 bonus pts\n"},"history2/ƒë∆∞·ªùng-s·∫Øt-b·∫Øc-nam":{"title":"ƒë∆∞·ªùng s·∫Øt b·∫Øc nam","links":[],"tags":[],"content":"note\n\n\nC√¢u 3: T·∫°i sao Ph√°p x√¢y d·ª±ng ƒë∆∞·ªùng s·∫Øt B·∫Øc Nam? B√¢y gi·ªù c√≥ c·∫ßn x√¢y d·ª±ng ƒë∆∞·ªùng s·∫Øt B·∫Øc Nam kh√¥ng?\n\n\nnƒÉng l·ª±c v·∫≠n chuy·ªÉn, ti√™u chu·∫©n tƒÉng cao, th·ªùi gian ƒëi l·∫°i th·∫•p\n‚Üí t·∫°i sao l·∫°i c·∫ßn x√¢y d·ª±ng m√† kh√¥ng s·ª≠ d·ª•ng v√† n√¢ng c·∫•p nh·ªØng csht hi·ªán c√≥ nh∆∞ ƒë∆∞·ªùng h√†ng kh√¥ng\n\n\nan to√†n (k c√≥ ch·∫Øn ngang qua ƒë∆∞·ªùng), tin c·∫≠y (ƒëk th·ªùi ti·∫øt, √πn t·∫Øc gthong), m√¥i tr∆∞·ªùng (ƒë∆∞·ªùng s·∫Øt th·∫£i co2 √≠t h∆°n h·∫≥n)\n\n\nc√≥ gi·∫£i ph√°p n√†o s·ª≠ d·ª•ng nh·ªØng h·ªá th·ªëng v·∫≠n chuy·ªÉn\n\n\nƒë∆∞·ªùng s·∫Øt t·ªëc ƒë·ªô cao ng·∫ßm\n\n\nng√¢n s√°ch x√¢y d·ª±ng ƒë∆∞·ªùng s·∫Øt c√°t linh\n\n\n\n\n\n2 v·∫•n ƒë·ªÅ n·ªïi c·ªôm: t·∫Øc ngh·∫Ωn ‚Üí v·∫≠n chuy·ªÉn h√†ng ho√° + v·∫≠n chuy·ªÉn h√†nh kh√°ch ƒëang qu√° t·∫£i\n\n\ncriteria: nƒÉng l·ª±c v·∫≠n chuy·ªÉn ƒë∆∞·ªùng b·ªô, ti√™u chu·∫©n tƒÉng cao, th·ªùi gian ƒëi l·∫°i th·∫•p\n\n\nwhy better:\n\n\nc√≥ c√°ch n√†o ƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ (qu√° t·∫£i trong v·∫≠n chuy·ªÉn h√†ng ho√° v√† h√†nh kh√°ch) b·∫±ng c√°ch s·ª≠ d·ª•ng nh·ªØng c∆° s·ªü h·∫° t·∫ßng s·∫µn c√≥ v√† n√¢ng c·∫•p l√™n, thay v√¨ ph·∫£i ƒë·∫≠p m·ªõi, v√† hi·ªáu qu·∫£ h∆°n v·ªÅ m·∫∑t ng√¢n s√°ch + m√¥i tr∆∞·ªùng + t√≠nh kh·∫£ thi\n\n\nqu√° t·∫£i ‚Üí ƒë∆∞·ªùng b·ªô cao t·ªëc v√† ƒë∆∞·ªùng s·∫Øt cao t·ªëc\n\n\nƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ qu√° t·∫£i, 2 ph∆∞∆°ng √°n c√°ch kh·∫£ thi nh·∫•t ƒëang l√† ƒë∆∞·ªùng b·ªô cao t·ªëc v√† ƒë∆∞·ªùng s·∫Øt cao t·ªëc\n\n90% ch√∫ng ta l·ªá thu·ªôc v√†o n∆∞·ªõc ngo√†i do ch∆∞a ƒë·ªß tr√¨nh ƒë·ªô, nƒÉng l·ª±c, t·ª´ kh√¢u c√¥ng ngh·ªá, v·∫≠t t∆∞, nguy√™n nhi√™n v·∫≠t li·ªáu ƒë·∫øn v·∫≠n h√†nh.\nng√¢n s√°ch + m√¥i tr∆∞·ªùng + t√≠nh kh·∫£ thi\n\n\n\nƒê∆∞·ªùng b·ªô tr∆∞·ªõc hay ƒë∆∞·ªùng s·∫Øt tr∆∞·ªõc?\n\n\n\n\n\nkbt g√¨ nh∆∞ng mu·ªën l√†m ‚Üí d·ª±a v√†o ai ƒë·ªÉ h·ªçc ƒë∆∞·ª£c ‚Üí chuy·ªÉn giao c√¥ng ngh·ªá ‚Üí ƒëi theo h·ªçc ng∆∞·ªùi gi·ªèi nh·∫•t\n\nm·∫•u ch·ªët t·∫•t c·∫£ d·ª± √°n l√† l√†m tnao n·∫Øm ƒë∆∞·ª£c c√¥ng ngh·ªá ƒë·∫•y\n\n\n\nv√¨ sao ph√°p x√¢m chi·∫øm ƒë∆∞·ª£c ‚Üí c√≥ m·ª•c ƒë·ªãch n·ªïi c·ªôm &amp; r√µ r√†ng\n\n\nƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ qu√° t·∫£i, ch√∫ng ta n√™n ∆∞u ti√™n ƒë∆∞·ªùng b·ªô tr∆∞·ªõc hay ƒë∆∞·ªùng s·∫Øt tr∆∞·ªõc\n\n\nng√¢n s√°ch:\n\n\n\n\n\nC√≥ nhi·ªÅu √Ω ki·∫øn ph·∫£n bi·ªán ƒë√°ng suy nghƒ© nh∆∞ c·∫ßn 16 nƒÉm l√†m xong th√¨ v·∫≠n t·ªëc 250km/h ƒë√£ l·∫°c h·∫≠u, ch∆∞a k·ªÉ ƒë·∫øn vi·ªác ch·ªü h√†ng v√† ch·ªü kh√°ch s·∫Ω ·∫£nh h∆∞·ªüng l·∫´n nhau, t√≠nh b·ªÅn v·ªØng gi·∫£i quy·∫øt ntn?\n\n\nchi ph√≠ logistic cao h∆°n nhi·ªÅu\n\n\n\n\n\ntheo b·∫°n, ng√¥n ng·ªØ gen z ƒëang l√† m·ªëi nguy hi·ªÉm hay l√† m·ªôt s·ª± ph√°t tri·ªÉn trong ng√¥n ng·ªØ ti·∫øng vi·ªát th·ªÉ hi·ªán ƒë∆∞·ª£c c√°i t√¥i\n\nc√≥ th·ªÉ ph√°t tri·ªÉn ntn\n\n\n\nnguy hi·ªÉm ƒëang b√°o ƒë·ªông t·ªõi ch·ªØ qu·ªëc ng·ªØ, v√† n·∫øu l√† vi·ªán tr∆∞·ªüng vi·ªán nn h·ªçc th√¨ b·∫°n s·∫Ω l√†m g√¨ ƒë·ªÉ b·∫£o t·ªìn v·∫ª ƒë·∫πp c·ªßa ng√¥n ng·ªØ gen z\n\n\n\nb·∫£o t·ªìn ch·ªØ qu·ªëc ng·ªØ ntn trong qu√° tr√¨nh h·ªôi nh·∫≠p v√† ti·∫øng anh tr·ªü th√†nh m·ªôt ng√¥n ng·ªØ s·ª≠ d·ª•ng h√†ng ng√†y\n*t·ª´ ch·ªØ h√°n, sang ch·ªØ n√¥m v√¨ kh√¥ng th·ªÉ bi·ªÉu di·ªÖn ƒë·∫ßy ƒë·ªß c√°c t·ª´ v·ª±ng, ng·ªØ ph√°p v√† s·∫Øc th√°i vƒÉn ho√° ti·∫øng Vi·ªát, nh∆∞ng t·ª´ ch·ªØ n√¥m sang ch·ªØ qu·ªëc ng·ªØ bi·ªÉu hi·ªán s·∫Øc th√°i vƒÉn ho√° tv r·∫•t r√µ qua d·∫•u c√¢u , v·∫´n kh√≥ ph·ªï bi·∫øn r·ªông ‚Üí\nƒë·∫øn m·ª©c ƒë√¥i khi c√≥ nh·ªØng s·ª± t·ª´ kh√°c nghƒ©a nh∆∞ng ƒë√°nh v·∫ßn, ƒë·ªçc v√† ch·ªØ vi·∫øt y chang, c√≥ d·∫•u*\nn·∫øu ko c·∫£i ti·∫øn v·∫≠y th√¨ c√≥ n√™n gi·∫£n l∆∞·ª£c?\n\n\n\nb·∫°n nghƒ© sao v·ªÅ nh·ªØng t·ª´ d·ªãch t·ª´ ti·∫øng anh sang ti·∫øng vi·ªát, c√°ch s·ª≠ d·ª•ng n√†o h·ª£p l√Ω h∆°n, n·∫øu nh∆∞ c√°ch s·ª≠ d·ª•ng ti·∫øng anh h·ª£p l√Ω h∆°n th√¨ ph·∫£i chƒÉng ta ƒëang d·∫ßn nh∆∞·ª£ng b·ªô cho vi·ªác ho√† tan ng√¥n ng·ªØ ti·∫øng vi·ªát vs ta\n\n\nc√°ch n√≥i ch√™m ti·∫øng anh v√† ti·∫øng vi·ªát, nh∆∞ b·∫°n v·ª´a n√≥i l√† c√°c c√°i terms, c√≥\n\n\nB·∫£n ch·∫•t v·ªën c√≥ c·ªßa ti·∫øng Vi·ªát nh∆∞ th·∫ø n√†o v√† vi·ªác s·ª≠ d·ª•ng ƒë√∫ng b·∫£n ch·∫•t ƒë√≥ ra sao th√¨ ƒë√≥ ch√≠nh l√† s·ª± trong s√°ng c·ªßa ti·∫øng Vi·ªát ‚Üí ko c√≥ nh·ªØng t·ª´ ch∆∞a ƒë∆∞·ª£c th√¨ c√≥ ƒëc g·ªçi m·∫•t trong s√°ng. n·∫øu mu·ªën trong s√°ng = ng·ª´ng ph√°t tri·ªÉn ng√¥n ng·ªØ ti·∫øng vi·ªát\n\n"},"index":{"title":"Map of Contents","links":["algoDesign/***algoDesign-map","artificialIntelligence/***AI-map","comOrg/***comOrg-map","DSA/***-DSA-map-(OOP-course)","probStatAdvanced/***probStatAdvanced-Map","history2/***history-2-map"],"tags":[],"content":"\n***algoDesign map\n***AI map\n***comOrg map\n*** DSA map (OOP course)\n***probStatAdvanced Map\n***history 2 map\n"},"probStatAdvanced/***probStatAdvanced-Map":{"title":"***probStatAdvanced Map","links":["probStatAdvanced/Simple-Linear-Regression-Model","probStatAdvanced/Time-series","probStatAdvanced/Finding-trend-in-a-time-series-graph","probStatAdvanced/Moving-averages","probStatAdvanced/Additive-Model---finding-seasonal-component-variations","probStatAdvanced/Multiplicative-Model---finding-seasonal-percentage-variations","probStatAdvanced/forecasting-future-values-in-time-series","probStatAdvanced/deseasonalization---removing-variations-to-indicate-trend","probStatAdvanced/Stochastic-process","probStatAdvanced/Markov-chain","probStatAdvanced/Chapman-Kolmogorov-Equations","probStatAdvanced/25-03-2024"],"tags":[],"content":"probStatAdvanced Map\nChapter 1: Simple Linear Regression\n\nSimple Linear Regression Model\n\nChapter 2:\n\nTime series\nFinding trend in a time series graph\nMoving averages\nAdditive Model - finding seasonal component variations\nMultiplicative Model - finding seasonal percentage variations\nforecasting future values in time series\ndeseasonalization - removing variations to indicate trend\n\nChapter 3: Markov Chains\n\nStochastic process\nMarkov chain\nChapman-Kolmogorov Equations\n25 03 2024\n\nnote\n\nch∆∞a l√†m h·∫øt b√†i trong slide 2\n"},"probStatAdvanced/25-03-2024":{"title":"25 03 2024","links":[],"tags":[],"content":"\nclassification of states\n\nj accessible from state i if Pijn‚Äã&gt;0 for some n &gt;= 0\n\n\naccessible: move from state i to j after certain of steps\nrelation of communication\n\ni com with i, i &gt;=0; Pij0‚Äã=P(Xk‚Äã=i‚à£Xk‚Äã=i)=1\ni com with j, then j com with i; there are such m,n such that Pijm‚Äã&gt;0andPjim‚Äã&gt;0 then j‚Üîi\ni com with j, j com with k, then i com with k; Pijn‚Äã&gt;0,j‚Üîk:Pjkm‚Äã&gt;0\n\nP_{ik}^{n+m} - chapman - \\sum\n\n\n\n\n\n\n\ntwo states that communicate ‚Üí in the same class\nany 2 classes of states - either identical or disjoint\nirreducible in markov chain if there is only 1 class\nIf A‚à™BÓÄ†=‚àÖ then A = B\n\n"},"probStatAdvanced/Additive-Model---finding-seasonal-component-variations":{"title":"Additive Model - finding seasonal component variations","links":[],"tags":[],"content":"what is additive model\n\nadditive model: Y=T+S+R\nassume random component R is negligible, the seasonal component S is: S=Y‚àíT (de-trended series)\n\nY¬†is the actual time series\nT¬†is the trend series (moving average)\nS¬†is the seasonal component (Not included in some models)\nC¬†is the cyclical component (excluded)\nR¬†is the random component\n\n\n"},"probStatAdvanced/Chapman-Kolmogorov-Equations":{"title":"Chapman-Kolmogorov Equations","links":[],"tags":["Math/probability/markovChain/chapman"],"content":"Chapman-Kolmogorov Equations\n\n\nn-step transition probabilities Pijn‚Äã: probability a process state i will be in state j after n additional transitions\n\nPijn‚Äã=P{Xn+k‚Äã=j‚à£Xk‚Äã=i},¬†n‚â•0,¬†i,j‚â•0.\n\n\n\nChapman-Kolmogorov equations to compute n-step transition probabilities\n\nPijn+m‚Äã=‚àëk=0‚àû‚ÄãPijn‚ÄãPijm‚Äã‚àÄn,m‚â•0,‚àÄi,j\n\n\n\nP(n): matrix of n-step transition probabilities Pijn‚Äã\n\nP(n+m)=P(n)‚ãÖP(m)\n‚áí n-step transition matrix obtained by multiplying P by itself n times\n\n\n"},"probStatAdvanced/Finding-trend-in-a-time-series-graph":{"title":"Finding trend in a time series graph","links":["Regression-Model"],"tags":[],"content":"how to find trend in a time series graph\nInspection:\n\nThe trend line can be drawn by eye on a graph in such a way that it appears to lie evenly between the recorded points, that is, a line of best fit drawn by eye.\n\nRegression Analysis:\n\nThis method makes the assumption that the trend line is a straight line.\nPeriods of time are numbered, and the regression line of the data on those periods is found.\nThat line is taken to be the trend.\n\nMoving Average:\n\nThis method attempts to remove seasonal variations by a process of averaging\n"},"probStatAdvanced/Markov-chain":{"title":"Markov chain","links":[],"tags":["Math/probability/markovChain"],"content":"Intro\n\n\n{Xn‚Äã,n=0,1,2,...} is a stochastic process\n\n\nIf Xn‚Äã=i ‚áí process is in state i at time n\n\n\nn‚â•0\n\n\nMarkov property: ‚Äúmemoryless‚Äù - next state depends only on current state, not the sequence of events in the past\n\n\nWhenever process in state i ‚Üí fixed probability Pij‚Äã that process will next be in state j\n\n\nP{Xn+1‚Äã=j‚à£Xn‚Äã=i,Xn‚àí1‚Äã=in‚àí1‚Äã,‚Ä¶,X1‚Äã=i1‚Äã,X0‚Äã=i0‚Äã}=Pij‚Äã\n\nfor all states i0‚Äã,i1‚Äã,‚ãØ,in‚àí1‚Äã,i,j and all n‚â•0\n\n\n\nMarkov chain: conditional distribution of any future state Xn+1‚Äã, given past states X0‚Äã,‚ãØ,Xn‚àí1‚Äã and present state Xn‚Äã, is independent of past states, and depends only on the present state\n\n\nP: matrix of one-step transition probabilities Pij‚Äã\n\n‚ÄãP00‚ÄãP10‚Äã‚ãÆ‚ÄãP01‚ÄãP11‚Äã‚ãÆ‚ÄãP02‚ÄãP21‚Äã‚ãÆ‚Äã‚ãØ‚ãØ‚Äã‚Äã\neg. P10‚Äã: from row to column ‚áí row 1, col 0\n\n\n\nsimple example: a Markov chain modeling the weather, in which we know today is sunny, can give us probability for whether tomorrow is sunny, rainy or cloudy solely based on today‚Äôs data\n\n"},"probStatAdvanced/Moving-averages":{"title":"Moving averages","links":[],"tags":[],"content":"what is moving average\n\nA series of arithmetic averages over a given number of time periods. It is the estimate of the long run average of the variable.\nHelp smoothing out the data with less peaks and valley\n\nlarge grouped data point will be more smooth\n\n\ngiven k is the amount considered in MA (eg. # of months)\n\nif considering most recent values ‚Üí small value of k is preferred\nif considering past values ‚Üí larger value of k is preferred\n\n\n\nOdd number of time periods in moving average\n\nThe average of any 3 data points becomes the value of the 2nd data point\n\nEven number of time periods in moving average\n\nFormula: ((0.5‚àóa+b+c+d+0.5‚àóe)/5), place the value in position 3, similarly for other odd time periods\nOther way: in 4 months, calculate sum of 2 months twice, then calculate that total sum\n"},"probStatAdvanced/Multiplicative-Model---finding-seasonal-percentage-variations":{"title":"Multiplicative Model - finding seasonal percentage variations","links":[],"tags":[],"content":"what is multiplicative model\n\nY=T.S.R\n\nT: original units\nS &amp; R: percentages\nif R negligible (R ~1) ‚Üí seasonal percentage: S=Y/T\n\n\n\nwhen does multiplicative outperform additive model\n\nwhen the trend is increasing or decreasing over time\nMultiplicative is often preferred as it assumes components are dependent on each other\n"},"probStatAdvanced/Simple-Linear-Regression-Model":{"title":"Simple Linear Regression Model","links":["Linear-regression"],"tags":[],"content":"title\nnote\n\nLinear regression\nHas the form¬†(y=Œ≤0‚Äã‚Äã+Œ≤1‚Äã‚Äã+œµ)\n\nSimple linear regression equation: (E(y)=Œ≤0‚Äã‚Äã+Œ≤1‚Äã‚Äãx)\nœµ: random var referred to as error term\nIn practice,¬†Œ≤0‚Äã‚Äã¬†and¬†Œ≤1‚Äã‚Äã¬†are not known, but can be estimated with¬†b0‚Äã‚Äã¬†and¬†b1‚Äã‚Äã, where¬†b0‚Äã‚Äã¬†and¬†b1‚Äã‚Äã¬†are computed by least squares method\n\n\n\nEstimated simple linear regression model:\n\n(y‚Äã^‚Äã=b0‚Äã‚Äã+b1‚Äã‚Äãx)\n\n(y^‚Äã)‚Äã¬†is the point estimator of¬†E(y)\n\n\ngraph of Estimated simple linear regression model = estimated regression line = line of best fit\n\n"},"probStatAdvanced/Stochastic-process":{"title":"Stochastic process","links":["artificialIntelligence/state-space"],"tags":[],"content":"stochastic process\n\nX(t),¬†t‚ààT\n\nA collection of random variables. For each t‚ààT, X(t) is a random variable\nThe index¬†t¬†is often interpreted as time and¬†X(t)¬†is the state of the process at time¬†t\n\nEg. X(t): total number of students visiting VinUni by time t\n\n\nThe set¬†T¬†is called the¬†index set¬†of the process.\n\nwhen T countable ‚Üí the stochastic process has discrete-time\nwhen T is an interval of real line ‚Üí the stochastic process has continuous-time\n\n\nX(t)‚àà state space\n\n\n"},"probStatAdvanced/Time-series":{"title":"Time series","links":[],"tags":[],"content":"Definition of time series:\n\na series of figures or values recorder over time\n\ntime series example\n\n\n\nComponents:\n\n4 components of time series:\n\nTime Series Trend\n\nA continuous long-term movement over time in the values recorded\nUpward, downward vs horizontal\n\nSeasonal Variation\n\nMovements in the time series that reoccur each year about the same time due to the change in the seasons.\n\nexample, the spending in ice cream is higher during summer\n\n\n\nCyclical Variation\n\nMany variables often exhibit a tendency to fluctuate above and below the long-term trend over a long period of time.\nThey cover much longer time periods than do seasonal variations.\n\nRandom Variation\n\nCaused by unusual and unexpected occurrences producing movements which have no discernible pattern.\nThese movements are unique and unlikely to reoccur in similar fashion.\nThey can be caused by events such as wars, floods, earthquakes, political elections, or oil embargoes.\n\nTime Series Models:\n\nA time series model can be expressed as some combination of these four components.\nTwo types of models are commonly associated with time series:¬†Additive Model and multiplicative model.\n\nThe additive model is expressed as¬†Y=T+S+C+R¬†where\n\nY¬†is the actual time series\nT¬†is the trend series\nS¬†is the seasonal component (Not included in some models)\nC¬†is the cyclical component (excluded)\nR¬†is the random component\n\n\nWe only consider Y=T+S+R\n\n\n"},"probStatAdvanced/deseasonalization---removing-variations-to-indicate-trend":{"title":"deseasonalization - removing variations to indicate trend","links":[],"tags":[],"content":"what is deseasonalization\n\nprocess of removing variations to leave a figure indicating trend\n"},"probStatAdvanced/forecasting-future-values-in-time-series":{"title":"forecasting future values in time series","links":[],"tags":[],"content":"how to forecasting future values in time series\n\nforecasting by extrapolation: process of estimating beyond original range, the value of a variable, on the basis of its relationship with another variable\nForecasts of future values should be made as follows.\n\nCalculate a trend line using moving averages or regression.\nUse the trend line to forecast future trend line values.\nAdjust these values by the average seasonal variation. With the additive model, add the variation. With the multiplicative model, multiply the trend value by the variation proportion\n\n\n\nnote on extrapolation\n\nextrapolation based on historical data, not including effects of developments ‚Üí can be used for short term forecasts for specific areas, where no untypical developments are expected\n"}}