{"DSA/***-DSA-map-(OOP-course)":{"title":"*** DSA map (OOP course)","links":["DSA/Kruskal's-Algorithm","DSA/Prim's-Algorithm"],"tags":[],"content":"\n\nKruskal’s Algorithm\nPrim’s Algorithm\n"},"DSA/Kruskal's-Algorithm":{"title":"Kruskal's Algorithm","links":["tags/computerScience/DSA/tree/MST","tags/fc","DSA/Prim's-Algorithm"],"tags":["computerScience/DSA/tree/MST","fc"],"content":"Context\n\nTime: 06 04 2024 - 21:51\nTags:MST\nChild:\nSource:\n\nDefinition of Kruskalfc\n\ndefinition\n\nconnected graph\nweighted edge\nresult in a MST\n\n\nalgo\n\npick the smallest edge\nrepeatedly look for the smallest edges that don’t create a cycle\nlink\nCE → AB → AD → DF → FG\nlink\nmerge sort: O(ElogE)\n\n\nalgo2:\n\nStarts to build the MST from the vertex carrying minimum weight in the graph.\nSorts all the edges in increasing order of their weight.\nPicks the smallest edge and checks if it forms a cycle with the spanning tree formed so far. If not, it includes this edge. Else, it discards it.\nRepeats the process until there are (V-1) edges in the spanning tree.\nCan generate forest (disconnected components) at any instant and can work on disconnected components.\nTraverses one node only once.\nTime complexity is O(E log V), where E is the number of edges and V is the number of vertices.\nRuns faster in sparse graphs.\n\n\n\n\nDifference with Prim’s Algo"},"DSA/Prim's-Algorithm":{"title":"Prim's Algorithm","links":["tags/computerScience/DSA/tree/MST","tags/fc","DSA/Kruskal's-Algorithm"],"tags":["computerScience/DSA/tree/MST","fc"],"content":"Context\n\nTime: 06 04 2024 - 21:55\nTags:MST\nChild:\nSource:\n\nDefinition of Prim’s Algorithmfc\n\nStarts to build the MST from any vertex in the graph.\nMaintains two sets of vertices. The first set contains the vertices already included in the MST, the other set contains the vertices not yet included.\nAt every step, it considers all the edges that connect the two sets and picks the minimum weight edge from these edges.\nAfter picking the edge, it moves the other endpoint of the edge to the set containing MST.\nGives connected component and works only on connected graph.\nTraverses one node more than one time to get the minimum distance.\nTime complexity is O(V^2), which can be improved up to O(E log V) using Fibonacci heaps.\nRuns faster in dense graphs\n\n\nDifference with Kruskal’s Algorithmfc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrim’s AlgorithmKruskal’s AlgorithmIt starts to build the Minimum Spanning Tree from any vertex in the graph.It starts to build the Minimum Spanning Tree from the vertex carrying minimum weight in the graph.It traverses one node more than one time to get the minimum distance.It traverses one node only once.Prim’s algorithm has a time complexity of O(V2), V being the number of vertices and can be improved up to O(E log V) using Fibonacci heaps.Kruskal’s algorithm’s time complexity is O(E log V), V being the number of vertices.Prim’s algorithm gives connected component as well as it works only on connected graph.Kruskal’s algorithm can generate forest(disconnected components) at any instant as well as it can work on disconnected componentsPrim’s algorithm runs faster in dense graphs.Kruskal’s algorithm runs faster in sparse graphs.It generates the minimum spanning tree starting from the root vertex.It generates the minimum spanning tree starting from the least weighted edge.Applications of prim’s algorithm are Travelling Salesman Problem, Network for roads and Rail tracks connecting all the cities etc.Applications of Kruskal algorithm are LAN connection, TV Network etc.Prim’s algorithm prefer list data structures.Kruskal’s algorithm prefer heap data structures.^1712415352340"},"algoDesign/***algoDesign-map":{"title":"***algoDesign map","links":["algoDesign/algorithm-design-process","algoDesign/stable-matching-problem","algoDesign/Gale-Shapley-Algorithm","algoDesign/algorithm-analysis--and--efficiency--and--worst-case-runtime","algoDesign/big-o-notation","algoDesign/big-omega-notation","algoDesign/big-theta-notation","algoDesign/huffman-coding","algoDesign/Depth-First-Search---DFS","algoDesign/Lab-2-algo-des","algoDesign/Lab-3-algo-des","algoDesign/Lab-4-algo-des","algoDesign/Lab-5-algo-des"],"tags":[],"content":"*** algoDesign map\nLec 01: intro to algos and stable matching problem\n\nalgorithm design process\nspecific algo learned during the course\n\ngreedy\ndivide and conquer\ndynamic programming\nnetwork flows\n\n\nstable matching problem\n\nGale Shapley Algorithm\n\n\n\nLecture 02: Basic of Algorithm Analysis\n\nalgorithm analysis &amp; efficiency &amp; worst case runtime\n\nbig-o notation\nbig-omega notation\nbig-theta notation\n\n\n\nGreedy Algo 1\n\ncoin changing\n\ncons of greedy: only care about present, not the future; lack of backtracking!!\n\n\ninterval scheduling\ninterval partitioning\nscheduling to minimal lateness\nhuffman coding\nDepth First Search - DFS\n\n\nLab\nLab 2 algo des\nLab 3 algo des\nLab 4 algo des\nLab 5 algo des"},"algoDesign/Depth-First-Search---DFS":{"title":"Depth First Search - DFS","links":[],"tags":[],"content":"implementation\ndef dfs(matrix, start):\n    visited = []\n    stack = [start]\n \n    while stack:\n        vertex = stack.pop()\n        if vertex not in visited:\n            visited.append(vertex)\n            for i in range(len(matrix)):\n                if matrix[vertex][i] and i not in visited:\n                    stack.append(i)\n \n    return visited\n \nn = int(input())\nmatrix = [list(map(int, input().split()))for _ in n]\nstart = int(input())\ndfs(matrix, start)"},"algoDesign/Gale-Shapley-Algorithm":{"title":"Gale Shapley Algorithm","links":[],"tags":[],"content":"Propose-and-Reject (Gale-Shapley) Algorithm\n\n\n\n\ntheoretical explanation\n\neverybody (all those from the 2 sides) submit their preference list, ranking the other side\n1st side choosing other people of the 2nd side. those of 2nd side with many selections will reject all but their top suitors. Those who match will form a tentative pair\neach 1st side people rejected then propose the their next rank choices (whether their choices are free or not). 1st side and 2nd side people, forming the previously tentative pair, can reconsider and make new pair\niterate step 1-3\n\n\nexample\n\n\n\n\n\nimplementation\n\nyoutu.be/o1olHmxDzTw\n\nalgorithm analysis\n\ntermination guaranteed? → Yes, at most n2 proposals/rounds of the algorithm\n\nn men, in worst case, each man has to propose to n women in order to find a match ⇒ n2\n\n\neveryone gets a match guaranteed? → Yes\n\n\n\n\nresult allocation guaranteed stable? → Yes\n"},"algoDesign/Lab-2-algo-des":{"title":"Lab 2 algo des","links":[],"tags":[],"content":"Theory Practice\nQuestion 1\n\nSecond loop runs from 0 to i2−1 → when j%i, the third loop will run 1,i,2i,⋯ times\nTotal loop: 1+i+2i+⋯+(i−1)i=1+2i2(i−1)​ ⇒ Complexity is O(n3)\n⇒ Total complexity: O(n4) (count the first loop)\n\nQuestion 2\n\n\nTo prove that f1​+f2​=θ(max{f1​(n),f2​(n)}), we need to show there exists positive constants k1​,l2​,n0​ such that ∀n≥n0​ we have:\n\nk1​.max(f1​,f2​)≤f1​+f2​≤k2​.max(f1​,f2​)\n\n\n\nWLOG, we assume f1​≤f2​ so we have to prove\n\nk1​.f2​≤f1​+f2​≤k2​.f2​\n\n\n\nWith k2​=2, the right inequality always hold as f1​+f2​≤f2​+f2​=2⋅f2​\n⇒ By choosing k1​=1,k2​=2, and any n0​\n\n\nFrom the definition, we have f(n)=θ(g(n)) ⇒ f is asymptotically positive (f&gt;0).\n\n\nWith k1​=1, the left inequality always hold as f1​+f2​≥f2​(sincef≥0)\n⇒ Proving max(f1​,f2​)=θ(f1​−f2​)  is now finding k1​,k2​\nand n0​ such that for all n≥n0​ we have:\nk1​⋅(f1​−f2​)≤max(f1​,f2​)≤k2​⋅(f1​−f2​). With f1​=x,f2​=x−1 ⇒ k1​⋅1≤x≤k2​⋅1\nAs x varies, it is impossible to find such constants k1,k2 ⇒ The statement is then disproved\n\n\nQuestion 3:\n\nWe can use Hash Set, in which we will gradually append an element into the Hash Set. We then will not append an element that already appears in the Set\nThe operation of adding an element to the Set and checking whether there already has that element has the complexity of O(n)\nthe suggested code\n\ndef removeDuplication(arr):\n\thash_Set = set()\n\tfor i in arr:\n\t\tif i not in hash_Set:\n\t\t\thash_Set.add(i)\n\tprint(hash_Set)\n \nremoveDuplication([1,2,4,4,6,2,4,7,6])\n\nthis will output:\n\n{1, 2, 4, 6, 7} # a set of integers with no duplications\nQuestion 4:\n\nThe worst case running time of this algorithm:\n\nfor subproblems with size ≤k, the algorithm uses insertion sort, with worst case time complexity is O(k2)\nThe complexity of using Merge sort with problem size k in this case is O(log(n/k)). As each layer requires O(n) for merging, the complexity for this process if O(nlogkn​)\nThe complexity of using Insertion sort with the problem size k in this case is O(k2.kn​)=O(nk)\nTotal complexity would be: O(nk+nlogkn​)\n\n\n\nQuestion 5:\nWe have: ∑i=2∞​i1​≤∫1n​x1​⟺H(n)≤∫1n​x1​+1−ln(n)+1\nWe also have: ∑i=1∞​21​≥∫1n​x1​⟺H(n)≥ln(n)\n⇒ ln(n)≤H(n)≤ln(n)+1"},"algoDesign/Lab-3-algo-des":{"title":"Lab 3 algo des","links":[],"tags":[],"content":"Theory\nQuestion 1:\n\nThe proposed solution of iteratively choosing the position to build new stations, maximizing the number of new towns covered, is not necessarily optimal.\nExample:\n\nConsider a scenario where the towns along the railroad path are arranged in a zigzag pattern\nThe algorithm starts by selecting the first town and building a train station at that position\nAs it iterates through the towns, it will continue to build train stations at every other town, alternating between the upper and lower positions\n⇒ This approach may result in a higher number of train stations being built compared to an optimal solution\n\n\n\n\nAn optimal solution would identify that building train stations only at the upper or lower positions, rather than both, can cover all the towns within the required distance D\nBy selecting the upper or lower positions strategically, the optimal solution can achieve the same coverage with fewer train stations\n\nQuestion 2:\n\nThe workers have 2 actions: load package on current truck or let current truck go and load on new truck\nCurrent procedure: load each truck to full capacity before moving to next truck\n\n\nCase 1: Package is too big for current truck - no difference between company’s solution and optimal solution\nCase 2: Package can fit in current truck - company’s solution always loads on current truck, optimal solution may load on next truck\nIf both solutions have same actions up to a point, optimal solution will use one more truck than company’s solution. So if number of packages loaded is the same, but optimal solution uses one more truck ⇒ not actually optimal\n⇒ Company solution is optimal\n\nQuestion 3:\n\nWhat makes Prim’s algorithm “greedy”?\n\nThe algorithm makes the optimal choice at each iteration by selecting the shortest edge that connects a vertex outside the tree to a vertex in the tree.\n\n\nTime and space complexity for Prim’s algorithm:\n\nTime complexity:\n\nO((n + m) log n), where n is the number of vertices and m is the number of edges in the graph\nReason: The algorithm iterates through all vertices and their neighbors, and the priority queue operations take O(log n) time.\n\n\nSpace complexity:\n\nO(n), where n is the number of vertices\nReason: The algorithm need to store all the edges of the graph (O(m)) and all vertices of the graph (O(n))\n\n\n\n\nDoes Prim’s algorithm always return the optimal solution:?\n\nYes, Prim’s algorithm always returns the optimal solution, which is the minimum spanning tree. This can be proven by showing that at each iteration, the algorithm selects the shortest edge that connects a vertex outside the tree to a vertex in the tree. By always choosing the shortest edge, the algorithm ensures that the total weight of the edges in the tree is minimized.\n\n\n\nQuestion 4\n\nThe robot’s algorithm finds a peak in a 2-D mountain range near its starting point\nHowever, it may get stuck in a local maximum and miss potentially taller global maximums\nIn a 3D case, the algorithm needs to consider multiple angles with varying granularity, in which a smaller angle granularity leads to higher computational costs\nTo improve the algorithm’s performance, steps can be introduced where the robot moves towards the point determined by gradient descent\nThe distance of each move determines the next step to consider\nFor example, if going higher by gradient descent brings a 5-meter increase, the next steps will scan a larger distance around it (e.g., 1/5 meter further)\nThis way, the robot considers a greater distance as it gets closer to its local maximum. And this approach may help the algorithm find the global maximum more efficiently.\n"},"algoDesign/Lab-4-algo-des":{"title":"Lab 4 algo des","links":[],"tags":[],"content":"Question 1:\nWe can use the Prim’s algorithm to find the Minimum Spanning Tree\n\nPick the edge with minimum weight from the edges set; for example, we pick edge (0,1) with weight 2\nRepeatedly picking edges with weight 2, we will result in [(0,1),(1,2),⋯,(n−1,n)] with nodes [0,1,2,⋯]\nOur minimum spanning tree then will have the weight of ∑i=1n​2∣i−(i−1)∣=2n\n\nQuestion 2:\n\nApproach:\n\nFinding maximum vehicle height using modified Prim’s algorithm.\n\n\nAlgorithm Steps:\n\nSort edges by weight (descending).\nRepeat until all nodes are explored:\na. Select edge with maximum weight d\nb. Determine maximum allowable height at the intersection d\nc. Mark other end of road (nodes) as explored\n\n\nAlgorithm Characteristics:\n\nTime complexity: O(Blog V)\nSpace complexity: O(B + V)\n\n\n\nQuestion 3:\n\nGreedy: At each step, the algorithm chooses the two symbols with the lowest frequencies, without considering their future impact on the encoding of other symbols.\nOptimal substructure: Huffman coding constructs an optimal prefix code by recursively merging the two least frequent characters into a single node. This process repeats until a single root node remains. The efficiency of this method is due to Huffman coding’s optimal substructure property.\n\nQuestion 4:\n\n\n\n\n\n\naaaaaaaabbbbccccddee→ 00000000100100100100101101101101110110111111\n"},"algoDesign/Lab-5-algo-des":{"title":"Lab 5 algo des","links":[],"tags":[],"content":"Algorithm Design - Spring 2024\nPham Quynh Trang\nV202200890\nQuestion 1:\n\nAlgorithm\n\nIterate through nodes in sorted order\nRemove each outgoing arc temporarily &amp; check if resulting graph is a valid topological ordering (using the Topological Sort function)\nIf yes, arc can be removed; otherwise, restore it\n\n\n\nQuestion 2:\na) Maximizing Minimum Weight of Edge:\n\nObservations:\n\nDetermining the existence of a perfect matching in a graph is straightforward, regardless of edge weights.\nConstruct a graph G(h) from Kn,n using only edges with weights at least h.\nThe perfect matching, M, in Kn,n maximizing the minimum edge weight contains exactly n edges.\nIf there’s a perfect matching in G(h), M in Kn,n must have a minimum edge weight ≥h\n\n\nApproach:\n\nFind the largest possible h such that a perfect matching exists in G(h), employing binary search\nThe perfect matching in G(h) becomes the desired solution in Kn,n, maximizing the minimum edge weight\n\n\n\nb) Maximizing Product of Chosen Edges’ Weights\n\nAlgorithm Choice: One option is to use Max-flow Algorithm\nKey Observation:\n\nUtilize the property log(a∗b)=log(a)+log(b).\nConvert the problem into finding a max-flow that maximizes the log-weight.\n\n\nSolution Approach: Apply the minimum-cost maximum-flow algorithm to discover the perfect matching maximizing the product of chosen edges’ weights\n\nThe minimum-cost maximum-flow algorithm is a graph algorithm used to find the maximum flow in a network with minimum cost. It involves finding the optimal flow from a source to a sink while minimizing the total cost associated with sending the flow through the network.\nMethods:\n\nRepresent the graph with edge weights as costs.\nApply the minimum-cost maximum-flow algorithm to find the maximum flow that minimizes the total cost, which in this case corresponds to maximizing the sum of logarithmic weights.\nThe resulting flow corresponds to the desired perfect matching, achieving the objective of maximizing the product of chosen edges’ weights.\n\n\n\n\n\nQuestion 3:\n\n\na.  List of edges must be in the MST regardless of the missing cost values\n\nApplying Kruskal algorithm, we will sort the edges in ascending order. ⇒ We have:\n\nGH = 2 &lt; BD = 3 &lt; BC = 9 &lt; AC = 10 &lt; DC = 15 &lt; AB = 20\nIf there are &gt;4 edges with cost &lt;=2, GH might not be chosen in the MST ⇒ GH is not a must choose edge\nBD will then be chosen next or chosen after some edges have cost &lt;=3. It will not be the last edge chosen, as it need at least 6 edges to connect vertices A, C, E, F, G, H and form MST. If we do not use BD, either AB or BC must be used to connect all vertices and form MST, in which each of these edges all cost more than BD ⇒ BD is a must choose edge\nBC is not a must choose edge (as proven above)\nSuppose that C has not been connected, it will either be connected by AC or BC as among all those known edge weights, AC &lt; BC &lt; DC. But BC is not an optimal selection ⇒ we choose AC ⇒ AC is a must choose edge to make sure it will go through all the nodes in optimal paths\nb. Edges cannot be added in the MST are AB and CD. As the Kruskal algorithm will always choose BD, BC, or AC before AB and CD.\n\n\n\n\n\nQuestion 4:\n\nGoal: Determine existence of a simple cycle through edge (s,t) with cost ≤ γ.\n\nFind a simple path from t to s with minimum cost.\nUse edge (s,t) to form the cycle with minimum cost, including (s,t).\n\n\nDistances:\n\nDefine dist(t,s) as the minimum cost of the simple path from t to s.\nCheck if dist(t,s)+cs,t≤γ\n\n\nProcedure:\n\nFind the minimum cost simple path from t to s.\nAdd the cost of edge (s,t) to determine if the cycle satisfies the condition.\n\n\n\nQuestion 5:\n\nInitialization: Initialize a variable ‘res’ to a vertex, starting at 0. Eventually, ‘res’ might become the universal sink.\n\n‘res’ is set to a vertex, initially 0.\n\n\nComparison:\n\nCompare ‘res’ with each subsequent vertex to determine its potential as a universal sink.\nIf there’s an edge from ‘res’ to the current vertex, update ‘res’ to the current vertex.\nOtherwise, keep ‘res’ unchanged.\n\n\nVerification:\n\nAfter the process, if only one vertex remains in ‘res’, it could be a universal sink.\nCheck if any other vertices have edges pointing towards this vertex.\n\nIf no such vertices exist, it’s a universal sink.\nOtherwise, it’s not.\n\n\n\n\n"},"algoDesign/algorithm-analysis--and--efficiency--and--worst-case-runtime":{"title":"algorithm analysis & efficiency & worst case runtime","links":["algoDesign/algorithm-analysis--and--efficiency--and--worst-case-runtime"],"tags":[],"content":"what is algorithm analysis\n\nstudy to estimate the resources an algorithm used to solve a specific problem, i.e. calculating efficiency\ndoes not give exact values (eg. time, space, v.v), but help to study the behavior and estimate efficiency of the algo\n\nwhat is efficiency in algorithm\n\nrelated to the input length - time complexity, or volume of memory - space complexity\nwhy care about efficiency: there are many approaches to solve problem. Algo analysis is then to figure out what is the most optimal solution\n\neg. airbag in cars are programmed to open within 2s (for eg), if it takes longer → cant protect the driver\n\n\n\nwhat is time complexity\n\na computational way to show how runtime of an algo changes as the input size changes\n\nwhy measure using worst case analysis - WCA\n\npurpose of worst case running time: what if an algo performs well on most cases except for some very slow running case?\nWCA is considered most efficient in analyzing algo\n\nas for eg average-case analysis, where we study the performance of an algorithm over random instances → what is random? How to choose unbiased random\nreal input is not also a random distribution → average case analysis tells more about mean performance of an algorithm rather than the comprehensive performance of the algorithm.\n\n\n\nbenchmark of WCA to determine algo efficiency\n\ncompare with brute force search (checking all possible cases)\nalgo is efficient if achieves better worst case performance than brute force search\nbrute force is not good as\n\ntoo slow to be useful\nintellectual cop-out, provide nothing into the structure of the problem we are studying\n\n\nalgo improving brute force search nearly always contain a valuable heuristic idea (shortest straight path to the goal) + computational tractability (ability to calculate)\nalgo is efficient if it has polynomial running time\n\npolynomial types:\n\nConstant (degree 0)\nLinear (degree 1)\nQuadratic (degree 2)\nCubic (degree 3)\nand so on\n\n\n\n\n\n\nasymptotic analysis\n\nmethod of defining mathematical boundaries of an algo’s run-time performance → estimate time complexity function for arbitrarily large input\ncan estimate the average case, best case, and worst case scenario of an algorithm\n\ncommon asymptotic notations\n\nconstant time: O(1)\nlinear: O(n)\nlogarithmic: O(log n)\nquadratic: O(n^2)\ncubic: On(n^3)\nand so on\norder: (1&lt;log(n)&lt;sqr(n)&lt;n&lt;n×log(n)&lt;n2&lt;n3&lt;....&lt;nn)\nnote: remove all constants. eg. O(n/2) → O(n)\n"},"algoDesign/algorithm-design-process":{"title":"algorithm design process","links":[],"tags":[],"content":"algorithm design process\n\ngiven a computing problem, how to approach solution\n\nformulate mathematically clean problem definition\npropose an algo\nprove that it correctly solves the problem\nanalyze its running time\n→ iterative process\n\n\n"},"algoDesign/big-o-notation":{"title":"big-o notation","links":[],"tags":[],"content":"what is big-o notation\n\nmathematical way to express (the closest) upper bound (worst case) of an algorithm running time\nmathematical example: pic, pic 2\nformula: f(n)=O(g(n)) IFF f(n)&lt;=c.g(n), where n≥n0​,c&gt;0,n0​≥1\n\nc: constant\nn: natural number denoting size of the algo\n\n\npic\n"},"algoDesign/big-omega-notation":{"title":"big-omega notation","links":[],"tags":[],"content":"what is big-omega notation\n\nmathematical way to express (the closest) lower bound (best case) of an algorithm running time - fastest time an algorithm can run\nformula: f(n)=Ω(g(n)) IFF f(n)&gt;=c.g(n), where n≥n0​,c&gt;0,n0​≥1\n\nc: constant\nn: natural number denoting size of the algo\n\n\nexample: pic\n"},"algoDesign/big-theta-notation":{"title":"big-theta notation","links":[],"tags":[],"content":"what is big-theta notation\n\nmathematical way to express average case of an algorithm running time - most realistic time complexity\nnormally used when best case O = worst case Ω\nformula: f(n)=θ(g(n)) IFF c1​.g(n)≤f(n)≤c2​.g(n), where n≥n0​;c1​,c2​&gt;0;n0​≥1\n\nc: constant\nn: natural number denoting size of the algo\n\n\nexample: pic\n"},"algoDesign/huffman-coding":{"title":"huffman coding","links":[],"tags":[],"content":"how to do huffman encoding\n\nsource: link\ngiven a string “AABCBAD” → 7 characters\n\n7 * 8 bits (UTF-8) = 56 bits\n\nUnicode transformation format = UTF\n\n\n\n\nwrite table of the # of repetition for each character\n\n\n\n\nmake huffman tree by joining the 2 least repeated elements. continue until an entire tree is made with every element\n\n\n\n\n\n\nleft path is 0\nright path is 1\n\n\n\n\nencode each character\n\n\n\n\nfinal result\n\n\n\n\n"},"algoDesign/stable-matching-problem":{"title":"stable matching problem","links":["algoDesign/Gale-Shapley-Algorithm"],"tags":[],"content":"problem\n\n\nproblem in written description:\n\n\n\n\n“STABLE”\n\neveryone gets matched\nno pair of individuals both prefer each other to their current partners (if it is just 1 individual preferring the other, it’s fine)\n\n\n\nsolution\n\nGale Shapley Algorithm\n"},"algoDesign/time-complexity--and--space-complexity":{"title":"time complexity & space complexity","links":[],"tags":[],"content":"time complexity\n\ntime required to solve given prob\n\nhow to estimate\n\n\n\nspace complexity\n\nmemory required to solve given prob\n"},"artificialIntelligence/***AI-map":{"title":"***AI map","links":["artificialIntelligence/the-importance-of-AI","artificialIntelligence/what-is-AI","artificialIntelligence/the-different-approached-to-AI","artificialIntelligence/definition-of-an-agent","artificialIntelligence/the-structure-of-agents","artificialIntelligence/learning-agents","artificialIntelligence/options-to-design-an-AI-agent","artificialIntelligence/designing-rational-agents","artificialIntelligence/reflex-agent","artificialIntelligence/planning-agent","artificialIntelligence/search-problems","artificialIntelligence/state-space","artificialIntelligence/state-space-graph-vs-search-tree","artificialIntelligence/state-space-graph","artificialIntelligence/search-tree","artificialIntelligence/search-algorithm","artificialIntelligence/tree-search-algorithm","artificialIntelligence/depth-first-search---dfs","artificialIntelligence/breadth-first-search---bfs","artificialIntelligence/iterative-deepening","artificialIntelligence/cost-sensitive-search","artificialIntelligence/uniform-cost-search---ucs","artificialIntelligence/pancake-problem","artificialIntelligence/fringe-strategy---the-one-queue","artificialIntelligence/search-heuristics","artificialIntelligence/greedy-search","artificialIntelligence/a*-search","artificialIntelligence/admissible-heuristics","artificialIntelligence/manhattan's-distance","artificialIntelligence/8-Puzzle","artificialIntelligence/semi-lattice-of-heuristics","artificialIntelligence/graph-search","artificialIntelligence/consistent-heuristics","artificialIntelligence/constraint-satisfaction-problems","artificialIntelligence/examples-of-constraint-satisfaction-problems","artificialIntelligence/constraint-graphs","artificialIntelligence/The-Waltz-Algorithm","artificialIntelligence/Standard-Search-Formulation-of-CSPs","artificialIntelligence/search-methods-for-CSPs","artificialIntelligence/backtracking-search","artificialIntelligence/filtering-in-CSPs---forward-checking,-arc-consistency","artificialIntelligence/k-consistency","artificialIntelligence/ordering-in-CSPs---minimum-remaining-values,-least-constraining-value","artificialIntelligence/deterministic-games","artificialIntelligence/zero-sum-games","artificialIntelligence/Expectimax-Search","artificialIntelligence/probabilities,-for-search-in-AI","artificialIntelligence/the-dangers-of-optimism-and-pessimism-in-model-assumptions","artificialIntelligence/Expectiminimax","artificialIntelligence/multi-agent-utilities","artificialIntelligence/monte-carlo-tree-search","probStatAdvanced/Markov-chain","artificialIntelligence/Markov-Decision-Processes---MDP","artificialIntelligence/utility-of-sequences-in-MDP","artificialIntelligence/The-Bellman-Equation","artificialIntelligence/quiz-2-AI","artificialIntelligence/COMP2050-Homework-1","artificialIntelligence/COMP2050-Homework-2"],"tags":[],"content":"Lectures\nChapter 1: Introduction\n\nthe importance of AI\nwhat is AI\nthe different approached to AI\n\nChapter 2: Intelligent Agents\n\ndefinition of an agent\nthe structure of agents\nlearning agents\n\n\nLecture 2: Agents and Search\n\noptions to design an AI agent\ndesigning rational agents\n\nreflex agent\nplanning agent\n\n\nsearch problems\nstate space\nstate space graph vs search tree\n\nstate space graph\nsearch tree\n\n\nsearch algorithm\n\ntree search algorithm\ndepth-first search - dfs\nbreadth-first search - bfs\niterative deepening\ncost-sensitive search\nuniform cost search - ucs\n\n\n\nLecture 3: Informed Search\n\nsearch so far\n\nsearch problems\nsearch tree\nsearch algorithm\n\n\npancake problem\nfringe strategy - the one queue\nuniform cost search - ucs\nsearch heuristics\ngreedy search\na* search\nadmissible heuristics\n\nmanhattan’s distance\n8 Puzzle\nsemi-lattice of heuristics\n\n\ngraph search\nconsistent heuristics\n\nLecture 4 + 5: CSPs\n\nTo solve search problems, we have assumptions about the world of the problem:\n\na single agent\ndeterministic actions\nfully observed states\ndiscrete state space\n\n\nsearch so far is for planning problem, concerning sequences of actions\n\npath to goal is important\npaths have various costs, depths\nheuristics give problem-specific guidance\n\n\nanother search problem is identification problem: assignments to variables\n\ngoal is important, not the path\nall paths have same depth (for some formulations)\nCPS - specialized class of identification problems → have more\n\n\nconstraint satisfaction problems\n\nexamples of constraint satisfaction problems\n\n\nconstraint graphs\n\nThe Waltz Algorithm\nStandard Search Formulation of CSPs\n\n\nsearch methods for CSPs\n\nbacktracking search\n\nfiltering in CSPs - forward checking, arc consistency\nk-consistency\nordering in CSPs - minimum remaining values, least constraining value\n\n\n\n\n\nLecture 6: Search with Other Agents I\n\ntypes of games: many\n\naxes\n\nDeterministic or stochastic?\nOne, two, or more players?\nZero sum?\nPerfect information (can you see the state)?\n\n\nwant algo to calculate strategy (policy) recommending a move from each state\ndeterministic games\nzero sum games\nvalue of a state: V(s) = maximum value of the child nodes s’ of s\n\n\n\nLecture 7: Search with Other Agents II - Uncertainty &amp; Utility\n\nworst-case vs average case: Uncertain outcomes controlled by chance, not an adversary!\n\nup triangle: maximizer\ndown triangle: minimizer\ncircle: chance node\n\n\nExpectimax Search\nprobabilities, for search in AI\nthe dangers of optimism and pessimism in model assumptions\nmixed layer game types\n\nExpectiminimax\nmulti-agent utilities\n\n\nmonte carlo tree search\nsummary\n\n﻿﻿Games require decisions when optimality is impossible\n\n﻿﻿Bounded-depth search and approximate evaluation functions\n\n\n﻿﻿Games force efficient use of computation\n\n﻿﻿Alpha-beta pruning, MCTS\n\n\n﻿﻿Game playing has produced important research ideas\n\n﻿﻿Reinforcement learning (checkers)\n﻿﻿Iterative deepening (chess)|\n﻿﻿Rational metareasoning (Othello)|\n﻿﻿Monte Carlo tree search (chess, Go)\n﻿﻿Solution methods for partial-information games in economics (poker)\n\n\n\n\n\nLecture 8: Markov Decision Processes MDP\n\nwhat’s next beyond search\n\nsearch: calculate what to do in current situation\n\n\nMDP is looking at learning habits/reflexes\n\npre-calculate what to do for any situation\nMarkov chain\n\n\nMarkov Decision Processes - MDP\n\nutility of sequences in MDP\nThe Bellman Equation\n\n\n\nQuiz\nQuiz 2\n\nquiz 2 AI\n\nHomework\nHomework 1\n\nCOMP2050 Homework 1\nCOMP2050 Homework 2\n\n\nLec"},"artificialIntelligence/8-Puzzle":{"title":"8 Puzzle","links":[],"tags":[],"content":"8 puzzle\n\npic\n\n8 puzzle 1\n\npic\nheuristic: # of tiles misplaced\nadmissible? Yes, as every misplaced tiles has to undergo an action ⇒ minimum # of action = # titles misplaced. ⇒ This is an underestimation of the actual cost, as every misplaced titles has to undergo a series of actions, not just 1 action\nh(start): 8 = # of tiles misplaced at the start state\n⇒ this is relaxed problem heuristic\n\n8 puzzle 2\n\npic\nheuristic: sum of the manhattan’s distance\nrelaxed problem? yes, as you can slide the tiles just like when there are no other tiles.\nadmissible? yes, as each tile has to go through &gt; than the heuristic cost when there are other tiles around\nh(start) = sum of total manhattan’s distance of each tile from the start state to the goal state (when there are no other tiles)\n\nwith 1: dist = 3\nwith 2: dist = 1\nwith 3: dist = 2\nwith 4: dist = 2\nwith 5: dist = 2\nwith 6: dist = 3\nwith 7: dist = 3\nwith 8: dist = 2\n⇒ h(start) = 3+1+2+2+2+3+3+2 = 18\n\n\n\n8 puzzle 3\n\nusing actual cost as heuristic\nadmissible? Yes, h(x)=h∗(x) → still satisfy\nsave on nodes expanded? Yes\nwhat’s wrong → we dont know the actual cost :D\n"},"artificialIntelligence/COMP2050-Homework-1":{"title":"COMP2050 Homework 1","links":[],"tags":[],"content":"COMP2050 Homework 1\nProblem 1:\n\nAs in graph with negative weights, using UCS may not be optimal even though the algorithm will still be terminated. Therefore, Professor Khoa cannot find the optimal solution using UCS with negative energy.\nIn the modified graph, where all edges are non-negative (assuming α=−1), the optimal route can be found and the algorithm can terminate. However, the optimal path in the original graph, which may contain negative edges, could differ\nNo, it will be the same.\n\nProblem 2:\nProblem: You are trapped in a large, complex maze garden and need to find the exit. The garden is represented as a 2D grid where open paths are denoted by ‘0’ and walls are denoted by ‘1’. The starting position is at the top-left corner (0,0) and the exit is at the bottom-right corner (n-1, m-1). There is also a branching factor, interpreted as the constraint on maximum number of directions you can traverse (i.e. left, right, up, down)\nIn this case, Depth-First Search (DFS) can be more efficient than Breadth-First Search (BFS) as:\n\nPath Length &amp; Branching Factor DFS is a better choice if the solution is expected to be far from the root. In this problem problem, if the exit is known to be far from the entrance, DFS could reach the solution faster because it explores a complete path to the end before backtracking.\nSpace Complexity: DFS uses less memory than BFS. In the worst-case scenario, BFS needs to store all nodes in memory, while DFS only needs to store some paths from the root to a leaf node, along with siblings of each node on the path\n\nIn general, DFS is usually better than BFS in problems where:\n\nThe tree/graph is known to have a large breadth (i.e., each node has many children)\nThe solution is expected to be deep in the tree/graph and not located in the higher levels\nSpace is a matter of concern, as DFS has lower memory requirements than BFS\n\nProblem 3:\n\nState: A tuple (a,b,c)\n\na represents the water in the 5L jar\nb represents the water in the 8L jar\nc represents the water in the 12L jar\n\n\nSuccessor Function:\n\nFill: Fill a jar from the source, changing the state to (5,b,c), (a,8,c), or (a,b,12). The cost is the effort to fill\nEmpty: Empty a jar, changing the state to (0,b,c), (a,0,c), or (a,b,0). The cost is minimal\nPour: Pour water between jars. The outcome depends on the current state.\n\n\nExample case: Pouring from the 5L to the 8L jar:\n\nif b+a≤8, results in (0,b+a,c)\nif b+a&gt;8, results in (a−(8−b),8,c)\n\n\nThe cost is the transferred water amount\n\n\nInitial State: (0,0,0)\nGoal State: (9,b,c);(a,9,c);(a,b,9)\n"},"artificialIntelligence/COMP2050-Homework-2":{"title":"COMP2050 Homework 2","links":[],"tags":[],"content":"Problem 1:\n\nVariable: V={X1​,X2​,X3​}\n\nX1​: first student hired\nX2​: second student hired\nX3​: third student hired\n\n\nDomains: D={Chinh,Duy,Quang,Jason,Hoang,Hieu,Phuc}\nConstraints:\n\nX1​=X2​=X3​\n2 AI expertises:\n\nProf Khoa has AI expertise, so at least 1 other must have AI expertise as well.\nXi​ with i∈{1,2,3} should have AI expertise\nPossible selections of AI: Chinh, Jason, Hieu\n\n\n2 Front end:\n\nCount of FE engineers among X1​,X2​,X3​ should be 2\nPossible selections of FE: Chinh, Duy, Quang, Hoang, Phuc\n\n\n1 Photoshop:\n\nCount of Photoshop among X1​,X2​,X3​ should be 1\nPossible selections of Photoshop: Duy, Hoang, Phuc\n\n\n1 Back end:\n\nCount of BE engineers among X1​,X2​,X3​ should be 1\nPossible selections of BE: Jason\n\n\n1 System:\n\nCount of System engineers among X1​,X2​,X3​ should be 1\nPossible selections of System: Quang, Hieu\n\n\n\n\n\nProblem 2\n\nanother choice can be\n\nVariable:\n\nR1​: Room where Duy is located\nR2​: Room where Chinh is located\nR3​: Room where Quang is located\nW1​: weapon in room adjacent to Duy’s room\nW2​: weapon in room adjacent to Chinh’s room\nW3​: weapon in room adjacent to Quang’s room\n\n\nDomain:\n\nEach variable Ri​,i∈{1,2,3} and Wj​,j∈{1,2,3} , can take values from set of 3 rooms and 3 weapons, which is {1,2,3} respectively\n\n\n\n\nUsing the variables and domains already provided in part a, we have the constraint:\n\n\n\nC=D=Q\n\n\nk=g=w\n\n\nD=w\n\n\n∣C−g∣=1\n\n\n∣Q−k∣=1\n\n\nD=1,g=1\n\n\nBacktracking steps Table\n\n\n\nProblem 3\n\n\nMinimax:\n\n\n\nAlpha beta prunning\n\n\n"},"artificialIntelligence/Evaluation-by-rollouts---monte-carlo-tree-search":{"title":"Evaluation by rollouts - monte carlo tree search","links":[],"tags":[],"content":"what is rollout\n\n”Move 37” in Go as example\nRepeat until terminal:\n\nPlay a move according to a fixed, fast rollout policy\n\n\nRecord the result\n⇒ Fraction of wins correlates with the true value of the position\nhaving a “better - quick, better than random” roll out policy helps\n"},"artificialIntelligence/Expectimax-Search":{"title":"Expectimax Search","links":["artificialIntelligence/Markov-Decision-Processes---MDP"],"tags":["computerScience/AI-ML/optimization","computerScience/searchProblems","computerScience/gameTheory"],"content":"expectimax search\n\nWhy wouldn’t we know what the result of an action will be?\n\nExplicit randomness: rolling dice, tossing a coin\nUnpredictable opponents: the ghosts respond randomly  (teleport, etc)\nActions can fail: when moving a robot, wheels might slip\n\n\nValues should now reflect average-case (expectimax) outcomes, not worst-case (minimax) outcomes\nExpectimax search: compute the average score under optimal play (maximize what we get on average when playing many times)\n\nMax nodes as in minimax search\nChance nodes are like min nodes but the outcome is uncertain\nCalculate their expected utilities\nI.e. take weighted average (expectation) of children\noptimality? 50/50 chance → not completely sure\nassumptions on the selection can be mismatched with the world\n\n\nformalize the underlying uncertain result problems as Markov Decision Processes - MDP\n\nexpectimax pseudocode\n\nexpectimax pseudocode\n\nexpectimax pruning\n\ncant do the same pruning, as there can be hugely large values dominating the others, affecting the expectation → if prun → misleading result\n\ndepth-limited expectimax\n\nas cant get to the bottom in the time we have → stop at some move, use est of the value (approx evaluation function)\ndont need to go deep in the tree → in a reasonable amount of time → find approx answer to the top\n\nquiz - should we use expectimax\n\nquiz - what tree search to use\n\nproblems w expectimax\n\ninfinite horizons → expectimax needs finite\nself-loop\nlarge search tree → lots of computation\n"},"artificialIntelligence/Expectiminimax":{"title":"Expectiminimax","links":[],"tags":[],"content":"\n\nEnvironment is an extra “random agent” player that moves after each min/max agent\nEach node computes the appropriate combination of its children\neg. backgammon\n"},"artificialIntelligence/Markov-Decision-Processes---MDP":{"title":"Markov Decision Processes - MDP","links":["artificialIntelligence/Expectimax-Search","artificialIntelligence/The-Bellman-Equation"],"tags":["Math/probability/markovChain","computerScience/AI-ML/RL"],"content":"Markov Decision Processes - MDP\nAn MDP is defined by:\n\n\nA set of states s ∈ S\n\n\nA set of actions a ∈ A\n\n\nA transition function T(s, a, s’)\n\nProbability that a from s leads to s’, i.e., P(s’| s, a)\nAlso called the model or the dynamics\n\n\n\nA reward function R(s, a, s’)\n\nSometimes just R(s) or R(s’)\n\n\n\nA start state\n\n\nMaybe a terminal state\n\n\nUsually denoted as tuple 〈S, A, T, R, 𝛄〉\n\n\nMarkov in MDP means action outcomes depend only on the current state (just like successor function of search)\n\n\nutilities of sequences\n\nmore reward, now → values of rewards decay exponentially U⟶P0​ + γP1​  + γ2P2​+⋯\n\n\n\npolicies in MDP\n\nin deterministic single-agent search problems: want optimal plan / sequence of actions from start to goal\nin MDP: want optimal policy π∗:S→A\n\na policy p gives an action for each state\noptimal policy: maximize expected utility if followed (can have many optimal policies, but will receive same amt of rewards in the long run)\nexplicit policy defines a reflex agent\n\n\nexpectimax didnt compute entire policies\n\nonly the action for a single state\n\n\n\nexample\nConsider a simple MDP where an agent is navigating a gridworld. The states (S) are the cells of the grid, the actions (A) are the directions the agent can move (up, down, left, right), and the rewards are +1 for reaching the goal cell, -1 for hitting a trap, and -0.01 for each step to encourage the agent to reach the goal quickly.\nA policy in this case might be a simple rule like “always move towards the goal if possible, otherwise move randomly”. This policy gives an action for each state (each cell of the grid).\nAn optimal policy (𝛑*) would be the one that maximizes the expected utility. This might involve taking a longer path to avoid traps, for example.\nThe Expectimax algorithm could be used to decide the best action for a single state. For example, if the agent is in a particular cell, Expectimax could be used to decide whether it’s better to move up, down, left, or right, based on the expected utility of each action. However, Expectimax wouldn’t provide a policy for the other cells of the grid.\nMDP Search Tree\n\n link\nMDP search tree\n\nEach MDP state projects an expectimax-like search tree\n\n\nProblems\n\nRepeated states\nTree goes on forever\n⇒ The Bellman Equation\n\n\n"},"artificialIntelligence/Standard-Search-Formulation-of-CSPs":{"title":"Standard Search Formulation of CSPs","links":[],"tags":[],"content":"states defined by the values assigned so far (partial assignments)\n\ninitial state: empty assignment, {}\nsuccessor function: assign value to an unassigned variable\ngoal test: current assignment is complete and satisfies all constraints\n"},"artificialIntelligence/The-Bellman-Equation":{"title":"The Bellman Equation","links":[],"tags":["computerScience/AI-ML/RL"],"content":"Optimal Quantities\n\nThe value (utility) of a state s:\n\nV∗(s)= maxa​Q∗(s,a)=maxa​∑s′​T(s,a,s′)[R(s,a,s′)+γV∗(s′)]\nexpected utility starting in s and acting optimally\n\n\nThe value (utility) of a q-state (s,a)\n\nQ∗(s,a)=∑s′​T(s,a,s′)[R(s,a,s′)+γV∗(s′)]\nexpected utility starting out having taken action a from state s and (thereafter) acting optimally\n\n\nThe optimal policy:\n\n𝝿*(s) = optimal action from state s\n\n\n\n\nTime limited values\n\ndefine Vk​(S) to be the optimal value of s if the game ends in k more time steps = what a depth-k expectimax give from s\n"},"artificialIntelligence/The-Waltz-Algorithm":{"title":"The Waltz Algorithm","links":[],"tags":[],"content":"what is The Waltz Algorithm\n\nearly computer vision algo - not how they do it now anymore\ninterpreting line drawing of solid polyhedra (đa diện) as 3D objects\nPose as CSP: each intersection is a variable, domain = {outtie, innie}. constraint if 2 things are connected, cannot have one convex, the other concave\n"},"artificialIntelligence/a*-search":{"title":"a* search","links":["artificialIntelligence/admissible-heuristics","artificialIntelligence/consistent-heuristics"],"tags":["computerScience/DSA/a-starSearch"],"content":"what is A* search\n\nUniform-cost orders by path cost, or backward cost g(n)\nGreedy orders by goal proximity, or forward cost h(n)\ncombination of UCS and greedy → Orders by the sum of backward cost ( g(n) ) and forward cost ( h(n) ): (f(n)=g(n)+h(n)) → A*\n\nA* search optimality\n\nTree search:\n\nA* is optimal if we have admissible heuristics, inadmissible (pessimistic) heuristic → not optimal\nUCS is a special case (h=0)\n\n\nGraph search\n\nA* is optimal if we have consistent heuristics\nUCS optimal (h = 0 is consistent)\n\n\nconsistency implies admissibility\nmost natural admissible tend to be consistent, esp. in relaxed problems\n\nshould stop when enqueue a goal?\n\nNo, as it may not be the most optimal solution → only stop when dequeue a goal\n\nA* vs other searches\n\na* vs ucs pic\nUCS: search widely just like BFS; in contours map: expand equally in all directions\nA*: zone in to search for optimal path (with good heuristic); in contours map: expand mainly toward the goal to ensure optimality\na* vs greedy vs ucs pic\n\nA* application\n\nVideo games\nPathing / routing problems\nResource planning problems\nRobot motion planning\nLanguage analysis\nMachine translation\nSpeech recognition\nGraph Matching\n"},"artificialIntelligence/admissible-heuristics":{"title":"admissible heuristics","links":["artificialIntelligence/manhattan's-distance"],"tags":["computerScience/DSA/a-starSearch","computerScience/AI-ML/optimization/a-starSearch"],"content":"what is heuristic\n\na heuristic (function) to speed up the process of finding optimal solution\neg. number of pancake out of order (pancake problem), number of titles misplaced (8 puzzle problem)\nan underestimation of the actual cost we will incur\n\nwhat is admissibility\n\nestimate how much cost from current state → goal state\n\npessimistic &amp; optimistic heuristic\n\npessimistic / inadmissible heuristics break optimality by trapping good paths on the fringe, example\noptimistic / admissible heuristics slow down bad plans, but never outweigh true costs → ensure A* optimality\n\nadmissible heuristics\n\na heuristic h is admissible (optimistic) if: 0≤h(n)≤h∗(n)\n\nh(n): heuristic function\nh∗(n) : actual cost to nearest goal\n\n\nexample: manhattan’s distance, pancake flipping (# of the largest pancake still out of place)\nmost of what involved in A* is brainstorming admissible heuristics\n\nwhy a-star tree search is optimal with admissible heuristic\nto prove optimality\n\nassume A is optimal goal node, B is suboptimal goal node, h is admissible\nProve: A will exit the fringe before B  = we will explore optimal node before suboptimal ones\n\nproof:\n\nimagine B on the fringe; ancestor n of A (or A itself) on the fringe\nclaim: n will be expanded before B\n\nf(n)≤f(A)\n\nthings to remember: n: a node on the path to A; A: goal node\nanalysis: As A is goal node, h(A)=0 ⇔ g(n)+h(n)≤g(A), or the total cost through n to the goal node is smaller or equal to the estimated cost through A to the goal node.\n\nThis is because g(n)≤g(A) (equal when n = A)\nh(n)≤h∗(n): or the heuristic through n to the goal node has to be smaller or equal to the actual cost through n to the goal node\n\n\n⇔f(n)≤g(A)\n⇔g(A)=f(A) as h(A)=0\n⇔f(n)≤f(A)\n\n\nf(A)&lt;f(B)\n\ng(A)&lt;g(B): as A is optimal goal node, B is suboptimal goal node\nf(A)&lt;f(B):h=0 at both goal states\n\n\nn expands before B: as of 1 and 2 ⇒ f(n)≤f(A)&lt;f(B) ⇒ f(n)&lt;f(B)\n\n\nTherefore, all ancestors of A expand before B\nA expands before B\nA search with admissible heuristic* is optimal\n\ncreating admissible heuristics\n\ninadmissible heuristics are often useful (find fast solution)\nWay to ensure admissibility in heuristics: introduce new actions\n\ntake original problem → add new actions → in this hypothetical problem space, we find the optimal solution\nas this is hypothetical, there are more actions available → optimal solution in this hypo space will be cheaper or same as in the real world\n⇒ often, admissible heuristics are solutions to relaxed problems, where new actions are available\n⇒ optimal solution in relaxed problem = admissible heuristic for real problem\n\n\nnote: A with heuristic is the trade-off between quality of estimate and work per node*\n\nas heuristic get closer to the true cost, you will expand fewer node (quality of estimate is better), yet we will have to do more work per node to compute the heuristic\n\n\n"},"artificialIntelligence/backtracking-search":{"title":"backtracking search","links":["artificialIntelligence/filtering-in-CSPs---forward-checking,-arc-consistency"],"tags":[],"content":"what is backtracking search\n\na type of DFS\nbasic uninformed algorithm for solving CSPs (dont have additional information about the state beyond its definition; doesnt know whether close to solution or not until finds one, or exhaust all possibilities)\n\n\nOne variable at a time\n\n﻿﻿Variable assignments are commutative (giao hoán) → fix ordering\n﻿﻿I.e., [WA = red then NT = green] same as [NT = green then WA = red]\n﻿﻿Only need to consider assignments to a single variable at each step\n\n\nCheck constraints as you go\n\n﻿﻿I.e. consider only values which do not conflict with previous assignments\n﻿﻿Might do some computation to check constraints\n﻿﻿“Incremental goal test”\n\n\n\n\n﻿﻿Can solve n-queens for n = 25\npic - algorithm implementing backtracking\nBacktracking = DFS + variable-ordering + fail-on-violation\n\nimproving backtracking\n\ngeneral purpose idea (not like heuristics in A* - custom the the search problem) but give huge gains in speed\nOrdering\n\nvariable should be assigned next?\nvalues tried in what order?\n\n\n﻿﻿Filtering: Can we detect inevitable failure early? → filtering in CSPs - forward checking, arc consistency\n﻿﻿Structure: Can we exploit the problem structure?\n"},"artificialIntelligence/breadth-first-search---bfs":{"title":"breadth-first search - bfs","links":[],"tags":[],"content":"note\n\nStrategy: expand a shallowest node first\nImplementation: fringe is a FIFO queue\nProperties:\n\nTime complexity: O(bs)\n\ns tiers → there will be s nodes of b in the worst case time\n\n\nSpace complexity: O(bs)\nComplete: yes\nOptimal: only if costs are all 1\n\n\n\n\nBFS in CSPs\n\nchoose a node as root, then explore level by level\neg. level 0, tree node is WA, child node is WA = R, WA = G, WA = B\n\nlevel 1, child node is WA = R and SA = G, WA = G and NT = R, …\n\n\nit falls into the worst case: explore the deepest level to find the solution\n"},"artificialIntelligence/consistent-heuristics":{"title":"consistent heuristics","links":[],"tags":[],"content":"consistent heuristics vs admissible heuristics\n\nnote: C is goal, A is node\nadmissibility: h(A)≤h∗(A)\nconsistency: heuristic arc cost ≤ actual cost for each arc: h(A)−h(C)≤cost(AtoC)\npic of inconsistency\n\nas  h=1 at C ⇒ it should be h=2 at A\n\n\n\npurpose of consistency\n\nf-value along a path never decreases\n\nh(A)≤cost(AtoC)+h(C): from the definition of consistency\nf(A)=g(A)+h(A)≤g(A)+cost(AtoC)+h(C)=f(C): add backward cost\n\n\n"},"artificialIntelligence/constraint-graphs":{"title":"constraint graphs","links":[],"tags":[],"content":"what is CG\n\nbinary CSP: each constraints related (at most) 2 vars\nbinary CG: nodes are variables, arcs show constraints\ngeneral-purpose CSP algos use graph structure to speed up search\n\neg. Tasmania is independent subproblem\n\n\nCG only show there are constraints, dont tell what the constraints are\naustralia map constraint graph\n5x5 nqueens constraint graph\n\nconstraint Queen 1 btw A and B means that 1,1 not oke, 1,2 not oke, 1,3 oke and so on\n\n\n"},"artificialIntelligence/constraint-satisfaction-problems":{"title":"constraint satisfaction problems","links":[],"tags":[],"content":"standard search problems\n\nstate is a “black box”: arbitrary data structure\ngoal test: any function over states\nsuccessor function can be anything\n\nconstraint satisfaction problems\n\nspecial subset of search problems\nstate defined by variables Xi​, values from domain D (D sometimes depends on i)\nGoal test: set of constraints specifying allowable combination of values for subsets of variables\nsimple example of a formal representation language\nallows more power and useful general-purpose algorithms than standard search algos\n\nVarieties of CSP\n\nDiscrete Variables\n\nfinite domains:\n\nsize d means O(dn) complete assignments → still bad\neg. boolean CSPs (including Boolean satisfiability - NP complete)\n\n\nInfinite domains (integers, strings, etc)\n\njob scheduling, variables are start/end times\nlinear constraints solvable, nonlinear undecidable\n\n\n\n\nContinuous variables\n\neg. start/end times for hubble telescope observations\nlinear constraints solvable in polynomial time by LP methods\n\n\n\nVarieties of Constraints\n\n﻿﻿Unary constraints involve a single variable (equivalent to reducing domains), e.g.:  SA=green\n﻿﻿Binary constraints involve pairs of variables, e.g: SA=WA\n﻿﻿Higher order constraints involve 3 or more variables: e.g., cryptarithmetic column constraints\n﻿﻿Preferences (soft constraints):\n\n﻿﻿E.g., red is better than green\n﻿﻿Often representable by a cost for each variable assignment\n﻿﻿Gives constrained optimization problems\n﻿﻿(We’ll ignore these until we get to Bayes’ nets)\n\n\n\nreal world CSPs\n\n﻿﻿Scheduling problems: e.g., when can we all meet?\n﻿﻿Timetabling problems: e.g., which class is offered when and where?\n﻿﻿Assignment problems: e.g., who teaches what class\n﻿﻿Hardware configuration\n﻿﻿Transportation scheduling\n﻿﻿Factory scheduling\n﻿﻿Circuit layout\n﻿﻿Fault diagnosis\n﻿﻿… lots more!\n"},"artificialIntelligence/cost-sensitive-search":{"title":"cost-sensitive search","links":[],"tags":["computerScience/searchProblems"],"content":"note\n\npic\nBFS finds the shortest path in terms of number of actions\nDoes not find the least-cost path\nNeed to consider the cost of each action\n"},"artificialIntelligence/definition-of-an-agent":{"title":"definition of an agent","links":[],"tags":[],"content":"title\nnote\n\nAn agent is something that perceives its environment through sensors and acts upon that environment through actuators based on its agent function.\n"},"artificialIntelligence/depth-first-search---dfs":{"title":"depth-first search - dfs","links":[],"tags":["computerScience/searchProblems/dfs"],"content":"note\n\nStrategy: expand a deepest node first\nImplementation: fringe is a LIFO stack\nProperties:\n\nNodes DFS expand?\n\nSome left prefix of the tree\nCould process the whole tree\nIf m is finite, takes time (O(bm))\n\n\nTime complexity: (O(bm))\n\nb: branching factor (the average number of successors per state)\nm: maximum depth\nsearch has to explore the entire tree before finding a solution or concluding that none exists.\n\n\nSpace complexity: (O(bm))\n\nsearch stores nodes &amp; their siblings along path from root → current node, with at most length is m\nat most number of siblings each level is b\n\n\nComplete: finite only if we prevent cycles\nOptimal: no. find the leftmost solution regardless of depth or cost\n\n\n\n\nwhen to use\n\ndetect cycles in a tree\n\nimplementation\n// Java program to print DFS traversal\n// from a given graph\nimport java.io.*;\nimport java.util.*;\n \n// This class represents a\n// directed graph using adjacency\n// list representation\nclass Graph {\n\tprivate int V;\n \n\t// Array of lists for\n\t// Adjacency List Representation\n\tprivate LinkedList&lt;Integer&gt; adj[];\n \n\t// Constructor\n\t@SuppressWarnings(&quot;unchecked&quot;) Graph(int v)\n\t{\n\t\tV = v;\n\t\tadj = new LinkedList[v];\n\t\tfor (int i = 0; i &lt; v; ++i)\n\t\t\tadj[i] = new LinkedList();\n\t}\n \n\t// Function to add an edge into the graph\n\tvoid addEdge(int v, int w)\n\t{\n\t\t// Add w to v&#039;s list.\n\t\tadj[v].add(w);\n\t}\n \n\t// A function used by DFS\n\tvoid DFSUtil(int v, boolean visited[])\n\t{\n\t\t// Mark the current node as visited and print it\n\t\tvisited[v] = true;\n\t\tSystem.out.print(v + &quot; &quot;);\n \n\t\t// Recur for all the vertices adjacent to this\n\t\t// vertex\n\t\tIterator&lt;Integer&gt; i = adj[v].listIterator();\n\t\twhile (i.hasNext()) {\n\t\t\tint n = i.next();\n\t\t\tif (!visited[n])\n\t\t\t\tDFSUtil(n, visited);\n\t\t}\n\t}\n \n\t// The function to do DFS traversal.\n\t// It uses recursive DFSUtil()\n\tvoid DFS(int v)\n\t{\n\t\t// Mark all the vertices as\n\t\t// not visited(set as\n\t\t// false by default in java)\n\t\tboolean visited[] = new boolean[V];\n \n\t\t// Call the recursive helper\n\t\t// function to print DFS\n\t\t// traversal\n\t\tDFSUtil(v, visited);\n\t}\n \n\t// Driver Code\n\tpublic static void main(String args[])\n\t{\n\t\tGraph g = new Graph(4);\n \n\t\tg.addEdge(0, 1);\n\t\tg.addEdge(0, 2);\n\t\tg.addEdge(1, 2);\n\t\tg.addEdge(2, 0);\n\t\tg.addEdge(2, 3);\n\t\tg.addEdge(3, 3);\n \n\t\tSystem.out.println(\n\t\t\t&quot;Following is Depth First Traversal &quot;\n\t\t\t+ &quot;(starting from vertex 2)&quot;);\n \n\t\t// Function call\n\t\tg.DFS(2);\n\t}\n}\n// This code is contributed by Aakash Hasija\n \nDFS in CSPs\n\nif the worst case is we have to find sth at the deepest level, DFS at least in some first attempts can reach the solution\n"},"artificialIntelligence/designing-rational-agents":{"title":"designing rational agents","links":["artificialIntelligence/definition-of-an-agent"],"tags":[],"content":"note\n\nan agent is an entity that perceives and acts\na rational agent: select actions maximizing its expected utility\nCharacteristics of the percepts, environment, and action space dictate techniques for selecting rational actions\n\n\n\n\n"},"artificialIntelligence/deterministic-games":{"title":"deterministic games","links":[],"tags":[],"content":"Many possible formalizations, one is:\n\nStates: S (start at s0)\nPlayers: P={1…N} (usually take turns)\nActions: A (may depend on player / state)\nTransition Function: S x A → S\nTerminal Test: S → {t,f}\nTerminal Utilities: S x P → R\n\nSolution for a player is a policy: S → A"},"artificialIntelligence/examples-of-constraint-satisfaction-problems":{"title":"examples of constraint satisfaction problems","links":[],"tags":[],"content":"eg of CSP: map coloring\n\npic of map in australia\nVariables: different states (WA, NT, Q, NSW, V, SA, T)\nDomains: values to assign, D = {red, green, blue}\nConstraints: adjacent regions must have different colors\n\nimplicit: WA=NT\nexplicit: (WA,NT)∈(red,green),(red,blue)...\n\n\nSolutions: assignments satisfying constraints\n\neg of CSP: n-queens\n\nintro: have chessboard of square size, must place queens on the board so that nobody is threatening others\nformulation 1 - nqueens\n\nvariables: Xij​ the squares = 4 x 4 = 36\ndomains: {0, 1}, for not queen and queen\nconstraint: …\n\n\nformulation 2 - nqueens\n\neg of CSP. cryptarithmetic\n\ncryptarithmetic vars, domains, constraints, and CG\nX1​,X2​,X3​: carry bit\nalldiff(): all have to be different\n\neg of CSP. sudoku\n\nsudoku vars, domains, constraints\n\nanother constraints: fill the missing number adhering to the prefilled numbers\n\n\n"},"artificialIntelligence/filtering-in-CSPs---forward-checking,-arc-consistency":{"title":"filtering in CSPs - forward checking, arc consistency","links":[],"tags":[],"content":"filtering:\n\nkeep track of domains for unassigned variables, cross off bad options\n\nforward checking\n\na way of filtering\ncross off values violating constraint when added to existing assignment\nprocess of forward checking aus map\nprevent the generation of paths leading to a dead-end in the search tree → more efficient than simple backtracking\n\nconstraint propagation\n\npropagates info from assigned to unassigned vars\ndoesnt provide early detection for all failures (checking btw unassigned and unassigned vars)\nreason from constraint to constraint\n\narc consistency\n\nan arc is just an edge with direction ⇒ an edge means 2 arcs to check ⇒ we can check satisfaction in 2 different directions\narc consistency = all arcs are consistence\nconceptually, can check an arc between 2 things not connected by a constraint\narc is consistent = no constraint violation along the arc ⇒ for 1 thing in the tail, there is at least one OK option in the head\nif violating ⇒ delete from the TAIL\nevery time deleting from a domain, arcs declared consistent pointing into it, is now questionable again\n⇒ dont have to backtrack as much as forward checking, as it detects failure earlier\ndisadvantage:\n\nbad runtime\nconvergence\n\n\ntrade off between making the core search run faster &amp; doing more filtering\nAC3: algo to enforce arc consistency in a CSP\n\nlimitation after enforcing arc consistency:\n\ncan have 1 solution/multiple solutions/no solution left\narc consistency runs inside a backtracking search\n\ndifference btw arc consistency and forward checking\n\nforward checking check constraints between current and future variables; arc consistency checks constraints between unassigned variables\nFC is faster to perform than AC\n\nK-consistency\n\n\n"},"artificialIntelligence/fringe-strategy---the-one-queue":{"title":"fringe strategy - the one queue","links":[],"tags":[],"content":"what is fringe strategies\n\nall search algorithm are the same, except for fringe strategies\n\nFringe Strategies: Each search algorithm systematically builds a search tree and chooses an ordering for the fringe. The difference lies in how they prioritize or order these unexplored nodes\nimplemented with priority queues\nPractically, for DFS and BFS, you can avoid the log(n) overhead from an actual priority queue, by using stacks and queues\nCan even code one implementation that takes a variable queuing object\n\n\n"},"artificialIntelligence/graph-search":{"title":"graph search","links":["artificialIntelligence/consistent-heuristics"],"tags":[],"content":"problem with search tree\n\nit is prone to expand repetitive nodes, pic\ngraph search → keep track of list of expanded nodes, not expand them again\n\ngraph search\n\nIdea: never expand a state twice\nImplementation:\n\nTree search + set of expanded states (“closed set”)\nloop through every node in the tree\n\nif its state was expanded before → skip it\nif new → add to the “closed set”\n\n\n\n\nImportant: store the closed set as a set, not a list (sets, in many languages like python, are implemented as hash tables → faster look up time than list)\nCompleteness? Yes, as we just remove the repetition in the search tree, so basically nodes all are searched, but not repeated\nOptimal? Maybe not\n\nonly optimal if we already searched the optimal states, then when searching others, we remove the stated searched. else, we may never optimally searched\nexample of a* graph search gone wrong\nunderlying issue? poor choice of heuristic → misled us to the suboptimal path → we need more than admissible heuristic ⇒ consistent heuristics\n\n\n"},"artificialIntelligence/greedy-search":{"title":"greedy search","links":[],"tags":[],"content":"what is greedy search\n\nStrategy: expand a node that you think is closest to a goal state, dont care about the cost\n\nHeuristic: estimate of distance to nearest goal for each state\n\n\nA common case:\n\nBest-first takes you straight to the (wrong) goal\n\n\nWorst-case: like a badly-guided DFS\n\n"},"artificialIntelligence/iterative-deepening":{"title":"iterative deepening","links":[],"tags":[],"content":"what is iterative deepening\n\nIdea: get DFS’s space advantage with BFS’s time / shallow-solution advantages\nRun a DFS with increasing depth limit\nNot wastefully redundant, most work in lowest level\nProperties:\n\nTime complexity: (O(bs))\nSpace complexity:  (O(bs))\nComplete: yes\nOptimal: only if costs are all 1\n\n\nvisualization\n"},"artificialIntelligence/k-consistency":{"title":"k-consistency","links":[],"tags":[],"content":"1-consistency - node consistency\n\nIncreasing degrees of consistency\n\n1-Consistency (Node Consistency): Each single node’s domain has a value which meets that node’s unary constraints (constraint on 1 variable\n\neg. node A,B,C can take a value in {1,2,3,4,5}, and A&gt;1 ⇒ A∈{2,3,4,5} will make A consistent\n\n\n2-Consistency (Arc Consistency): For each pair of nodes, any consistent assignment to one can be extended to the other\n\neg. given constraint A=B. if we assign the value 1 to A (A=1), we can find a value for B (B=2 or 3 or 4 or 5) that satisfies the constraint A=B, and vice versa, there is a value in A’s domain that satisfies the constraint A=B\n⇒ arc from A to B is consistent. same for B to C and C to A\n\n\nK-Consistency: For each k nodes, any consistent assignment to k-1 can be extended to the k-th node.\n\nif we assign the values 1 and 2 to A and B respectively (A=1, B=2), we can find a value for C (C=3) that satisfies the constraints A ≠ C and B ≠ C. Therefore, the set of nodes {A, B, C} is 3-consistent.\n\n\n\n\nHigher k more expensive to compute\n\nmust check more combinations of assignments\nis easier to find a solution (they eliminate inconsistency)\n\n\n(You need to know the k=2 case: arc consistency)\n"},"artificialIntelligence/learning-agents":{"title":"learning agents","links":[],"tags":[],"content":"title\nnote\n\nLearning agents are capable of learning from their experiences, which allows them to improve their performance and adapt to changing environments.\nA learning agent can be divided into four conceptual components: a learning element, a performance element, a problem generator, and a critic.\n"},"artificialIntelligence/manhattan's-distance":{"title":"manhattan's distance","links":[],"tags":[],"content":"what is manhattan’s distance\n\nthe shortest distance between 2 points, following the grid lines\nalso called sum of absolute distance\n∣x1​−x2​∣+∣y1​−y2​∣: the absolute differences in the x-coordinates and the y-coordinates of the two points\neg. as a taxi driver, The Manhattan distance is the shortest distance you can drive from one point to another, following the streets\n"},"artificialIntelligence/models":{"title":"models","links":[],"tags":["computerScience/AI-ML/machineLearning","computerScience/AI-ML/AI/model"],"content":"note\n\nalmost always wrong but some are useful\n"},"artificialIntelligence/monte-carlo-tree-search":{"title":"monte carlo tree search","links":["artificialIntelligence/Evaluation-by-rollouts---monte-carlo-tree-search"],"tags":[],"content":"MCTS\n\ndeveloped for the purpose of playing Go, with large branching factor b &gt; 300\nalpha beta search assume a fixed horizon can reach ~ b &gt; 4\ncombine 2 important ideas:\n\nEvaluation by rollouts - monte carlo tree search – play multiple games to termination from a state s (using a simple, fast or random policy) and count wins and losses\n\nwin a lot: state s is good, else, is bad\n\n\nSelective search – explore parts of the tree that will help improve the decision at the root, regardless of depth\n\nabandon the idea of fixed horizon\n\n\n\n\n\nMCTS version 0\n\nDo N rollouts from each child of the root, record fraction of wins\nPick the move that gives the best outcome by this metric\nmcts v0\nproblem with mcts v0\n\nkeep searching even though we know that’s a bad move → 0/10\n\n\n\nMCTS version 0.9\n\nallocate rollouts to more promising &amp; uncertain nodes\n\na tradeoff btw promising and uncertain\n\n\nMCTS version 0.9\n\nUpper Confidence Bounds - UCB heuristics\n\nUCB1 formula combines “promising” and “uncertain”\n\nUCB1(n)=N(n)U(n)​+C×N(n)logN(PARENT(n))​​\n\n\nN(n) = number of rollouts from node n\nU(n) = total utility of rollouts (e.g., # wins) for Player(Parent(n))\n\nKeep track of both for each node N(n)\n\n\nC: constant, depending on the stage of the game\n\nMCTS version 2.0: Upper Confidence of Trees - UCT\n\nRepeat until out of time:\n\nSelection: recursively apply UCB to choose a path down to a leaf node n  (i.e. from parent → choose child → grandchild → … → leaf node)\nExpansion: add a new child c to n\nSimulation: run a rollout from c\nBackpropagation: update U and N counts from c back up to the root\n\n\nChoose the action leading to the child with highest N\npic - UCT example\n\nwhy no min max\n\n“Value” of a node, U(n)/N(n), is a weighted sum of child values!\nIdea: as N → ∞, the vast majority of rollouts are concentrated in the best child(ren), so weighted average → max/min\nTheorem: as N → ∞ selects the minimax move\n\n(but N never approaches infinity!)\n\n\n"},"artificialIntelligence/multi-agent-utilities":{"title":"multi-agent utilities","links":[],"tags":[],"content":"\n\nWhat if the game is not zero-sum, or has multiple players?\nGeneralization of minimax:\n\nTerminals have utility tuples\nNode values are also utility tuples\nEach player maximizes its own component\nCan give rise to cooperation and competition dynamically…\n\n\n\n"},"artificialIntelligence/options-to-design-an-AI-agent":{"title":"options to design an AI agent","links":[],"tags":[],"content":"note\n\nThink/act as human\n\nHuman cognition and behavior\nLimitations and irrationality\n\n\nThink/act rationally\n\nGoal-oriented and utility-maximizing\nDecision-making process and outcomes\n\n\n"},"artificialIntelligence/ordering-in-CSPs---minimum-remaining-values,-least-constraining-value":{"title":"ordering in CSPs - minimum remaining values, least constraining value","links":["tags/computerScience/AI-ML/CSPs","tags/fc"],"tags":["computerScience/AI-ML/CSPs","fc"],"content":"Context\n\nTime: 06 04 2024 - 22:32\nTags:CSPs\nChild:\nSource:\n\nMinimum Remaining Valuesfc\n\nproblem in improving backtracking: which variable should be assigned next? → MRV\ndefinition: choose variable with minimum legal values left in its domain\n\nalso called “most constrained variable” or “fail-fast” ordering\n\n\n\nLeast constraining valuefc\n\nproblem in improving backtracking: in what order should the variable’s values be tried? → LCV\ndefinition: choose the least constraining value (the one that rule out fewest values in the remaining variables)\n\nmight take computation: eg. rerunning filtering\n\n\n"},"artificialIntelligence/pancake-problem":{"title":"pancake problem","links":[],"tags":[],"content":"note\n\npic\npic - tree search to get solution to pancake problem\n\ninitialize the search tree, initial state in the fringe\nloop to explore nodes in the fringe\n\nif the initial state is not the goal state\n\nif there are no candidates can be added to the fringe → return failure\nelse: choose a leaf node, expand on strategy\nif node contains a goal state → return solution\n\n\n\n\n\n\ntotal space graph is 4! = 4 (ways to choose the bottom layer) * 3 (ways to choose 3rd layer) * 2 (ways to choose 2nd layer) * 1 (way to choose the top layer) = 24\nAction and Cost: Flipping pancakes with a cost associated with the number of pancakes flipped.\nPath to Goal: Sequence of flips leading to the goal with a total cost.\n\nheuristic: # of largest pancake still out of place\n\n"},"artificialIntelligence/planning-agent":{"title":"planning agent","links":[],"tags":[],"content":"note\n\n\ndecide based on evaluating consequences of actions\n\n\nMust have a model of how the world evolves in response to actions\n\n\nMust formulate a goal (test)\n\n\nConsider how the world WOULD BE\n\n\nTypes:\n\nOptimal vs Complete planning\nPlanning vs Replanning\n\n\n"},"artificialIntelligence/probabilities,-for-search-in-AI":{"title":"probabilities, for search in AI","links":[],"tags":[],"content":"prob\n\nA random variable represents an event whose outcome is unknown\nA probability distribution is an assignment of weights to outcomes\nExample: Traffic on freeway\n\nRandom variable: T = whether there’s traffic\nOutcomes: T in {none, light, heavy}\nDistribution: P(T=none) = 0.25, P(T=light) = 0.50, P(T=heavy) = 0.25\n\n\nSome laws of probability (more later):\n\nProbabilities are always non-negative\nProbabilities over all possible outcomes sum to one\n\n\nAs we get more evidence, probabilities may change:\n\nP(T=heavy) = 0.25, P(T=heavy | Hour=8am) = 0.60\nWe’ll talk about methods for reasoning and updating probabilities later\n\n\n\nexpectation\n\nprobability * outcome\nThe expected value of a function of a random variable is the average, weighted by the probability distribution over outcomes\n\nwhat probability to use\n\nIn expectimax search, we have a probabilistic model of how the opponent (or environment) will behave in any state\n\nModel could be a simple uniform distribution (roll a die)\nModel could be sophisticated and require a great deal of computation\nWe have a chance node for any outcome out of our control: opponent or environment\nThe model might say that adversarial actions are likely!\n\n\nFor now, assume each chance node magically comes along with probabilities that specify the distribution over its outcomes\n"},"artificialIntelligence/quiz-2-AI":{"title":"quiz 2 AI","links":[],"tags":[],"content":"problem 2:\n\nfalse\n\nif all cost is not negative\n\n\nfalse\ntrue\ntrue\nfalse\ntrue\n\nucs is a star w heuristic 0\n\n\n\nproblem 3:\n\nA\nA\nC\nproblem 4:\nA\nA\nC\n"},"artificialIntelligence/reflex-agent":{"title":"reflex agent","links":[],"tags":[],"content":"note\n\nChoose action based on current percept (and maybe memory)\nMay have memory or a model of the world’s current state\nNo consideration of future consequences\nConsider how the world IS\nSimple and fast, but limited and suboptimal\n"},"artificialIntelligence/search-algorithm":{"title":"search algorithm","links":[],"tags":["computerScience/searchProblems"],"content":"Properties of search algorithm\n\ncomplete: guaranteed to find a solution if one exists?\noptimal: guaranteed to find least cost path?\ntime complexity?\nspace complexity?\npic\nSystematically builds a search tree\nChooses an ordering of the fringe (unexplored nodes)\nOptimal: finds least-cost plans\n\nCartoon of search tree:\n\nb: branching factor\nm: maximum depth\ns: depth of shallowest solution\nC*: cost of cheapest solution\n𝜺: minimum arc cost\nNumber of nodes in entire tree: 1+b+b2+⋯+bm=O(bm)\n"},"artificialIntelligence/search-heuristics":{"title":"search heuristics","links":[],"tags":[],"content":"what is a heuristic\n\nHeuristic Function: Estimates how close a state is to a goal, designed for specific search problems; a direction among multiple directions presented, to give a sense of the shortest path to the goal\nExamples: Manhattan distance (Manhattan(x1,y1,x2,y2)=∣x1−x2∣+∣y1−y2∣), Euclidean distance for pathing\npic - wo heuristic\npic - w heuristic: heuristic: the number of the largest pancake that is still out of place\nP(v) = dist(v) + h(v)\n\npriority for PQ = dist + heuristic → total path length → have to minimize this\n\n\n\n\nstart node: 90\n\n\n"},"artificialIntelligence/search-methods-for-CSPs":{"title":"search methods for CSPs","links":["artificialIntelligence/breadth-first-search---bfs","artificialIntelligence/depth-first-search---dfs","artificialIntelligence/backtracking-search"],"tags":[],"content":"BFS\n\nBFS in CSPs\n\nDFS\n\nDFS in CSPs\n\nNaive search\n\ndo all the assignments, then at the end discover it does not work → backtrack\n\nBacktracking search\n\nbacktracking search\n"},"artificialIntelligence/search-problems":{"title":"search problems","links":["artificialIntelligence/state-space","artificialIntelligence/models"],"tags":["computerScience/searchProblems"],"content":"note\n\nA search problem consists of:\n\nstate space: set of possible configurations\nSuccessor function: transitions between states (with actions, costs)\nStart state and goal test\n\n\nSolution: sequence of actions (plan) transforms start state → goal state\nSearch: find a solution if it exists\nSearch problem:\n\nmodels that abstract away the details of the environment\ncan have different state space sizes depending on the level of abstraction\nalmost always wrong but some are useful\n\n\n\n"},"artificialIntelligence/search-tree":{"title":"search tree","links":[],"tags":["computerScience/searchProblems/searchTree","computerScience/DSA/tree"],"content":"note\n\nA “What if” tree of plans (paths) in the state space graph\nStart state is the root node\nChildren correspond to successors\nNodes show states, but correspond to plans\nProblems:\n\nFor most problems, can never build the whole tree\nConstruct the tree on demand\n\n\n\n"},"artificialIntelligence/semi-lattice-of-heuristics":{"title":"semi-lattice of heuristics","links":["artificialIntelligence/semi-lattice-structure"],"tags":[],"content":"what is semi-lattice structure, comparison with tree\n\nsemi-lattice structure\n\npurpose of semi-lattice of heuristic\n\nunderstand relationships between different heuristics\nguide the selection of the most appropriate heuristics\npic of semi-lattice of heuristic\n\ncomparing dominance\n\nto see if 1 heuristic is dominant than the other\nDominance: ha​≥hc​ if:\n\n∀n:ha​(n)≥hc​(n)\nthis can tell us if both h(a) and h(c) is admissible (never overestimate the true cost), h(a) is better as it is closer to the actual cost ⇒ more efficient search\nnot all heuristic can be compared this way, sometimes they have lower and higher node, and can be in the same ranking\n\n\n\nbetter heuristics formed from 2 heuristics\n\nif have 2 heuristics, compare dominate btw them, and take the max ⇒ the max will be admissible and informative than either of these 2\nh(n)=max(ha​(n),hb​(n))\n"},"artificialIntelligence/semi-lattice-structure":{"title":"semi-lattice structure","links":[],"tags":[],"content":"what is semi-lattice structure, comparison with tree\n\npic of semi-lattice structure vs tree\n\n\nParent Nodes: In a tree, each node (except the root) has exactly one parent. This means there’s a single path from the root to any node. In a semi-lattice, a node can have more than one parent, allowing for multiple paths from the root to a node\n\n\n\n\nStructure: A tree has a hierarchical structure, with each level representing a “generation” of nodes. A semi-lattice doesn’t have this strict hierarchy and allows for more complex relationships between nodes\n\n\n\n\nReal-world analogy: A tree is like a family tree where each person has exactly one biological mother and one biological father. A semi-lattice is more like a network of roads in a city, where there are many different routes from one location to another\n\n\nMathematical Definition: A semi-lattice is a mathematical structure where any two elements have a greatest lower bound. This is not necessarily the case in a tree.\n"},"artificialIntelligence/state-space-graph-vs-search-tree":{"title":"state space graph vs search tree","links":[],"tags":["computerScience/searchProblems/searchTree","computerScience/searchProblems/stateSpace"],"content":"SSG vs ST\n\n\nNode in ST = entire path in SSG\n\n\na graph without a cycle = a tree\na graph with a cycle = an infinite tree\n\n\n"},"artificialIntelligence/state-space-graph":{"title":"state space graph","links":[],"tags":["computerScience/searchProblems/stateSpace"],"content":"State space graph\n\nMathematical representation of a search problem\n\nNodes: abstracted world configurations\nArcs: successors (action results)\n\n\nGoal test: set of goal node(s)\nIn a state space graph, each state occurs only once\nProblem: Too big to build in memory, but useful\n\n\n"},"artificialIntelligence/state-space":{"title":"state space","links":[],"tags":["computerScience/searchProblems/stateSpace"],"content":"definition\n\n\nWorld state: every detail of the environment\n\n\nSearch state: only relevant details for planning (abstraction)\n\n\nTrade-off between expressiveness and tractability\n\n\nexample:\n\n\n\n\n\nstate space size\n\nState space size: number of possible search states\nexample\n\n\n\n\n\n"},"artificialIntelligence/the-dangers-of-optimism-and-pessimism-in-model-assumptions":{"title":"the dangers of optimism and pessimism in model assumptions","links":[],"tags":[],"content":"\n\ndangerous optimism: assuming chance when the world is adversarial\ndangerous pessimism: assuming worst case when its not likely\n\nassumptions vs reality\n\nadversarial ghost &amp; minimax pacman = perfect combination\npic - adversarial ghost vs random ghost &amp; minimax pacman vs expectimax pacman\n\n"},"artificialIntelligence/the-different-approached-to-AI":{"title":"the different approached to AI","links":[],"tags":[],"content":"title\nnote\n\nThere are four main approaches to AI: acting humanly, thinking humanly, thinking rationally, and acting rationally.\nThe rational agent approach has been the most common as it involves creating agents that act so as to achieve the best outcome or the best expected outcome.\n"},"artificialIntelligence/the-importance-of-AI":{"title":"the importance of AI","links":[],"tags":[],"content":"title\nnote\n\nArtificial Intelligence (AI) is a significant field because it enables machines to mimic human intelligence.\nAI is a broad field that includes various subfields such as\n\nlearning,\nreasoning,\nperception,\nnatural language processing,\nand more.\n\n\n"},"artificialIntelligence/the-structure-of-agents":{"title":"the structure of agents","links":[],"tags":[],"content":"title\nnote\n\nAgents can be grouped into five classes based on the nature of their environment and how they operate: simple reflex agents, model-based reflex agents, goal-based agents, utility-based agents, and learning agents.\n"},"artificialIntelligence/tree-search-algorithm":{"title":"tree search algorithm","links":[],"tags":["computerScience/DSA/tree","computerScience/searchProblems/searchTree"],"content":"Search algorithm\n\nExpand out potential plans (tree nodes)\nMaintain a fringe (storage) of partial plans under consideration\nExploration strategy: Try to expand as few tree nodes as possible\n\nGeneral Tree Search\n\n\nMain questions:\n\nWhich leaf node to expand next\nWhether to check for repeated states\nData structures for frontier, expanded nodes\n\n\n"},"artificialIntelligence/uniform-cost-search---ucs":{"title":"uniform cost search - ucs","links":[],"tags":[],"content":"what is uniform cost search\n\nStrategy: expand a cheapest node first\nImplementation: fringe is a priority queue (priority: cumulative cost)\nProperties: (if the solution cost C* and arc costs at least 𝜺 → effective depth is roughly C*/𝜺\n\nTime complexity: \\\\(O(b^{C*/𝜺})\\\\)\nSpace complexity: \\\\(O(b^{C*/𝜺})\\\\)\nComplete: yes (if C* and 𝜺 are finite and positive)\nOptimal: yes\n\n\nvisualization\npic\nGood?\n\ncomplete &amp; optimal\n\n\nBad?\n\nexplore options in every direction\nno info about goal location\n\n\n"},"artificialIntelligence/utility-of-sequences-in-MDP":{"title":"utility of sequences in MDP","links":[],"tags":[],"content":"discounting of rewards\n\n\nmaximize rewards now ⇒ values of rewards decay exponentially\n\n\n\n\n\nU=R0​+γR1​+γ2R2​+⋯\n\n\nHow to discount?\n\nEach time we descend a level, we multiply in the discount once\n\n\n\nWhy discount?\n\nHelps our algorithms converge\nUncertainty about the future may not be fully represented\nIf the reward is financial, immediate rewards may earn more interest than delayed rewards\nAnimal/human behaviour shows preference for immediate reward\n\n\n\nInfinite Utilities: solution to game lasting forever, resulting in infinite rewards (esp when rewards are positive):\n\nfinite horizon (similar to depth-limited search)\n\nTerminate episodes after a fixed T steps (e.g. life)\n\nFor example, if we’re modeling a robot’s actions in a warehouse, we might decide to only look 100 steps into the future\nThe utility of a state is then the sum of the rewards for the next 100 steps.\n\n\nGives non-stationary policies (𝝿 depends on time left)\n\nwhen using finite horizon → policies become non-stationary (can change over time)\neg. when using finite horizon of 100 steps\n\nEarly in the horizon, it prioritizes actions that lead to long-term rewards (e.g., reaching distant packages).\nAs the horizon approaches, it becomes more focused on immediate rewards (e.g., delivering nearby packages).\n\n\n\n\n\n\nDiscounting:\n\nuse 0&lt;γ&lt;1\nU([r0​,⋅⋅r∞​])=∑t=0∞​γtrt​≤Rmax/(1−γ)\n\n\nAbsorbing state:\n\nguarantee that for every policy, a terminal state will eventually be reached (like “overheated” for racing)\n\n\n\n\n"},"artificialIntelligence/what-is-AI":{"title":"what is AI","links":["The-Turing-Test"],"tags":[],"content":"title\nnote\n\nAI has been defined in various ways, including thinking like a human, acting like a human, thinking rationally, and acting rationally.\nThe Turing Test, proposed by Alan Turing, is a method of measuring a machine’s ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human.\n"},"artificialIntelligence/zero-sum-games":{"title":"zero sum games","links":[],"tags":[],"content":"Zero-Sum Games\n\nAgents have opposite utilities (values on outcomes)\nLets us think of a single value that one maximizes and the other minimizes\nAdversarial, pure competition\nthe total sum is always 0 (the lose of someone is the gains of the others)\n\nGeneral Games\n§ Agents have independent utilities (values on outcomes) § Cooperation, indifference, competition, and more are all possible § More later on non-zero-sum games"},"comOrg/***comOrg-map":{"title":"***comOrg map","links":["comOrg/translators---assembler-+-compiler-+-interpreter","comOrg/instruction-set-architecture-(ISA)","comOrg/moore's-law","comOrg/base10---decimal,-base2---binary,-base16---hexadecimal","comOrg/negative-numbers-_-sign-magnitude-+-twos-complement-+-sign-extension--and--truncation","comOrg/transistors-_-n-type-and-p-type","comOrg/cmos-notation","comOrg/logic-gates","comOrg/universal-gates-_-nand-+-nor","comOrg/hide-complexity-in-logic-gates-through-abstraction","comOrg/multiplexer---MUX","comOrg/logic-symbols--and--notation","comOrg/logic-implementation-_-from-truth-tables-to-logic-circuits","comOrg/Combinational-circuits","comOrg/equality-comparators-using-XOR","comOrg/2-to-1-MUX","comOrg/4-to-1-MUX","comOrg/decoder","comOrg/encoder","comOrg/1-bit--and--4-bit-full-adder","comOrg/overflow","comOrg/binary-subtraction","comOrg/4-bit-adder-OR-subtractor","tags/toProceed","comOrg/shifters","comOrg/Arithmetic-Logic-Unit---ALU","comOrg/numbers-with-fractions-in-computer","comOrg/Sequential-circuits","comOrg/clock-in-sequential-circuit","Finite-State-Machine","comOrg/Moore-machine","comOrg/Mealy-machine","comOrg/State-diagram","comOrg/level-of-languages-in-computer","comOrg/instruction-processing","comOrg/RISC-V","comOrg/User-level-ISA","comOrg/RISC-V-registers","comOrg/Instruction-Types--and--RISC-V-Instruction-Types","R-Type-1:-arithmetic-and-logic","R-Type-2:-shift-instructions"],"tags":["computerArchitecture","toProceed"],"content":"comOrg map\nLecture 1\n\ntranslators - assembler + compiler + interpreter\ninstruction set architecture (ISA)\nmoore’s law\nbase10 - decimal, base2 - binary, base16 - hexadecimal\nnegative numbers _ sign-magnitude + twos-complement + sign extension &amp; truncation\n\nLecture 2\n\ntransistors _ n-type and p-type\ncmos notation\nlogic gates\nuniversal gates _ nand + nor\nhide complexity in logic gates through abstraction\nmultiplexer - MUX\nlogic symbols &amp; notation\nlogic implementation _ from truth tables to logic circuits\n\nLecture 3\n\nCombinational circuits\nequality comparators using XOR\nmultiplexer - MUX\n\n2-to-1 MUX\n4-to-1 MUX\n\n\ndecoder\nencoder\n\nLecture 4: Binary Arithmetic\n\n1 bit &amp; 4 bit full adder\noverflow\nbinary subtraction\n4 bit adder OR subtractortoProceed\nshifterstoProceed\nArithmetic Logic Unit - ALU\nnumbers with fractions in computer\n\nLecture 5: Sequential Logic\n\nSequential circuits\n\nclock in sequential circuit\n\n\n\nLecture 6: Finite State Machines\n\nFinite State Machine\n\nMoore machine\nMealy machine\n\n\nState diagram\nstate encoding:\n\nBinary encoding:\n\nN states need log2​N FFs\nEg: S0 = 00, S1 = 01, S2 = 10, S3 = 11\ntables\n\nstate transition\n\n\n\n\nbinary encoding\n\n\n\n\nmin term table ⇒ minterms ⇒ shorten, if possible\n\n\n\n\ncircuit\n\n\n\n\nOne-hot encoding\n\nEach state has 1 flip flop, Q of 1 FF = 1, Q of others = 0\nEg:             Q3 Q2 Q1 Q0\n\nS0 =   0    0    0    1\nS1 =    0    0    1    0\nS2 =    0    1    0    0\nS3 =    1    0    0    0\n\n\n\ncircuit\n\n\n\n\n\nLecture 8+9: RISC-V ISA\n\nlevel of languages in computer\nnumber of assembly languages: many, each processor need 1\nsimilar to number of C (?)\nRV32I - calc integers\nRV64F - calc float\ninstruction processing\nRISC-V\nUser level ISA\nRISC-V registers\nInstruction Types &amp; RISC-V Instruction Types\n\nR-Type 1: arithmetic and logic\nR-Type 2: shift instructions\n\n\n"},"comOrg/1-bit--and--4-bit-full-adder":{"title":"1 bit & 4 bit full adder","links":[],"tags":[],"content":"what is 1 bit full adder\n\n\n\nwhat is 4 bit full adder\n\n\n"},"comOrg/2-to-1-MUX":{"title":"2-to-1 MUX","links":[],"tags":[],"content":"note\n\n1 S: select input\n(Y=S′∗I0+S∗I1)\nwhen S = 0 → Y = I0\nwhen S = 1 → Y = I1\n\n"},"comOrg/4-bit-adder-OR-subtractor":{"title":"4 bit adder OR subtractor","links":[],"tags":[],"content":"what is 4 bit adder / subtractor\n\n\n\n"},"comOrg/4-to-1-MUX":{"title":"4-to-1 MUX","links":[],"tags":[],"content":"note\n\n2 S (select inputs)\n\neg. 8to1 MUX → 3S, 16to1 MUX → 4S\n\n\nY=S1′.S0′.I0+S1′.S0.I1+S1.S0′.I2+S1.S0.I3\n\n"},"comOrg/Arithmetic-Logic-Unit---ALU":{"title":"Arithmetic Logic Unit - ALU","links":[],"tags":[],"content":"what is ALU\n\nCombinational logic circuit that combines a variety of operations into a single unit\n\ncommon operations may include\n\nAddition and subtraction\nLogical (OR, AND)\nShift\nComparisons\n\n8 bit ALU\n\n\n\n\n\nALU operations, inputs &amp; outputs:\n\n\n\n\n\nALU block diagram\n\n\neg. ALU operation encodings\n\n\n\n\n"},"comOrg/Combinational-circuits":{"title":"Combinational circuits","links":["comOrg/equality-comparators-using-XOR","comOrg/multiplexer---MUX","comOrg/decoder","comOrg/encoder"],"tags":[],"content":"note\n\n\ncomplex functions built from basic gates\n\ncomparators\nMultiplexers\nDecoders\nEncoders\n\n\n\ncombinational: output depends only on current inputs\n\n\n\n\n"},"comOrg/D-Flip-Flop---DFF":{"title":"D Flip Flop - DFF","links":[],"tags":["comArc/sequentialCircuit"],"content":"positive edge-triggered DFF\n\ndata captured when clock low (0)\noutput changes only on rising edge\nQ = D\npic - positive edge-triggered DFF\n"},"comOrg/Instruction-Types--and--RISC-V-Instruction-Types":{"title":"Instruction Types & RISC-V Instruction Types","links":[],"tags":[],"content":"Instruction Types\nArithmetic\n• add, subtract, shift left, shift right, multiply, divide\nMemory\n• load value from memory to a register\n• store value to memory from a register\nControl flow\n• conditional jumps (branches)\n• jump and link (subroutine call)\nMany other instructions are possible\n• vector add/sub/mul/div, string operations\n• manipulate coprocessor\n• I/O\nRISC-V Instruction Types\n\nArithmetic/Logical\n\nR-type: result and two source registers, shift amount\nI-type: result and source register, shift amount in 16-bit immediate with sign/zero extension\nU-type: result register, 16-bit immediate with sign/zero extension\n\n\nMemory Access\n\nI-type for loads and S-type for stores\nload/store between registers and memory\nword, half-word and byte operations\n\n\nControl flow\n\nS-type: conditional branches: pc-relative addresses\nU-type: jump-and-link\nI-type: jump-and-link register\n\n\n\n"},"comOrg/Mealy-machine":{"title":"Mealy machine","links":[],"tags":["Math/discrete/Automata","comArc/sequentialCircuit/FSM"],"content":"Mealy state diagram\n\n1 input, 1 output, 2 states\nBubble for each state\nState transitions (arcs) for each input value\nInput values on the arcs (first number)\nOutput values on the arcs (second number)\nStarts at S0 when Reset asserted\n\nMealy machine structure diagram\n\npic\noutput depends on inputs and current state values\n"},"comOrg/Moore-machine":{"title":"Moore machine","links":[],"tags":["Math/discrete/Automata","comArc/sequentialCircuit/FSM"],"content":"Moore state diagram\n\n1 input, 1 output, 3 states\nBubble for each state\nState transitions (arcs) for each input value\nInput values on the arcs\nOutput values within the bubbles\nStarts at S0 when Reset asserted\npic\n\nMoore machine structure diagram\n\npic\noutput depend on current state value\n"},"comOrg/RISC-V-registers":{"title":"RISC-V registers","links":[],"tags":[],"content":"\nProgram counter (pc)\n32x32-bit integer registers (x0-x31)\n\nx0 always contains a 0\nx1 to hold the return address on a call.\n\n\n32 floating-point (FP) registers (f0- f31)\n\nEach can contain a single- or double precision FP value (32-bit or 64-bit IEEE FP)\nIs an extension\n\n\n"},"comOrg/RISC-V":{"title":"RISC-V","links":[],"tags":[],"content":"what is RISC-V (reduced instruction set computer)\nRISC-V, pronounced “risk five”, is an ISA standard (a document)\n\nopen-source implementation of a reduced-instruction-set-computer-based instruction set architecture\nprevious version before: RISC-I, II, III, IV\n\nmost ISA: X86, ARM, Power, MIPS, SPARC\n\ncommercially protected by patents\nprevent practical efforts to reproduce computer systems (so as to effectively sell patents :D)\n\nRISC-V is open source\n\npermit any person / group to construct compatible computers\nuse associated software\n\noriginated from UC Berkeley\n\nin 2010, by CS researchers at UCB\nnow has large number of contributors\n\nRISC-V ISA principles\n\nkept simple &amp; extendable\nseparated into multiple specifications\n\nUser-Level (unprivileged) ISA spec\nCompressed ISA spec (16-bit instructions)\nPrivileged ISA spec (supervisor-mode instructions)\n\n\nISA support is given by RV + word−width + extensionssupported\n\nE.g. RV32I means 32bitRISC−V with supportfortheIinstructionset\nE.g. RV64F means 64-bit RISC-V with support for the Single precision Floating-point instruction set\n\n\n"},"comOrg/Sequential-circuits":{"title":"Sequential circuits","links":["comOrg/clock-in-sequential-circuit"],"tags":["computerArchitecture/sequentialCircuit"],"content":"sequential circuit vs combinational circuit\n\nCombinational: Output depends only on current input\nSequential:\n\nOutput depends on current inputs + state variables (past history of the circuit, hold by the storage elements)\na clock periodically advances the circuit\n\n\npic sequential circuit vs combinational circuit\n\ntypes of sequential circuits:\n\nasynchronous sequential circuits: outputs &amp; state change AS input change\nsynchronous sequential circuits: output &amp; state change ONLY WHEN a special input, the clock, gets a certain value\n"},"comOrg/State-diagram":{"title":"State diagram","links":[],"tags":[],"content":"what is state diagram\n\nvisual specification of FSM\n\nBubble: state\nArcs: state transitions\nInput values shown on the arcs\nOutput values shown within the bubbles (Moore) or on the arcs (Mealy)\nClock input implicit (always present, triggering state transitions)\n\n\npic of Moore and Mealy FSM\n"},"comOrg/User-level-ISA":{"title":"User level ISA","links":[],"tags":[],"content":"define normal instructions needed for computation\n\nA mandatory Base integer ISA\n\nI: Integer instructions: ALU, branches/jumps, and loads/stores\n\n\nStandard Extensions\n\nM: Integer Multiplication and Division\nA: Atomic Instructions\nF: Single-Precision Floating-Point\nD: Double-Precision Floating-Point\nC: Compressed Instructions (16 bit)\nand more\n\n\n"},"comOrg/base10---decimal,-base2---binary,-base16---hexadecimal":{"title":"base10 - decimal, base2 - binary, base16 - hexadecimal","links":[],"tags":["computerScience/numerals"],"content":"general\n\n\n\nconvert to base 10\n\n\n\nconvert from base 10\n\nuse the remainder method\nrepeatedly divide by the number of base you are converting to\nplacing the remainder in backward order\n\n\nconversion summary\n\n\n"},"comOrg/binary-subtraction":{"title":"binary subtraction","links":[],"tags":[],"content":"what is two’s complement subtraction\n\n\n"},"comOrg/clock-in-sequential-circuit":{"title":"clock in sequential circuit","links":["comOrg/D-Flip-Flop---DFF"],"tags":["comArc/sequentialCircuit"],"content":"what is clock in sequential circult\n\nan input to a sequential circuit that changes output and state values at a predetermined rate\n\ntriggering edge\n\ntransition of the clock, capturing the input data\ninclude:\n\nPositive (rising) edge: 0 →1\nNegative (falling) edge: 1 → 0\n\n\nclock tick = occurrence of a triggering edge\n\nclock period and frequency\n\nclock period (cycle time): time between successive transitions in the same direction = tper​\nclock frequency: 1/tper​\npic - clock period and frequency\n\nedge-triggered storage\n\nD Flip Flop - DFF\n"},"comOrg/cmos-notation":{"title":"cmos notation","links":[],"tags":[],"content":"note\n\n\np-type\n\n0 to turn on/close = conducting current\n1 to turn off/open = not conducting current\n\n\nn-type\n\n1 to turn on/close = conducting current\n0 to turn off/open = not conducting current\n\n\n\nCMOS inverter\n\n\n"},"comOrg/decoder":{"title":"decoder","links":[],"tags":[],"content":"binary decoders\n\nn inputs, (2n) outputs\nEach output corresponds to a unique input value\nAt most one output asserted at a time (all is outputted at the same time &gt;&lt; only 1 is active)\n\n\n2-to-4 decoder\n\n\nexample: remember n inputs, (2n) outputs\n\nA1A0 is 00 → 1 in Y0\nA1A0 is 01 → we have 0 input → output is 2^0 = 1  → Y1 = 1\nA1A0 is 11 → 2^1 + 2^0 = 3 → Y3 = 1\n\n\n\n3-to-8 decoder\n\n\nA2A1A0 is 110 → 2^2+2^1 = 6 → Y6 = 1\n\ndecoder with enable\n\npic1\n\nillustration:\n\n1st row 0XX = when the enable is turned off, whatever input, there wont be any output\nfrom row 2 onward, enable is 1, it works just like normal decoder, taking into account the output solely not the enable anymore\n\n\n\n\npic2: enable is drawn just like an extra input\n"},"comOrg/encoder":{"title":"encoder","links":["comOrg/decoder"],"tags":["computerArchitecture/encoder"],"content":"note\n\nbinary encoders: 2n inputs → n outputs (encoder is opposite of decoder)\n\nquick remember: (2N) looks just like ENcoders\n\n\neg. keyboard\nexactly one input is asserted at any given time\n\n4-to-2 encoder\n\n\nanalyze:\n\nI3 = 1 → 2^n = 3 →\n\n\n"},"comOrg/equality-comparators-using-XOR":{"title":"equality comparators using XOR","links":[],"tags":[],"content":"note\n\n\n"},"comOrg/hide-complexity-in-logic-gates-through-abstraction":{"title":"hide complexity in logic gates through abstraction","links":[],"tags":[],"content":"note\n\n\n"},"comOrg/instruction-processing":{"title":"instruction processing","links":[],"tags":[],"content":"instruction processing\n\na basic processor\n\nfetches\ndecodes\nexecutes\none instruction at a time\n\n\n\n"},"comOrg/instruction-set-architecture-(ISA)":{"title":"instruction set architecture (ISA)","links":[],"tags":["computerArchitecture/ISA"],"content":"definition\n\nabstract interface between hardware and the lowest level software\n\n\ngroup of commands that processor can perform, to execute the program instructions\nevery processor designed is based on 1 specific ISA, which defines the operational capacity of processor in terms of set of commands, that the processor can decode and execute\nIntel 8085 ISA, has 246 operation codes, 74 instructions\n\nhow ISA is implemented\n\n\nmicroarchitecture\n\nprocessor architecture at the hardware level\nactual hardware implementation of the ISA\nhardware circuitry of the processor chip that implements 1 particular ISA\n\n\n"},"comOrg/level-of-languages-in-computer":{"title":"level of languages in computer","links":[],"tags":[],"content":"high level language\n\nC, Java, Python\nLoops, control flow, variables\n\nAssembly language\n\nno symbols (except labels)\n1 operation per statement\n”human readable machine language”\n\nMachine language\n\nbinary-encoded assembly\nlabels become addresses\nthe language of the CPU\n\nillustration\n or link"},"comOrg/logic-gates":{"title":"logic gates","links":[],"tags":[],"content":"definition\n\n\n\nlogic gates: names + symbols + truth tables\n\n\n\nlogic functions\n\n\n"},"comOrg/logic-implementation-_-from-truth-tables-to-logic-circuits":{"title":"logic implementation _ from truth tables to logic circuits","links":[],"tags":[],"content":"note\n\ncombination circuit\n\n\n\n\n"},"comOrg/logic-symbols--and--notation":{"title":"logic symbols & notation","links":[],"tags":[],"content":"\n\n"},"comOrg/moore's-law":{"title":"moore's law","links":[],"tags":[],"content":"note\n\n”# of transistors integrated on a die doubles every 18-24 months (i.e., grows exponentially with time)” - 1965 (Gordon Moore, founder Intel Corp.)\n"},"comOrg/multiplexer---MUX":{"title":"multiplexer - MUX","links":[],"tags":[],"content":"note\n\n\n\nDescription:\n\nIf selection is 0 choose the first input, otherwise choose the second input\nCombinational circuit that has multiple data inputs and one output, along with additional control or select inputs. The control inputs determine which of the data inputs is connected to the output.\n\n\nhow it works\n\nconnects one of n inputs to the output\n\nselect control signals pick one of the n sources (log2n select bits)\n\n\nuseful when multiple data sources need to be routed to a single destination\n\nOften arises from resource sharing\nExample: select 1-of-n data inputs to an adder\n\n\nunderstand how it output\n\nThe selection lines essentially form a 2-bit binary number that determined which input is selected to appear at the output\n\neg. 4-to-1 MUX\n\nIf S1S0 is 00, then I0 is selected.\nIf S1S0 is 01, then I1 is selected.\nIf S1S0 is 10, then I2 is selected.\nIf S1S0 is 11, then I3 is selected.\n\n\n\n\n\n\n\ncascading multiplexers\n\nLarge multiplexers can be implemented by cascading smaller ones\npic\n"},"comOrg/negative-numbers-_-sign-magnitude-+-twos-complement-+-sign-extension--and--truncation":{"title":"negative numbers _ sign-magnitude + twos-complement + sign extension & truncation","links":[],"tags":[],"content":"sign-magnitude representation\n\nconsists of 2 parts: sign and magnitude\ndecimal example: +12310​ and −12310​\nbinary example: 011002​=+1210​,111002​=−1210​\n\nsign represented by MSB (most significant bit = leftmost digit): 1 = negative, 0 = positive\n\n\n\ntwo’s complement representation\n\nrepresent negative number\npositive numbers represented as usual\nleading 1’s for negative numbers\nto negate any number\n\nWAY 1\n\nflip all the bits\nadd 1 to the least significant bit (LSB = rightmost digit)\n\n\nWAY 2\n\ntranslate normally like base 10 →\n\n\n\n\n"},"comOrg/numbers-with-fractions-in-computer":{"title":"numbers with fractions in computer","links":[],"tags":[],"content":"two common notations for numbers with fractions\n\nFixed-point: binary point fixed\nFloating-point: binary point floats to the right of the most significant 1\n"},"comOrg/overflow":{"title":"overflow","links":[],"tags":[],"content":"when can overflow occur\n\n\n\n"},"comOrg/shifters":{"title":"shifters","links":["tags/toProceed"],"tags":["toProceed"],"content":"logical shifters (&gt;&gt; or &lt;&lt;)\n\nshift value to left or right, fill empty spaces with 0’s\n\nEx: 11001 &gt;&gt; 2 = 00110\nEx: 11001 &lt;&lt; 2 = 00100\n\n\n\nArithmetic shifter (&gt;&gt;&gt; or &lt;&lt;&lt;)\n\nsame as logical shifter, but on right shift, fills empty spaces with the old most significant bit (msb).\n\nEx: 11001 &gt;&gt;&gt; 2 = 11110\nEx: 11001 &lt;&lt;&lt; 2 = 00100\n\n\n\nRotator\n\nrotates bits in a circle, such that bits shifted off one end are shifted into the other end\n\nEx: 11001 ROR 2 = 01110 (put skipped to be the beginning, rotate right)\nEx: 11001 ROL 2 =  00111(put skipped to the end, rotate left)\n\n\n\nshifter designtoProceed\n\n\n\neg. shift 2 times the input Y3 Y2 Y1 Y0 ⇒ they are all at 10 ⇒ 0 0 A3 A2\n\n\n\nshifters as multipliers, dividers\n\n\njust like in base 10, now is for base 2\n\n\nA&lt;&lt;N=A×2N\n\nExample: 00001 &lt;&lt; 2  = 00100  (1 × 22 = 4)\nExample: 11101 &lt;&lt; 2  = 10100  (-3 × 22 = -12)\n\n\n\nA&gt;&gt;&gt;N=A÷2N\n\nExample: 01000 &gt;&gt;&gt; 2 = 00010  (8 ÷ 22 = 2)\nExample: 10000 &gt;&gt;&gt; 2 = 11100  (-16 ÷ 22 = -4)\n\n\n"},"comOrg/transistors-_-n-type-and-p-type":{"title":"transistors _ n-type and p-type","links":[],"tags":[],"content":"info about transistors\n\n\n2 types of silicon\n\np-type silicon: positive free-carriers (holes)\nn-type silicon: negative free-carriers (electrons)\n\n\n2 types of transistors\n\np-transistor: Gate (- charged), generates electric field that creates a (+ charged) p-type channel connecting sources &amp; drain\nn-transistor: Gate (+ charged), generates electric field that creates a (- charged) n-type channel connecting sources &amp; drain\n\n\n\nCMOS\n\nComplementary Metal-Oxide Semiconductor (CMOS)\nuse both p- &amp; n-type transistors\n"},"comOrg/translators---assembler-+-compiler-+-interpreter":{"title":"translators - assembler + compiler + interpreter","links":[],"tags":["computerArchitecture/translator"],"content":"what is translator in computer\n\ndefinition\n\na translator or a programming language processor that converts a computer program from a language to another\nit takes a program written in source code and converts into machine code\nit discover and identifies errors during translation\n\n\ntypes of translators\n\nassembler: assembly (src code) → assembler (translator) → machine level language (object code)\ncompiler:\n\nread the complete src program in high level language → if error free, convert into machine level language\nspecifies errors in the src code at the end of compilation, if any\n\n\ninterpreter\n\nconvert high-level language to machine level language\nit converts line by line, then report errors with executable lines’ results → faster than compiler\n\n\n\n\n"},"comOrg/universal-gates-_-nand-+-nor":{"title":"universal gates _ nand + nor","links":[],"tags":[],"content":"note\n\ncan implement any functions with just NAND or NOR gates\nuseful for manufacturing\npic\n"},"history2/***history-2-map":{"title":"***history 2 map","links":["history2/Có-cần-phải-cải-tiến-chữ-quốc-ngữ","history2/his2lec2-questions","history2/Nhật-Bản","history2/đường-sắt-bắc-nam","history2/NAQ-về-Quảng-Châu","history2/reflection-lecture-3-his2","history2/Everything-about-Võ-Nguyên-Giáp","history2/make-in-việt-nam-his2","history2/liệu-có-thể-tránh-được-cuộc-chiến-tranh-đông-dương-lần-1-hay-không","history2/draft---pháp-rơi-vào-thế-phải-chiến","history2/LĐ1---Pháp-rơi-vào-thế-phải-chiến"],"tags":[],"content":"Lecture 1\nCó cần phải cải tiến chữ quốc ngữ?\nLecture 2\n\nhis2lec2 questions\nNhật Bản\n\nCâu 3: Tại sao Pháp xây dựng đường sắt Bắc Nam? Bây giờ có cần xây dựng đường sắt Bắc Nam không? đường sắt bắc nam\n\nLecture 3\n\nNAQ về Quảng Châu\nlàm 1 việc k có thiên thời địa lợi nhân hoà, thì có phải đg cùng k mà làm. cta sẽ justify hành động của mk, cho rằng đường cùng. Nhưng thực ra luôn luôn có đường khác\ntướng giỏi là tưởng còn sống và ít thiệt hại nhất (đầu tiên là cho tướng)\nbác muốn khuyến khích mng viết báo → lãnh đạo phải biết viết\n\n\n\nhỏi câu simple\nreflection lecture 3 his2\ncompare (tác động ít nhóm ng hơn, sustainable hơn)\n\nLecture 5:\n\nEverything about Võ Nguyên Giáp\n”Lời kêu gọi toàn quốc kháng chiến” của HCM ngày 19/12/1946 đã phát động một cuộc chiến tranh toàn dân chống Pháp. Tư tưởng nào có thể dùng để phát động một cuộc chiến về công nghệ trong chiến dịch “Make in Việt Nam” - make in việt nam his2\n\nLecture 6:\n\nliệu có thể tránh được cuộc chiến tranh đông dương lần 1 hay không\n\ndraft - pháp rơi vào thế phải chiến\nLĐ1 - Pháp rơi vào thế phải chiến\n\n\n"},"history2/Chiến-tranh-Thế-giới-2":{"title":"Chiến tranh Thế giới 2","links":[],"tags":[],"content":"\nkết thúc CTTG1 vào 1918\n\nthắng trận: Anh, Pháp, Italia, Mỹ, Nhật\nbại trận: Đức, Áo - Hung\n\n\n1929, đại khủng hoảng kinh tế → từ sụp đổ thị trường chứng khoán hoa kì, lan rộng toàn TG ⇒ 2 cách khôi phục kinh tế chính\n\ntiến hành cải cách kinh tế xã hội: Anh, Pháp, Mỹ\nbành trướng lãnh thổ, xâm chiếm thuộc địa, vơ vét tài nguyên: Đức, Ý, Nhật\n\n\n10 May – 25 June 1940, đức thắng pháp (The Battle of France), xoá sạch đội quân tinh nhuệ nhất nước Pháp → cuộc di tản Dunkirk (đội quân cuối cùng của A thoát đc) → Đức chiếm luôn Paris, thôn tính Pháp, kiểm soát các thuộc địa bù nhìn của pháp (gồm VN) (bằng cách lập chính phủ bù nhìn ở P)\ncủng cố khối liên minh phát xít - ý, đức, nhật ký hiệp ước tam cường\n22/6/1941, xoá bỏ hiệp ước xô đức (không xâm lược lẫn nhau) → xâm lược liên xô\n1940s, ở châu á, nhật nhanh chóng chiếm hầu hết miền đông trung quốc\n1944, mỹ anh, quân đồng minh, đánh đức, pháp đc giải phóng\n⇒ pháp\n\n\n\nđộng lực\n\nmong muốn: lòng tham muốn chiếm đất, bóc lột lao động, tài nguyên\n\nThe French colonization and occupation of Vietnam were a result of secular imperialism, driven by economic interests and strategic considerations. In addition to exploiting Vietnam’s resources, the French saw the region as a strategic buffer to facilitate access to resources in China. France, however, used the pretext of protecting Christians, who were persecuted by the Nguyen, as a justification for their invasion of Vietnam. (link)\n\n\nsợ hãi: không duy trì được vị thế cường quốc của mình, sau khi liên tục bị mất nước → Pháp cần lấy lại vị thế, danh dự, đường đường là cường quốc lớn từng thắng CTTG1, giờ lại bại trận\n\nsau CTTG1, thế giới trải qua\n\n\n\n\n"},"history2/Có-cần-phải-cải-tiến-chữ-quốc-ngữ":{"title":"Có cần phải cải tiến chữ quốc ngữ?","links":[],"tags":[],"content":"note\n\nƯu điểm của chữ quốc ngữ.\nsử dụng rất ít kí hiệu nhưng khả năng biểu đạt cao\nVì theo mẫu tự La Tinh ⇒ dễ học dễ viết, tạo điều kiện để người việt dễ học các ngôn ngữ khác (anh, pháp,..)\nA. Dễ học và sử dụng B. Hỗ trợ giao tiếp và tiếp cận thông tin C. Khả năng tương thích với công nghệ và phương tiện truyền thông hiện đại\nNhược điểm của chữ quốc ngữ.\nDo người phương tây soạn ⇒ ký tự hay cụm ký tự ghi cùng một âm tiết (c và k, g và gh, ng và ngh)\nRa đời khi cơ sở nghiên cứu phân tích hệ thống ngữ âm của tiếng Việt chưa đầy đủ, chưa có những khái niệm ngôn ngữ học hiện đại như âm vị nên có chỗ bất hợp lý\nNgôn ngữ kèm nhiều dấu phụ nhất trên thế giới\nA. Sự phong phú và phức tạp của ngôn ngữ Việt Nam B. Thiếu khả năng phản ánh đầy đủ các âm điệu và ngữ điệu C. Khó khăn trong việc bảo tồn và phát triển văn hóa dân tộc thông qua chữ quốc ngữ\nNhững đề xuất cải tiến chữ quốc ngữ gần đây.\nA. Cần cân nhắc giữa việc cải tiến và bảo tồn chữ quốc ngữ B. Khuyến khích nghiên cứu và đầu tư vào các phương pháp giảng dạy và sử dụng chữ quốc ngữ hiệu quả hơn C. Tôn trọng và bảo tồn những giá trị văn hóa của ngôn ngữ Việt Nam thông qua việc phát triển chữ quốc ngữ.\n\n⇒ Possible Qs:"},"history2/Everything-about-Võ-Nguyên-Giáp":{"title":"Everything about Võ Nguyên Giáp","links":[],"tags":[],"content":"\n\n“Dân không thờ sai ai bao giờ” - Dương Trung Quốc. lòng dân sẽ quyết định các bậc tiền nhân còn sống mãi trong lịch sử dân tộc hay không”\n\nFun insight\n\n\nLê Đức Thọ không thích Võ Nguyên Giáp → mqh giữa tướng Giáp và LĐT\n\nchiến dịch mậu thân 1968: [link](5 VỊ TƯỚNG TÀI BA NHẤT LỊCH SỬ VIỆT NAM (P1) (spiderum.com))\n30 ng thân cận với tướng pháp bị bắt giữ\nTướng Giáp đưa chưã bệnh Hungary\nHCM nghỉ ngơi ở Bắc Kinh\ndù thua trong chiến trường, nhưng bức ảnh đã đưa chiến thắng trên truyền thông trả về cho VNDCCH.\n\n\n\nLê Trọng Tấn - vị tướng đánh trận giỏi nhất lịch sử hiện đại Việt Nam: link\n\nphương châm “thắng không tranh công, thua không đổ lỗi”\n\n\n\nmột số câu hỏi tò mò\n\n\nBài học\n\nBài học cuộc sống từ quyết định của tướng Giáp tại Điện Biên Phủ 1954 (spiderum.com)\n\n\n\nvì sao từ nhà giáo trở thành vị tướng\n\ncon người ưa chuộng hoà bình, ông nói nếu không làm tướng cũng sẽ làm giáo viên dạy triết hoặc lịch sử\n\n\nbác giáp học quân sự ở đâu\n\nchưa từng trải qua bất kì trường lớp nào\nnhà lý luận chiến tranh clausewitz đã từng nói, nếu muốn tự học về quân sự chỉ có 2 con đường: kinh nghiệm bản thân và lịch sử chiến tranh\nchiến tranh du kích\n\n\n\n\n\nliệu có thể tránh được cuộc chiến tranh đông dương lần 1 hay không\n"},"history2/LĐ1---Pháp-rơi-vào-thế-phải-chiến":{"title":"LĐ1 - Pháp rơi vào thế phải chiến","links":["history2/Chiến-tranh-Thế-giới-2"],"tags":[],"content":"Cần vơ vét thuộc địa để khắc phục tổn thất\n\nSau CTTG 2,\n"},"history2/NAQ-về-Quảng-Châu":{"title":"NAQ về Quảng Châu","links":[],"tags":[],"content":"Topic 4: Tại sao NAQ quay về Quảng Châu mà không ở lại châu Âu làm việc cho QTCS. Ông đã làm được gì quan trọng nhất ở Quảng Châu?\n\n\n"},"history2/Nhật-Bản":{"title":"Nhật Bản","links":[],"tags":[],"content":"note\n\nfukuzawa\n\n12 năm chuẩn bị\ncải cách nhật thành công?\n\nphát hành sách ra công chúng, 5tr bản (30tr dân) → trình độ dân trí cao\nphái đoàn 128 ng đi tất cả thành phố lớn, học từ các nước lớn (hiến pháp đức, tàu thuỷ hà lan, lái xe anh) → shortcut cắt tgian, learn from the best + apply luôn\n\n\n\n\nnguyễn trường tộ - cải cách nộp cho vua, cận thần &gt;&lt; cải cách toàn diện\n\n\n\nnghiên cứu lịch sử hay kinh doanh, v.v → luôn phải để ý bối cảnh xung quanh, các nước khác, lsu vhoa ctri, trong bối cảnh chung của cả TG\n\n"},"history2/Untitled":{"title":"Untitled","links":[],"tags":[],"content":""},"history2/draft---pháp-rơi-vào-thế-phải-chiến":{"title":"draft - pháp rơi vào thế phải chiến","links":[],"tags":[],"content":"\nđối với pháp, cuộc chiến mang tính chính trị và tâm lý hơn kinh tế~~\n\nnếu pháp để đông dương dành độc lập, các quyền và tài sản của Pháp tại nhiều thuộc địa hải ngoại sẽ nhanh chóng bị mất theo\nxung đột giữa lợi ích đế quốc và phong trào độc lập của Đông Dương\nxung đột giữa các cường quốc châu âu - ai chiếm được nhiều thuộc địa, tài nguyên hơn\n\nDẫn chứng: Việc cạnh tranh giữa các quốc gia châu Âu (như Pháp, Anh) để chiếm đóng các vùng đất và tài nguyên ở Đông Dương đã làm tăng sự căng thẳng và xung đột (Ví dụ: Trận Mạc Cửu năm 1940 giữa Pháp và Nhật Bản).\n\n\n\n\npháp liên tiếp bại trận kể từ CTTG T2 nổ ra → khắc phục tổn thất bằng cách vơ vét thuộc địa (Trong đó có VN)\n\nT6/1940, Pháp bị đức quốc xã chiếm đóng trong CTTG2 → cơ hội Nhật Bản chiếm bán đảo Đông Dương từ P\nT9/1940, Nhật tấn công VN, P chạy về Thái Nguyên → thời cơ cho khởi nghĩa đã đến\n\n27/9/1940, chi bộ ĐCS ĐD phát động khởi nghĩa, dành 1 số địa bàn\nP bại trận ở CTTG2, bị Nhật cướp quyền ở Đông Dương\n09/03/1945, Nhật đảo chính Pháp trên toàn bán đảo đông dương, P theo đó phải rời VN\n\nnhật bản tuyên bố trao trả độc lập cho việt nam, thành lập và bảo hộ đế quốc VN, giữ nguyên bộ máy cai trị, thay ng nhật vào vị trí ng pháp\nN vơ vét tư liệu sản xuất hàng hoá lương thực, cướp tài sản của dân VN, chiếm kho thóc → nạn đói 1945\n\n\n⇒ đấu tranh vũ trang giữa các dân tộc, điển hình là VN, P, N\n\n\nNhật thua VN\n\nnhật sợ ptrao cộng sản lan rộng, đã mở càn quét bình định, tấn công vào các vùng chốt hiểm của việt minh &gt;&lt; tư tưởng công sản của VN lan truyền mạnh mẽ, ng dân thấy lối đi mới thoát khỏi xiềng xích phong kiến cũ → không chấp nhận bóc lột hà khắc của N.\ngiữa 1945, cuộc chiến chưa đi xa, ĐQ Nhật đầu hàng phe đồng minh → tại sao\n\nVN có cơ hội lớn dành lại độc lập → 19/8/1945, VM tổ chức CMT8 từ tổng khởi nghĩa HN lan rộng ra khắp Bắc Trung Nam → ĐQ Nhật, chính phủ ĐQ VN do N thành lập sụp đổ. 2/9 → khai sinh VNDCCH sau gần 100 năm Pháp thuộc\n\n\n\n\n⇒ sự khẳng định là mình mạnh hơn Nhật, lấy lại danh dự\n\n\n\n\nCheck your Supabase project’s API settings to find these values\nsupabase.com/dashboard/project/_/settings/api\nat RootLayout (./app/[locale]/layout.tsx:75:87)\nat stringify ()\n⨯ Error: Your project’s URL and Key are required to create a Supabase client!"},"history2/his2lec2-questions":{"title":"his2lec2 questions","links":[],"tags":[],"content":"\nnăng\n"},"history2/liệu-có-thể-tránh-được-cuộc-chiến-tranh-đông-dương-lần-1-hay-không":{"title":"liệu có thể tránh được cuộc chiến tranh đông dương lần 1 hay không","links":[],"tags":[],"content":"Chứng minh không thể tránh được cuộc chiến tranh đông dương lần 1 qua 3 luận điểm, gồm\n\nluận điểm chính (1 câu ngắn gọn)\nSupporting ideas\nDẫn chứng, data\nDL: Tối T7 trước lúc họp\n\n\n\nframing\n\nnguyên nhân và bối cảnh của CTDD\n\n([wiki](Chiến tranh Đông Dương – Wikipedia tiếng Việt)) xung đột thật sự đã nổ ra từ ngày 23 tháng 9 năm 1945 khi quân Pháp theo chân quân Anh tiến vào miền Nam Việt Nam để giải giáp quân Nhật.\n\n\n\n\n\n\n\n\n\nmột cuộc chiến đã được lường trước bởi các bên\n\nđối với VN, đây là giai đoạn đầu tiên trong cuộc kháng chiến 30 năm của họ\nsẽ là cuộc chiến: Giữa hổ và voi. Nếu hổ đứng yên, chắc chắn voi sẽ dẫm bẹp. Nhưng hổ nấp trong rừng và sẽ xuất hiện ban đêm, cắn một miếng rồi lại biến mất vào rừng sâu. Dần dần voi sẽ chảy hết máu mà chết. Đó sẽ là cuộc chiến tranh Đông Dương.\ntạm ước 14/09 bị phá bỏ, Hội nghị Fontainebleau đã thất bại do Pháp vẫn giữ lập trường thực dân và âm mưu tái chiếm Việt Nam\n\n\n\nđối với pháp, cuộc chiến mang tính chính trị và tâm lý hơn kinh tế\n\nnếu pháp để đông dương dành độc lập, các quyền và tài sản của Pháp tại nhiều thuộc địa hải ngoại sẽ nhanh chóng bị mất theo\nlãnh đạo pháp: cuộc chiến này có quy mô lớn hơn chút so với một cuộc tái chiếm thuộc địa cổ điển\n\n\n\nPháp đứng vào thế tiến thoái lưỡng nan về chính trị:\n\ndebate câu 4 week 6 - Google Docs\n\n\n\nxung đột giữa lợi ích đế quốc và phong trào độc lập của Đông Dương\n\n\nĐòn bẩy quốc tế và cạnh tranh lợi ích:\n\nCác cường quốc châu Âu đang cạnh tranh lợi ích trong khu vực Đông Dương, tạo ra áp lực không thể tránh khỏi cho các quốc gia địa phương.\nSự can thiệp của các cường quốc đã làm tăng căng thẳng và nguy cơ xung đột.\nDẫn chứng: Việc cạnh tranh giữa các quốc gia châu Âu (như Pháp, Anh) để chiếm đóng các vùng đất và tài nguyên ở Đông Dương đã làm tăng sự căng thẳng và xung đột (Ví dụ: Trận Mạc Cửu năm 1940 giữa Pháp và Nhật Bản).\n\n\n\n\n\nBản tuyên ngôn nhân quyền và dân quyền của cách mạng pháp năm 1971: người ta sinh ra tự do và bình đẳng về quyền lợi và phải luôn luôn được tự do và bình đẳng về quyền lợi\n\n\n\npháp liên tiếp bại trận kể từ CTTG T2 nổ ra → khắc phục tổn thất bằng cách vơ vét thuộc địa (Trong đó có VN)\nP chưa ý thức đc đe doạ phong trào CSQT mang lại, chỉ lo vơ vét thuộc địa, tham chiến nhiều nơi, dành đất với các đồng mình\n\nP vơ vét VN, tầng lớp nông dân công nhân ngày càng căm phẫn, tư sản địa chủ trí thức ngả dần về phía cách mạng. các tầng lớp đều chờ thời cơ nổi dậy chống lại chính phủ P\n\n\nNhật muốn vẽ lại bản đồ TG - điểm yếu là k có nhiều tài nguyên khoáng sản (phải nhập khẩu) → muốn sáp nhập TQ &amp; các quốc gia lân cận vào thịnh vượng chung đại đông á ⇒ ctranh Trung Nhật\nT6/1940, Pháp bị đức quốc xã chiếm đóng trong CTTG2 → cơ hội Nhật Bản chiếm bán đảo Đông Dương từ P\nT9/1940, Nhật tấn công VN, P chạy về Thái Nguyên → thời cơ cho khởi nghĩa đã đến\n\n27/9/1940, chi bộ ĐCS ĐD phát động khởi nghĩa, dành 1 số địa bàn\nP bại trận ở CTTG2, bị Nhật cướp quyền ở Đông Dương\n⇒ đấu tranh vũ trang giữa các dân tộc, điển hình là VN, P, N\n\n\n1941, ptrao cộng sản đông dương bùng nổ, NAQ về VN, trực tiếp lãnh đạo CM chống P\n19/5/1941, Việt Minh thành lập, nvu giải phóng dân tộc chống pháp dành độc lập\n09/03/1945, Nhật đảo chính Pháp trên toàn bán đảo đông dương, P theo đó phải rời VN\n\nnhật bản tuyên bố trao trả độc lập cho việt nam, thành lập và bảo hộ đế quốc VN, giữ nguyên bộ máy cai trị, thay ng nhật vào vị trí ng pháp\nN vơ vét tư liệu sản xuất hàng hoá lương thực, cướp tài sản của dân VN, chiếm kho thóc → nạn đói 1945\n\n\n9/3-12/3/1945, ĐCS DD ra chỉ thị Nhật Pháp bắn nhau và hành động của chúng ta\n\nchủ trương phát động cao trào đánh nhật mạnh mẽ\n\n\nnhật sợ ptrao cộng sản lan rộng, đã mở càn quét bình định, tấn công vào các vùng chốt hiểm của việt minh &gt;&lt; tư tưởng công sản của VN lan truyền mạnh mẽ, ng dân thấy lối đi mới thoát khỏi xiềng xích phong kiến cũ → không chấp nhận bóc lột hà khắc của N.\ngiữa 1945, cuộc chiến chưa đi xa, ĐQ Nhật đầu hàng phe đồng minh → tại sao\n\nVN có cơ hội lớn dành lại độc lập → 19/8/1945, VM tổ chức CMT8 từ tổng khởi nghĩa HN lan rộng ra khắp Bắc Trung Nam → ĐQ Nhật, chính phủ ĐQ VN do N thành lập sụp đổ. 2/9 → khai sinh VNDCCH sau gần 100 năm Pháp thuộc\n\n\ntuy nhiên tư tưởng thượng đẳng, thói quen đàn áp dân tộc khác còn đó → Nhật bại trận, mất quyền kiểm soát ĐD\n\nhiệp định Postdam, quân đội Anh, 23/9/1945, đại diện đồng minh tiến vào giải giáp quân nhật ở nam việt nam.  Theo chân A, P đưa quân trở lại Đông Dương phải tiếp tục nằm trong Liên hiệp Pháp, ng dân P ủng hộ cuộc chiến, cho rằng nếu Pháp để Đông Dương giành độc lập, các quyền lợi và tài sản của thực dân Pháp tại các thuộc địa hải ngoại sẽ nhanh chóng bị mất theo.\n23/9/1946, P nổ súng tấn công sài gòn, P cho biết họ muốn lãnh thổ Đông Dương phải tiếp tục nằm trong Liên hiệp Pháp mới được thành lập\n\n\n\n\n\nđổ bộ cảng hải phòng 1946\nquân đồng minh gồm Anh và trung hoa dân quốc tiến vào VN rải rác quân nhật → tạo điều kiện cho Pháp trở lại chiếm sài gòn → Pháp k chỉ muốn kiểm soát mNam VN, P muốn thay thể quân Tưởng giải giáp quân nhật để thâu tóm toàn bộ miền bắc\n28/2/1946 - P đưa nhiều lợi ích để kí với Trung Hoa Dân Quốc HĐ Trùng Khánh\n\nP biến HP (thuộc chủ quyền VNDCCH) thành cảng tự do đvs ng Hoa\nVN tức giận, k thừa nhận văn bản\n\n\nbất chấp VNDCCH phản đối, đầu t3/1946, P di chuyển ra HP thực hiện hiệp định trùng khánh\n\nTHDQ viện cớ chưa nhận được lệnh về thực hiện hiệp ước, k chấp nhận cho P tiến vào, đe doạ nếu cố tình đổ bộ HP, quân T sẽ nổ súng\nquân T thực ra muốn kéo dài tgian vơ vét của cái\nP vẫn tiến vào HP → nổ súng xung đột nổ ra\n\n\nsau xung đột, P hy vọng đàm phán với VN để thay quân Tưởng ở mBac VN\n\nVNDCCH từ lâu đã muốn Tg rút về nc → tránh rắc rối → hiệp định sơ bộ: hoà hoãn với P\n\n\n18/3/1946: Tg rút khỏi mB, P cho quân đóng tại cảng HP và dẫn quân lên HN\n\nk lâu sau, P vi phạm HĐ: cho quân chiếm đóng các vị trí quan trọng ở HP (sở thuế quan, ngân hàng, cảng HP gần như bị phong toả ) → nhiều biểu tình, meeting phản đối P\nđể cứu vãn căng thảng → VNDCCH cử ng đến hội nghị fontainebleau đàm phán\ntrong lúc đàm phán diễn ra, P tiếp tục can thiệp thuế quan ở HP, ngầm ủng hộ ng buôn bán nước ngoài trốn thuế ở VN\n\n\nT9/1946: tạm ước việt pháp\n\nhành động gây hấn của Pháp k dịu đi\ntỏ thiện chí của ng V, HCM đề nghị tổ chức bóng đá giao hữu giữa P và VN, hoà 1-1, kkhi vui vẻ &gt;&lt; k ngăn đc tham vọng của P tại Hải Phòng\nngay sau đó, P ra mệnh lệnh (13706 r3s + 938pc) chỉ huy lên kế hoạch chiếm hải phòng\nVN nhận ra khó kéo dài hoà hoãn → HCM chia thành 12 chiến khu\n\n\nT11/1946\n\nP tấn công trụ sở hải quan tại HP &gt;&lt; VN phản đối, kdinh chủ quyền trong kiểm soát vde lquan xuất nhập khẩu &gt;&lt; P vẫn công khai gây chiến\n23/11/1946, HCM vẫn thiện chí kêu gọi Pari đình chiến tránh đổ máu (nhân nhượng &gt;&lt; chuẩn bị tiềm lực mọi mặt)  &gt;&lt; P k dừng lại → VN quyết dành lại HP\nchiến khu trưởng khu 3 (Hoàng Minh Thảo, khu 3 gồm hải phòng) trăn trở ra lệnh cho dân thường &amp; llvt rút khỏi HP, để lại nhóm nhỏ phá P &amp; xây tuyến phòng thủ ngoại thành thành phố, chốt giữ các cửa ngõ (phá sập cầu, tháo rỡ đường sắt HP Hải DG, đổ đá ngăn sông)\n28/11/1946: VN rút hoàn toàn ra khỏi nội thành HP\nsau trận cam lộ, chiến sự giằng co kéo dài cho đến đầu tháng 12\n\n\nT12/1946:\n\nP hoàn toàn kiểm soát HP, chiếm thêm Lạng Sơn &amp; ĐN\nkết thúc chiến dịch HP 1946\n\nđể phát động chiến trên toàn VN, P gửi ít nhất 3 tối hậu thư, ycau chính phủ HCM giải giáp quân sự để P nắm quyền kiểm soát ⇒ HCM ra kêu gọi Toàn Quốc Kháng Chiến\nBlum - thủ tướng mới ở P, bất ngờ kêu gọi giải quyết xung đột ở đông dương theo cách trao lại độc lập cho VNDCCH → thông điệp tích cực nhất → HCM gửi bức thông điệp tới Blum, gợi ý cụ thể cách giải quyết xung đột (Sainteny - đại diện P, gửi vào SG rồi sang Pari)\n16/12: âm mưu xâm chiếm VN, tướng Valluy phổ biến plan đánh chiếm hà nội và cả phía bắc vĩ tuyến 16 cho các tướng lĩnh P (nhấn mạnh phá hoại chướng ngại vật Việt Minh dựng → khiêu khích người việt tạo ra xung đột → valluy mượn cớ xung đột ở HN, cảnh báo thủ tướng P thận trọng với thông điệp HCM)\n18/12: P đưa ra 2 tối hậu thư yêu cầu VNDCCH chấm dứt dựng chướng ngại vật, đe doạ từ 20/12 quân pháp sẽ tự đảm nhiệm trị an HN\ntối 18/12: VM phục kích từ ngoại ô → TP, kêu gọi ng dân nâng cảnh giác tuân thủ kỷ luật chờ lệnh mới đc tấn công. trong nội thành, phố xá thưa thớt bóng ng, nhà cửa đóng kín, nhưng thực chất bên trong từ ban công, cửa sổ đến mái nhà đều trở thành vị trí phòng ngự. tường trong nhà, ngoài sân, trên gác đều được đục thành lỗ giao thông di chuyển từ nhà đến nhà, tạo trận địa chiến đấu liên hoàn\nsáng 19/12: P ra tối hậu thư #3, đòi chính phủ VN đình chỉ mọi hđ chuẩn bị chiến tranh, cho quân đội P duy trì an ninh trong tpho, doạ cướp vũ khi quân tự vệ HN\nHCM triệu tập hội nghị TW đảng mở rộng, đã soạn sẵn lời kêu gọi tqkc. Võ Nguyên Giáp ra mệnh lệnh chiến đấu.\n\ncơ quan đầu não rút khỏi nội thành để bảo toàn lực lượng\nCơ quan mật mã bộ tổng tham mưu truyền đi bản mật lệnh\n\ntổng tham mưu quy ước khi đài tiếng nói phát câu lúc đúng 20h 19/12/1946 “đồng bào chú ý” - tín hiệu tổng giao chiến\nkhoảng 20 giờ ngày 19/12/1946, công nhân nhà máy điện Yên Phụ phá máy, cả thành phố tắt điện + đài tiếng nói phát “đồng bào chú ý” → hiệu lệnh chiến đấu toàn thành, mở đầu kháng chiến toàn quốc.\n\n\n\n\n\n\n\nTinh thần dân tộc\nBối cảnh thế giới ảnh hưởng đến Pháp - Pháp rơi vào thế phải chiến\n\nNhật chiếm bán đảo đông dương từ P (vì cần tài nguyên từ các nc thuộc địa đông dương, [link](TOÀN CẢNH CHIẾN TRANH VIỆT NAM - CHIẾN TRANH ĐÔNG DƯƠNG - YouTube) 10:50)\nphong trào QTCS ảnh hưởng tới Pháp\n\n\nBối cảnh ảnh hưởng đến Việt Nam - Việt Nam rơi vào thế không thể nhân nhượng\n\n\n\nreply: chứng minh ngay cả khi chúng tôi ở trong thế giới của các bạn, luận điểm của chúng tôi vẫn đúng\n\npháp thắng k bại trận trong thì lòng tham vẫn vô đáy\n\n\n\n\nmẫu thuẫn lớn nhất vì sao k thể k xảy ra đông dương lần 1 là gì"},"history2/make-in-việt-nam-his2":{"title":"make in việt nam his2","links":[],"tags":[],"content":"\n\n\nkế hoạch marshall P nhận hỗ trợ từ mỹ\n\n\ntổ chức nhiều cơ hội được quốc tế công nhận\n\nhợp tác với các bên có tên tuổi\n\npay it forward, giúp tên tuổi họ thâm nhập thị trường việt nam\nđối tác là\n\n\n\n\n\ntạo ra các hỗ trợ đi nước ngoài học tập, phát triển, về VN phục vụ\n\nVingroup scholarship\n\n\n\nđầu tư vào giáo dục\n\n"},"history2/reflection-lecture-3-his2":{"title":"reflection lecture 3 his2","links":[],"tags":[],"content":"good\n\nresearch well about different topics\n1 bonus point for answer\n\nimprove\n\nfocus on getting the main idea of the topic → get points by answering more than questioning\nfocus on self interpretation, think in multiple perspective\nask thought-provoking questions, start with why\nevery words you speak out has to be:\n\ndirect to the point in 1 sentences of max 8 words\nexplain later if asked\n\n\ntake note questions from others, esp good questions with 2 bonus pts\n"},"history2/đường-sắt-bắc-nam":{"title":"đường sắt bắc nam","links":[],"tags":[],"content":"note\n\n\nCâu 3: Tại sao Pháp xây dựng đường sắt Bắc Nam? Bây giờ có cần xây dựng đường sắt Bắc Nam không?\n\n\nnăng lực vận chuyển, tiêu chuẩn tăng cao, thời gian đi lại thấp\n→ tại sao lại cần xây dựng mà không sử dụng và nâng cấp những csht hiện có như đường hàng không\n\n\nan toàn (k có chắn ngang qua đường), tin cậy (đk thời tiết, ùn tắc gthong), môi trường (đường sắt thải co2 ít hơn hẳn)\n\n\ncó giải pháp nào sử dụng những hệ thống vận chuyển\n\n\nđường sắt tốc độ cao ngầm\n\n\nngân sách xây dựng đường sắt cát linh\n\n\n\n\n\n2 vấn đề nổi cộm: tắc nghẽn → vận chuyển hàng hoá + vận chuyển hành khách đang quá tải\n\n\ncriteria: năng lực vận chuyển đường bộ, tiêu chuẩn tăng cao, thời gian đi lại thấp\n\n\nwhy better:\n\n\ncó cách nào để giải quyết vấn đề (quá tải trong vận chuyển hàng hoá và hành khách) bằng cách sử dụng những cơ sở hạ tầng sẵn có và nâng cấp lên, thay vì phải đập mới, và hiệu quả hơn về mặt ngân sách + môi trường + tính khả thi\n\n\nquá tải → đường bộ cao tốc và đường sắt cao tốc\n\n\nđể giải quyết vấn đề quá tải, 2 phương án cách khả thi nhất đang là đường bộ cao tốc và đường sắt cao tốc\n\n90% chúng ta lệ thuộc vào nước ngoài do chưa đủ trình độ, năng lực, từ khâu công nghệ, vật tư, nguyên nhiên vật liệu đến vận hành.\nngân sách + môi trường + tính khả thi\n\n\n\nĐường bộ trước hay đường sắt trước?\n\n\n\n\n\nkbt gì nhưng muốn làm → dựa vào ai để học được → chuyển giao công nghệ → đi theo học người giỏi nhất\n\nmấu chốt tất cả dự án là làm tnao nắm được công nghệ đấy\n\n\n\nvì sao pháp xâm chiếm được → có mục địch nổi cộm &amp; rõ ràng\n\n\nđể giải quyết vấn đề quá tải, chúng ta nên ưu tiên đường bộ trước hay đường sắt trước\n\n\nngân sách:\n\n\n\n\n\nCó nhiều ý kiến phản biện đáng suy nghĩ như cần 16 năm làm xong thì vận tốc 250km/h đã lạc hậu, chưa kể đến việc chở hàng và chở khách sẽ ảnh hưởng lẫn nhau, tính bền vững giải quyết ntn?\n\n\nchi phí logistic cao hơn nhiều\n\n\n\n\n\ntheo bạn, ngôn ngữ gen z đang là mối nguy hiểm hay là một sự phát triển trong ngôn ngữ tiếng việt thể hiện được cái tôi\n\ncó thể phát triển ntn\n\n\n\nnguy hiểm đang báo động tới chữ quốc ngữ, và nếu là viện trưởng viện nn học thì bạn sẽ làm gì để bảo tồn vẻ đẹp của ngôn ngữ gen z\n\n\n\nbảo tồn chữ quốc ngữ ntn trong quá trình hội nhập và tiếng anh trở thành một ngôn ngữ sử dụng hàng ngày\n*từ chữ hán, sang chữ nôm vì không thể biểu diễn đầy đủ các từ vựng, ngữ pháp và sắc thái văn hoá tiếng Việt, nhưng từ chữ nôm sang chữ quốc ngữ biểu hiện sắc thái văn hoá tv rất rõ qua dấu câu , vẫn khó phổ biến rộng →\nđến mức đôi khi có những sự từ khác nghĩa nhưng đánh vần, đọc và chữ viết y chang, có dấu*\nnếu ko cải tiến vậy thì có nên giản lược?\n\n\n\nbạn nghĩ sao về những từ dịch từ tiếng anh sang tiếng việt, cách sử dụng nào hợp lý hơn, nếu như cách sử dụng tiếng anh hợp lý hơn thì phải chăng ta đang dần nhượng bộ cho việc hoà tan ngôn ngữ tiếng việt vs ta\n\n\ncách nói chêm tiếng anh và tiếng việt, như bạn vừa nói là các cái terms, có\n\n\nBản chất vốn có của tiếng Việt như thế nào và việc sử dụng đúng bản chất đó ra sao thì đó chính là sự trong sáng của tiếng Việt → ko có những từ chưa được thì có đc gọi mất trong sáng. nếu muốn trong sáng = ngừng phát triển ngôn ngữ tiếng việt\n\n"},"index":{"title":"Map of Contents","links":["algoDesign/***algoDesign-map","artificialIntelligence/***AI-map","comOrg/***comOrg-map","DSA/***-DSA-map-(OOP-course)","probStatAdvanced/***probStatAdvanced-Map","history2/***history-2-map"],"tags":[],"content":"\n***algoDesign map\n***AI map\n***comOrg map\n*** DSA map (OOP course)\n***probStatAdvanced Map\n***history 2 map\n"},"probStatAdvanced/***probStatAdvanced-Map":{"title":"***probStatAdvanced Map","links":["probStatAdvanced/Simple-Linear-Regression-Model","probStatAdvanced/Time-series","probStatAdvanced/Finding-trend-in-a-time-series-graph","probStatAdvanced/Moving-averages","probStatAdvanced/Additive-Model---finding-seasonal-component-variations","probStatAdvanced/Multiplicative-Model---finding-seasonal-percentage-variations","probStatAdvanced/forecasting-future-values-in-time-series","probStatAdvanced/deseasonalization---removing-variations-to-indicate-trend","probStatAdvanced/Stochastic-process","probStatAdvanced/Markov-chain","probStatAdvanced/Chapman-Kolmogorov-Equations","probStatAdvanced/25-03-2024"],"tags":[],"content":"probStatAdvanced Map\nChapter 1: Simple Linear Regression\n\nSimple Linear Regression Model\n\nChapter 2:\n\nTime series\nFinding trend in a time series graph\nMoving averages\nAdditive Model - finding seasonal component variations\nMultiplicative Model - finding seasonal percentage variations\nforecasting future values in time series\ndeseasonalization - removing variations to indicate trend\n\nChapter 3: Markov Chains\n\nStochastic process\nMarkov chain\nChapman-Kolmogorov Equations\n25 03 2024\n\nnote\n\nchưa làm hết bài trong slide 2\n"},"probStatAdvanced/25-03-2024":{"title":"25 03 2024","links":[],"tags":[],"content":"\nclassification of states\n\nj accessible from state i if Pijn​&gt;0 for some n &gt;= 0\n\n\naccessible: move from state i to j after certain of steps\nrelation of communication\n\ni com with i, i &gt;=0; Pij0​=P(Xk​=i∣Xk​=i)=1\ni com with j, then j com with i; there are such m,n such that Pijm​&gt;0andPjim​&gt;0 then j↔i\ni com with j, j com with k, then i com with k; Pijn​&gt;0,j↔k:Pjkm​&gt;0\n\nP_{ik}^{n+m} - chapman - \\sum\n\n\n\n\n\n\n\ntwo states that communicate → in the same class\nany 2 classes of states - either identical or disjoint\nirreducible in markov chain if there is only 1 class\nIf A∪B=∅ then A = B\n\n"},"probStatAdvanced/Additive-Model---finding-seasonal-component-variations":{"title":"Additive Model - finding seasonal component variations","links":[],"tags":[],"content":"what is additive model\n\nadditive model: Y=T+S+R\nassume random component R is negligible, the seasonal component S is: S=Y−T (de-trended series)\n\nY is the actual time series\nT is the trend series (moving average)\nS is the seasonal component (Not included in some models)\nC is the cyclical component (excluded)\nR is the random component\n\n\n"},"probStatAdvanced/Chapman-Kolmogorov-Equations":{"title":"Chapman-Kolmogorov Equations","links":[],"tags":["Math/probability/markovChain/chapman"],"content":"Chapman-Kolmogorov Equations\n\n\nn-step transition probabilities Pijn​: probability a process state i will be in state j after n additional transitions\n\nPijn​=P{Xn+k​=j∣Xk​=i}, n≥0, i,j≥0.\n\n\n\nChapman-Kolmogorov equations to compute n-step transition probabilities\n\nPijn+m​=∑k=0∞​Pijn​Pijm​∀n,m≥0,∀i,j\n\n\n\nP(n): matrix of n-step transition probabilities Pijn​\n\nP(n+m)=P(n)⋅P(m)\n⇒ n-step transition matrix obtained by multiplying P by itself n times\n\n\n"},"probStatAdvanced/Finding-trend-in-a-time-series-graph":{"title":"Finding trend in a time series graph","links":["Regression-Model"],"tags":[],"content":"how to find trend in a time series graph\nInspection:\n\nThe trend line can be drawn by eye on a graph in such a way that it appears to lie evenly between the recorded points, that is, a line of best fit drawn by eye.\n\nRegression Analysis:\n\nThis method makes the assumption that the trend line is a straight line.\nPeriods of time are numbered, and the regression line of the data on those periods is found.\nThat line is taken to be the trend.\n\nMoving Average:\n\nThis method attempts to remove seasonal variations by a process of averaging\n"},"probStatAdvanced/Markov-chain":{"title":"Markov chain","links":[],"tags":["Math/probability/markovChain"],"content":"Intro\n\n\n{Xn​,n=0,1,2,...} is a stochastic process\n\n\nIf Xn​=i ⇒ process is in state i at time n\n\n\nn≥0\n\n\nMarkov property: “memoryless” - next state depends only on current state, not the sequence of events in the past\n\n\nWhenever process in state i → fixed probability Pij​ that process will next be in state j\n\n\nP{Xn+1​=j∣Xn​=i,Xn−1​=in−1​,…,X1​=i1​,X0​=i0​}=Pij​\n\nfor all states i0​,i1​,⋯,in−1​,i,j and all n≥0\n\n\n\nMarkov chain: conditional distribution of any future state Xn+1​, given past states X0​,⋯,Xn−1​ and present state Xn​, is independent of past states, and depends only on the present state\n\n\nP: matrix of one-step transition probabilities Pij​\n\n​P00​P10​⋮​P01​P11​⋮​P02​P21​⋮​⋯⋯​​\neg. P10​: from row to column ⇒ row 1, col 0\n\n\n\nsimple example: a Markov chain modeling the weather, in which we know today is sunny, can give us probability for whether tomorrow is sunny, rainy or cloudy solely based on today’s data\n\n"},"probStatAdvanced/Moving-averages":{"title":"Moving averages","links":[],"tags":[],"content":"what is moving average\n\nA series of arithmetic averages over a given number of time periods. It is the estimate of the long run average of the variable.\nHelp smoothing out the data with less peaks and valley\n\nlarge grouped data point will be more smooth\n\n\ngiven k is the amount considered in MA (eg. # of months)\n\nif considering most recent values → small value of k is preferred\nif considering past values → larger value of k is preferred\n\n\n\nOdd number of time periods in moving average\n\nThe average of any 3 data points becomes the value of the 2nd data point\n\nEven number of time periods in moving average\n\nFormula: ((0.5∗a+b+c+d+0.5∗e)/5), place the value in position 3, similarly for other odd time periods\nOther way: in 4 months, calculate sum of 2 months twice, then calculate that total sum\n"},"probStatAdvanced/Multiplicative-Model---finding-seasonal-percentage-variations":{"title":"Multiplicative Model - finding seasonal percentage variations","links":[],"tags":[],"content":"what is multiplicative model\n\nY=T.S.R\n\nT: original units\nS &amp; R: percentages\nif R negligible (R ~1) → seasonal percentage: S=Y/T\n\n\n\nwhen does multiplicative outperform additive model\n\nwhen the trend is increasing or decreasing over time\nMultiplicative is often preferred as it assumes components are dependent on each other\n"},"probStatAdvanced/Simple-Linear-Regression-Model":{"title":"Simple Linear Regression Model","links":["Linear-regression"],"tags":[],"content":"title\nnote\n\nLinear regression\nHas the form (y=β0​​+β1​​+ϵ)\n\nSimple linear regression equation: (E(y)=β0​​+β1​​x)\nϵ: random var referred to as error term\nIn practice, β0​​ and β1​​ are not known, but can be estimated with b0​​ and b1​​, where b0​​ and b1​​ are computed by least squares method\n\n\n\nEstimated simple linear regression model:\n\n(y​^​=b0​​+b1​​x)\n\n(y^​)​ is the point estimator of E(y)\n\n\ngraph of Estimated simple linear regression model = estimated regression line = line of best fit\n\n"},"probStatAdvanced/Stochastic-process":{"title":"Stochastic process","links":["artificialIntelligence/state-space"],"tags":[],"content":"stochastic process\n\nX(t), t∈T\n\nA collection of random variables. For each t∈T, X(t) is a random variable\nThe index t is often interpreted as time and X(t) is the state of the process at time t\n\nEg. X(t): total number of students visiting VinUni by time t\n\n\nThe set T is called the index set of the process.\n\nwhen T countable → the stochastic process has discrete-time\nwhen T is an interval of real line → the stochastic process has continuous-time\n\n\nX(t)∈ state space\n\n\n"},"probStatAdvanced/Time-series":{"title":"Time series","links":[],"tags":[],"content":"Definition of time series:\n\na series of figures or values recorder over time\n\ntime series example\n\n\n\nComponents:\n\n4 components of time series:\n\nTime Series Trend\n\nA continuous long-term movement over time in the values recorded\nUpward, downward vs horizontal\n\nSeasonal Variation\n\nMovements in the time series that reoccur each year about the same time due to the change in the seasons.\n\nexample, the spending in ice cream is higher during summer\n\n\n\nCyclical Variation\n\nMany variables often exhibit a tendency to fluctuate above and below the long-term trend over a long period of time.\nThey cover much longer time periods than do seasonal variations.\n\nRandom Variation\n\nCaused by unusual and unexpected occurrences producing movements which have no discernible pattern.\nThese movements are unique and unlikely to reoccur in similar fashion.\nThey can be caused by events such as wars, floods, earthquakes, political elections, or oil embargoes.\n\nTime Series Models:\n\nA time series model can be expressed as some combination of these four components.\nTwo types of models are commonly associated with time series: Additive Model and multiplicative model.\n\nThe additive model is expressed as Y=T+S+C+R where\n\nY is the actual time series\nT is the trend series\nS is the seasonal component (Not included in some models)\nC is the cyclical component (excluded)\nR is the random component\n\n\nWe only consider Y=T+S+R\n\n\n"},"probStatAdvanced/deseasonalization---removing-variations-to-indicate-trend":{"title":"deseasonalization - removing variations to indicate trend","links":[],"tags":[],"content":"what is deseasonalization\n\nprocess of removing variations to leave a figure indicating trend\n"},"probStatAdvanced/forecasting-future-values-in-time-series":{"title":"forecasting future values in time series","links":[],"tags":[],"content":"how to forecasting future values in time series\n\nforecasting by extrapolation: process of estimating beyond original range, the value of a variable, on the basis of its relationship with another variable\nForecasts of future values should be made as follows.\n\nCalculate a trend line using moving averages or regression.\nUse the trend line to forecast future trend line values.\nAdjust these values by the average seasonal variation. With the additive model, add the variation. With the multiplicative model, multiply the trend value by the variation proportion\n\n\n\nnote on extrapolation\n\nextrapolation based on historical data, not including effects of developments → can be used for short term forecasts for specific areas, where no untypical developments are expected\n"}}